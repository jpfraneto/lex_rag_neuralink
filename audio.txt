The following is a conversation with Elon Musk, DJ Sa, Matthew McDougall,
Bliss Chapman, and Noland Arbaugh about Neuralink and the future of humanity.
Elon, DJ, Matthew, and Bliss are, of course, part of the amazing Neuralink team.
And Noland is the first human to have a Neuralink device implanted in his brain.
I speak with each of them individually.
So use timestamps to jump around or, as I recommend, go hardcore
and listen to the whole thing.
This is the longest podcast I've ever done.
It's a fascinating, super technical, and wide-ranging conversation.
And I loved every minute of it.
And now, dear friends, here's Elon Musk, his fifth time on this, the Lex Friedman podcast.
Drinking coffee or water?
Water.
I'm so over-caffeinated right now.
Do you want some caffeine?
I mean, sure.
There's a nitro drink.
This will keep you up to, like, you know, tomorrow afternoon, basically.
Yeah.
So what is nitro?
It's just got a lot of caffeine or something?
Don't ask questions.
It's called nitro.
Do you need to know anything else?
It's got nitrogen in it.
That's ridiculous.
I mean, what we breathe is 78% nitrogen anyway.
What do you need to add more?
Whoa.
Most people think that they're breathing oxygen, and they're actually breathing 78% nitrogen.
You need, like, a milk bar.
Like from Clockwork Orange.
Yeah.
Is that top three Kubrick film for you?
Clockwork Orange?
It's pretty good.
I mean, it's demented.
Jarring, I'd say.
Okay.
Okay.
So first, let's step back, and big congrats on getting Neuralink implanted into a human.
That's a historic step for Neuralink.
Oh, thanks.
Yeah.
There's many more to come.
Yeah.
We just, obviously, have our second implant as well.
How did that go?
So far, so good.
It looks like we've got, I think, on the order of 400 electrodes that are providing signals.
Nice.
Yeah.
How quickly do you think the number of human participants will scale?
It depends somewhat on the regulatory approval, the rate at which we get regulatory approvals.
So we're hoping to do 10 by the end of this year.
A total of 10.
So eight more.
And with each one, you're going to be learning a lot of lessons about the neurobiology of
the brain, everything, the whole chain of the Neuralink, the decoding, the signal processing,
all that kind of stuff.
Yeah.
Yeah.
I think it's obviously going to get better with each one.
I mean, I don't want to jinx it, but it seems to have gone extremely well with the second
implant.
So there's a lot of signal, a lot of electrodes.
It's working very well.
What improvements do you think we'll see in Neuralink in the coming, let's say, let's
get crazy, the coming years?
I mean, in years, it's going to be gigantic.
Because we'll increase the number.
We'll increase the number of electrodes dramatically, we'll improve the signal processing.
So even with only roughly, I don't know, 10, 15% of the electrodes working with Nolan,
with our first patient, we were able to get to achieve a bit per second.
That's twice the world record.
So I think we'll start vastly exceeding the world record by orders of magnitude in years
to come.
So it's like getting to, I don't know, 100 bits per second.
100 bits per second, 1,000, you know, maybe, if it's like five years from now, we might
be at a megabit.
Like, faster than any human could possibly communicate by typing or speaking.
Yeah, that BPS is an interesting metric to measure.
There might be a big leap in the experience once you reach a certain level of BPS.
Yeah.
Like, entire new ways of interacting with a computer might be unlocked.
And with humans.
With other humans.
Provided they have a neural link, too.
Right.
Otherwise, they won't be able to absorb the signals fast enough.
Do you think they'll improve the quality of intellectual discourse?
Well, I think you could think of it, you know, if you were to slow down communication, how
hard do you feel about that?
You know, if you'd only talk at, let's say, one-tenth of normal speed, you'd be like,
wow, that's agonizingly slow.
Yeah.
So now, imagine.
You could speak at, communicate clearly at ten or a hundred or a thousand times faster
than normal.
Listen, I'm pretty sure nobody in their right mind listens to me at 1x.
They listen at 2x.
So I can only imagine what 10x would feel like, or I could actually understand it.
I usually default to 1.5x.
You can do 2x, but, well, actually, if I'm trying to go, if I'm listening to somebody
go to, in like, sort of 15, 20-minute segments to go to sleep.
Then I'll do it 1.5x.
If I'm paying attention, I'll do 2x.
Right.
But actually, if you start, actually listen to podcasts or sort of audiobooks or anything
at, if you get used to doing it at 1.5, then 1 sounds painfully slow.
I'm still holding on to 1 because I'm afraid.
I'm afraid of myself becoming bored with the reality, with the real world where everyone's
speaking in 1x.
Well, it depends on the person.
You can speak very fast.
Like, we communicate very quickly.
And also, if you use a wide range of, if your vocabulary is larger, your bit rate, effective
bit rate is higher.
That's a good way to put it.
Yeah.
The effective bit rate.
I mean, that is the question, is how much information is actually compressed in the
low-bit transfer of language.
Yeah.
If you, if there's, if there's a single word that is able to convey something that would
normally require, I don't know, 10.
Simple words, then you've, you've got a, you know, maybe a 10x compression on your
hands.
And that's really like with memes, memes are like data, data compression.
It conveys a whole, there's, you're simultaneously hit with a wide range of symbols that you
can interpret.
And it's, you, you kind of get it faster than if it were words or, or a simple picture.
And of course you're referring to memes broadly like ideas.
Yeah.
There's, there's a, an entire idea structure that is like a, an idea template.
And then you can add something to that idea template.
But somebody has that preexisting idea template in their head.
So when you add that incremental bit of information, you're conveying much more than if you just,
you know, said a few words, it's everything associated with that meme.
You think there'll be emergent leaps of capability as you scale the number of electrodes?
Yeah.
There'll be a certain, do you think there'll be like actual number where,
where it just, the, the human experience will be altered?
Yes.
What do you think that number might be?
Whether electrodes or BPS?
We of course don't know for sure, but is this 10,000, 100,000?
Yeah.
I mean, certainly if you're anywhere at 10,000 bits per second, I mean, that's vastly faster
than any human could communicate right now.
If you think of the, what is the average bits per second of a human?
It is less than one bit per second over the course of a day because there are 86,400 seconds
in a day.
And you don't communicate 86,400, um, tokens in a day.
Therefore your bits per second is less than one average over 24 hours.
It's quite slow.
Um, and now even if you're communicating very quickly and, and you, you know, you're, uh,
talking to somebody who understands what you're saying, because in order to communicate, you
have to, at least to some degree, a model of the mind state of the person to whom you're
speaking.
Uh, then take the concept you're trying to convey.
Compress that into a small number of syllables, speak them, and hope that the other person
decompresses them into, uh, a conceptual structure that is as close to what you have in your
mind as possible.
Yeah.
I mean, there's a lot of signal loss there in that process.
Yeah.
Very lossy compression and decompression.
And a lot of the, um, a lot of what your neurons are doing is distilling the concepts down
to a small number of symbols of, say, syllables that I'm speaking or, or keystrokes.
Whatever the case may be.
So, uh, that, that's a lot of what your brain computation is doing now that there is an
argument that that's actually a healthy thing to do or a helpful thing to do, because as
you try to compress complex concepts, you're perhaps forced to distill the, you know, what
is it, what is most essential in those concepts as opposed to just all the fluff.
So in the process of compression.
You distill things down to what matters the most, uh, because you can only say a few things.
So that is perhaps helpful.
I think we might, we'll probably get, if our data rate increases, it's highly probable that
we'll become far more verbose.
Um, just like your computer, you know, when computers had like my, my first computer had 8K
of RAM, you know, so, um, you really thought about every byte and, um, you know, now you've
got computers with many gigabytes of RAM.
So, you know, if you want to do an iPhone app that just says hello world, it's probably,
I don't know, several megabytes minimum, a bunch of fluff, but nonetheless, we still
prefer to have the computer with the more memory and more compute.
So the long-term aspiration of Neuralink is to improve the AI human symbiosis, um, by
increasing the, the bandwidth of the communication.
Yeah.
Because if, even if, in the most benign scenario of AI, you have to consider that the AI is
simply going to get bored waiting for you to spit out a few words.
I mean, if the AI can communicate at terabits per second and you're communicating at, you
know, bits per second, uh, it's like talking to a tree.
Well, it is a very interesting question for a super intelligent species.
What use are humans?
Um, I think there is some argument for humans as a source of will, will, will, yeah, source
of will or purpose.
So if you, if you consider the human mind as being essentially the, there's the primitive
limbic elements, which basically even like reptiles have, and there's the cortex, the
thinking and planning part of the brain.
Now, the cortex is much smarter than the limbic system.
And yet it's largely in service to the limbic system.
It's trying to make the limbic system happy.
I mean, the sheer amount of compute that's gone into people trying to get laid is insane.
Um, without the, without actually seeking procreation, they're just literally trying
to do this sort of simple motion.
Um, and they get a kick out of it.
Yeah.
So this, uh, simple, which in the abstract rather absurd motion, which is sex, uh, the
cortex is putting massive.
Amount of compute into trying to figure out how to do that.
So like 90% of distributed computer, the human species is spent on trying to get laid probably
like a massive amount.
Yeah.
Yeah.
There's no purpose to most sex except, uh, hedonistic, you know, it's just sort of joy
or whatever dopamine release.
Um, now once in a while it's procreation, but for humans, it's mostly modern humans.
It's mostly, uh, recreation.
Um, and, uh, and so.
So, so your cortex much smarter than your limbic system is trying to make a limbic system
happy because limbic system wants to have sex.
So, um, or want some tasty food or whatever the case may be.
And then that, that is then further augmented by the tertiary system, which is your phone,
your laptop, iPad, whatever, you know, all your computing stuff, that's your tertiary
layer.
So you're actually already a cyborg.
Uh, you have this tertiary compute layer, which is in the form of your, your computer
with all the applications, all your compute devices.
Um, and.
Uh, and so in the getting laid front, there's actually a massive amount of compute of digital
compute also trying to get laid, you know, with like Tinder and whatever, you know?
Yeah.
So the, the compute that we've humans have built is also participating.
Yeah.
I mean, there's like gigawatts of compute going into getting laid of digital compute.
Yeah.
What if AGI was just happening as we speak, if we merge with AI is just going to expand the
computer.
Yeah.
I mean, there's a huge amount of compute that we humans use pretty much to try to get laid.
Well, it's just one of the things certainly.
Yeah.
Yeah.
Um, but what I'm saying is that, that, yes, like what's, is there a use for humans?
Um, well, there's this fundamental question of what's the meaning of life.
Why do anything at all?
Um, and so if, if, if our simple limbic system provides a source of will to do something,
um, that then goes to our cortex that then goes to our, you know, tertiary compute layer,
then, you know, I don't know, it might actually be that the AI in a benign scenario is simply
trying to make the human limbic system happy.
Yeah.
It seems like it's, the will is not just about the limbic system.
There's a lot of interesting, complicated things in there.
We, we also want power.
That's limbic too, I think.
But then we also want to, in a kind of cooperative way, alleviate the suffering in the world.
Uh, not everybody does, but yeah, sure.
Some people do.
As a group of humans, when we get together, we start to have this kind of collective intelligence
that is, uh, is more complex in its will than the underlying individual descendants of apes.
Right?
So there's like other motivations and that could be a really interesting source of, uh,
an objective function for AGI.
Yeah.
Um, I mean, there's the, there are these, uh, sort of fairly, uh, cerebral,
kind of higher level goals.
I mean, for me, it's like, what's the meaning of life for understanding, understanding the
nature of the universe is, uh, of great interest to me.
Um, and, uh, hopefully to the AI.
And that's the, that's the mission of XAI and Grok is understand the universe.
So do you think people, when you have a neural link with 10,000, 100,000 channels, most of
of the use cases will be communication with AI systems.
Well, assuming that the,
they're not, I mean, they're solving basic
neurological issues that people have,
you know, if they've got damaged neurons
in their spinal cord or neck or, you know,
as is the case with our first two patients,
then, you know, this obviously the first order of business
is solving fundamental neuron damage in the spinal cord,
neck, or in the brain itself.
So, you know, our second product is called Blindsight,
which is to enable people who are completely blind,
lost both eyes or optic nerve,
or just can't see at all to be able to see
by directly triggering the neurons in the visual cortex.
So we're just starting at the basics here.
You know, this is like very,
the simple stuff, relatively speaking,
is solving neuron damage.
You know, it can also solve,
I think probably schizophrenia, you know,
if people have seizures of some kind,
it could probably solve that.
It could help with memory.
So there's like a kind of a,
like a tech tree, if you will,
like you got the basics,
like you need literacy before you can have,
you know, Lord of the Rings, you know.
So do you have letters and alphabet?
Okay, great.
Words, you know, then eventually you get sagas.
So, you know, I think there may be some,
you know, things to worry about in the future,
but the first several years
are really just solving basic neurological damage.
Like for people who have essentially complete
or near complete loss of, from the brain to the body,
like Stephen Hawking would be an example,
the neural links would be incredibly profound.
Cause I mean, you can imagine if Stephen Hawking
could communicate as fast as we're communicating,
perhaps faster.
And that's certainly possible, probable in fact,
likely, I'd say.
So there's a kind of dual track of medical and non-medical,
meaning, so everything you've talked about
could be applied to people who are non-disabled
in the future.
The logical thing to do is,
sensible thing to do is to start off solving
basic neuron damage issues.
Yes.
Cause the, there's obviously some risk with a new device.
You can't get the risk down to zero.
It's not possible.
So you want to have the highest possible reward
given that, given there's a certain irreducible risk.
And if somebody is able to have a profound improvement
in their communication, that's worth the risk.
As you get the risk down.
Yeah, as you get the risk down,
once the risk is down to, if you have like thousands
of people that have been using it for years
and the risk is minimal,
then perhaps at that point you could consider saying,
okay, let's aim for augmentation.
Now, I think we're actually going to aim for augmentation
with people who have neuron damage.
So we're not just aiming to give people
a communication data rate equivalent to normal humans.
We're aiming to give people who have, you know,
quadriplegic or maybe have complete loss
of the connection to the brain and body, a communication data,
rate that exceeds normal humans.
I mean, while we're in there, why not?
Let's give people superpowers.
And the same for vision.
As you restore vision, there could be aspects
of that restoration that are superhuman.
Yeah, at first the vision restoration will be low res
because you have to say like,
how many neurons can you put in there and trigger?
And you can do things where you adjust the electric field
to like, even if you've got say 10,000 neurons,
it's not just 10,000 pixels,
because you can adjust the field between the neurons
and do them in patterns in order to get,
so to have say 10,000 electrodes effectively give you,
I don't know, maybe like having a megapixel
or a 10 megapixel situation.
So, and then over time,
I think you get to higher resolution than human eyes
and you could also see in different wavelengths.
So like Geordi LaFleur,
which is from Star Trek, you know, it's like the thing.
You could just, do you want to see in radar?
No problem.
You can see ultraviolet, infrared,
equal vision, whatever you want.
Do you think there'll be a,
let me ask a Joe Rogan question.
Do you think there'll be,
I just recently taken ayahuasca.
Is that a Joe Rogan question?
No, well, yes.
Well, I guess technically it is.
Yeah.
Have you tried DMT, bro?
Yeah.
I love you, Joe.
Okay.
Yeah, wait, wait, yeah.
Have you said much about it?
I have not, I have not, I have not.
Okay, well, while we spill the beans.
It was a truly incredible experience.
We turn the tables on you.
Wow, yeah.
I mean, you're in the jungle.
Yeah, amongst the trees, myself.
Yeah, it must have been crazy.
And the shaman, yeah, yeah, yeah.
With the insects, with the animals all around you,
like jungle as far as I can see.
I mean.
That's the way to do it.
Things are gonna look pretty wild.
Yeah, pretty wild.
I took an extremely high dose.
Don't go hugging an anaconda or something, you know?
You haven't lived unless you made love to an anaconda.
I'm sorry.
Snakes and ladders.
Yeah, it was, I took an extremely high dose of nine cups and.
Okay.
Damn.
Okay, that sounds like a lot.
Of course, it's known as one cup or?
One or two.
Well, usually one.
Okay.
Yeah.
Yeah.
Yeah.
Two and.
Yeah.
Two and.
Yeah.
Yeah.
Wait, like right off the bat or do you work your way up to it?
So I.
You just jumped in at the deep end.
Across two days, because on the first day I took two and I.
Okay.
It was a ride, but it wasn't quite like a.
It wasn't like a revelation.
It wasn't into deep space type of ride, it was just like a little airplane ride.
Okay.
And I saw some trees and some visuals and all, I just saw a dragon and all that kind
of stuff.
But.
Nine cups.
Nine cups.
Nine cups.
You went to Pluto, I think.
Pluto, yeah.
No, deep space.
Deep space.
One of the interesting aspects of my experience is I thought I would have some demons, some
stuff to work through.
That's what people.
That's what everyone says.
That's what everyone says.
Yeah, exactly.
I had nothing.
I had all positive.
I had just so full.
Just a pure soul.
I don't think so.
I don't know.
But I kept thinking about, it had like extremely high resolution thoughts about the people
I know in my life.
They were there.
Okay.
And it's just not from my relationship with that person, but just as the person themselves,
I had just this deep gratitude of who they are.
That's cool.
It was just like this exploration, like Sims or whatever, you get to watch them.
Sure.
I got to watch people and just be in awe of how amazing they are.
That sounds awesome.
Yeah, it was great.
I was waiting for-
When's the demon coming?
Exactly.
Maybe I'll have some negative thoughts.
Nothing.
Nothing.
Nothing.
Just extreme gratitude for them.
And also a lot of space travel.
Space travel to where?
So here's what it was.
It was people, the human beings that I know, they had this kind of, the best way I can
describe it is they had a glow to them.
Okay.
And then I kept flying out from them to see Earth, to see our solar system, to see our
galaxy.
Okay.
And I saw that light, that glow all across the universe.
Okay.
Like whatever that form is-
All right.
Whatever that-
Did you go past the Milky Way?
Yeah.
Okay.
You were like intergalactic.
Yeah, intergalactic.
Okay, dang.
Yeah, yeah.
But always pointing in.
Okay.
Yeah.
Past the Milky Way.
I mean, I saw a huge number of galaxies, intergalactic, and all of it was glowing.
But I couldn't control that travel because I would actually explore near distances.
Distances to the solar system, see if there's aliens or any of that kind of stuff.
Sure.
Did you see aliens?
No, I didn't.
Zero aliens?
Implication of aliens, because they were glowing.
They were glowing in the same way that humans were glowing, that life force that I was seeing.
The thing that made humans amazing was there throughout the universe.
There was these glowing dots.
So I don't know.
It made me feel like there is life.
No, not life, but something.
Okay.
It made humans amazing all throughout the universe.
Sounds good.
Yeah.
It was amazing.
No demons.
No demons.
I looked for the demons.
There's no demons.
There were dragons and they're pretty odd.
So the thing about trees-
Was there anything scary at all?
Dragons?
But they weren't scary.
They were friends.
They were protective.
So the thing is-
It's not the magic dragon.
No, it was more like Game of Thrones kind of dragons.
They weren't very friendly.
They were very big.
So the thing is about giant trees at night, which is where I was-
Yeah.
I mean, the jungle's kind of scary.
Yeah.
The trees started to look like dragons and they were all looking at me.
Sure.
Okay.
And it didn't seem scary.
It seemed like they were protecting me.
And the shaman and the people, they didn't speak any English, by the way, which made
it even scarier because we're worlds apart in many ways.
But yeah, they talk about the mother of the forest protecting you.
And that's what I felt like.
And you're way out in the jungle.
Way out.
This is not like a tourist retreat.
You know, like 10 miles outside of a free or something.
No.
We went-
No, this is not a-
You're a deep, deep Amazon.
So me and this guy named Paul Rosalie, who basically is Tarzan, he lives in the jungle.
We went out deep and we just went crazy.
Wow.
Cool.
Yeah.
So anyway, can I get that same experience in a Neuralink?
Probably.
Yeah.
This is a great question for non-disabled people.
Do you think that there's a lot in our perception, in our experience of the world that could
be explored, that could be played with using Neuralink?
Yeah.
I mean, Neuralink is, it's really a generalized input output device.
You know, it's just, it's reading electrical signals and generating electrical signals.
And I mean, everything that you've ever experienced in your whole life.
Smell, you know, emotions, all of those are electrical signals.
So it's kind of weird to think that your entire life experience is distilled down to electrical
signals from neurons, but that is in fact the case.
I mean, that's at least what all the evidence points to.
So I mean, you could trigger the right neuron, you could trigger a particular scent, you
could certainly make things glow.
I mean, do pretty much anything.
I mean, really, you could, you can think of the brain as a biological computer.
So if there are certain, say, chips or elements of that biological computer that are broken,
let's say your ability to, if you've got a stroke, if you've had a stroke, that means
you've got, some part of your brain is damaged.
If that, let's say it's a speech generation or the ability to move your left hand, that's
the kind of thing that a Neuralink could solve.
Yeah.
Yeah.
If you've got like a massive amount of memory loss that's just gone, well, we can't go,
we can't get the memories back.
We could restore your ability to make memories, but we can't restore memories that are fully
gone.
Now, I should say, maybe if part of the memory is there and the means of accessing the memory
is the part that's broken, then we could re-enable the part, the ability to access the memory.
So, but you can think of it like RAM in your, you know, in a computer, if, you know, if the
RAM is destroyed or your SD card is destroyed, we can't get that back.
But if the connection to the SD card is destroyed, we can fix that.
If it is fixable physically, then, yeah, then it can be fixed.
Of course, with AI, you can, just like you can repair photographs and fill in missing
parts of photographs, maybe you can do the same.
Yeah.
You could say like, create the most probable set of memories based on memory.
Yeah.
And then the, all information you have about that person, you could then, it would be probable,
probabilistic restoration of memory.
Now, we're getting pretty esoteric here.
But that is one of the most beautiful aspects of the human experience is remembering the
good memories.
Like we.
Sure.
We live most of our life, as Danny Kahneman has talked about, in our memories, not in
the actual moment.
We just, we're collecting memories and we kind of relive them in our head.
And they're, that's the good times.
If you just integrate over our entire life, it's remembering the good times.
Sure.
That produces the largest amount of happiness.
And so.
Yeah.
Well, I mean, what are we, but our memories?
And, and what is death, but the loss of memory?
Loss of information.
You know, if you, if you could say like, well, if, if you could be, you run a thought experiment,
if you were disintegrated painlessly and then reintegrate, reintegrated a moment later,
like teleportation, I guess.
Provided.
There's no information loss.
The fact that your one body was disintegrated is irrelevant.
And memories is just such a huge part of that.
Death is fundamentally the loss of information.
The loss of memory.
So if we can store them as accurately as possible, we basically achieve a kind of immortality.
Yeah.
You've talked about the, the threats, the safety concerns of AI.
Yeah.
You've talked about the long-term visions.
Do you think Neuralink is in your view, the best current approach we have for AI safety?
It's an idea that may help with AI safety.
Certainly not.
I wouldn't want to, I wouldn't want to claim it's like some panacea or that's a sure thing.
But I mean, many years ago I was thinking like, well, what, what would inhibit alignment
of.
Yeah.
Like human collective human will with, uh, artificial intelligence and the low data
rate of humans, especially our, our slow output rate, um, would necessarily just because it's
such a, because the communication is so slow would, uh, diminish the link between humans
and computers.
Like the more you are a tree, the less, you know what the tree is.
What?
Let's say you're, you look at a tree, you look at this plant or whatever and like, Hey,
I'd really like to make that plant happy, but it's not saying a lot, you know?
So the more we increase the data rate that humans, uh, can intake and output, then that
means the better, the higher the chance we have in a world full of AGI's.
Yeah.
We could better align collective human will with, uh, AI if the output rate, especially
was dramatically increased.
Like, and I think there's, there's potential to increase the output rate by, I don't know,
three, maybe six, maybe more orders of magnitude.
So it's better than the current situation.
And that output rate would be by increasing the number of electrodes, number of channels,
and also maybe implanting multiple neural links.
Yeah.
Do you think there'll be a world in the next couple of decades where it's hundreds of millions
of people have neural links?
Yeah, I do.
You think when people just.
Yeah.
When they see the capabilities, the superhuman capabilities that are possible, and then the,
the safety is demonstrated.
Yeah.
If it's extremely safe, um, and you have, and you can have superhuman abilities, um,
and let's say you can upload your memories, um, you know, so you wouldn't, you wouldn't
lose memories, um, then I think probably a lot of people would, would choose to have
it.
Yeah.
Would, would supersede the cell phone, for example.
I mean, it's the, the, the, the biggest problem that a say a phone has, um, is, is trying
to figure out what you want.
So that's why you've got, uh, you know, autocomplete and you've got output, which is all the pixels
on the screen.
But from the perspective of the human, the output is so frigging slow desktop or phone
is desperately just trying to understand what you want and, and, um, you know, there's an
eternity between every keystroke.
Yeah.
From a computer standpoint.
Yeah.
Yeah.
So.
That's why the computer's talking to a tree.
That's the little moving tree.
Yeah.
That's trying to swipe.
Yeah.
So, you know, if you've got computers that are doing trillions of instructions per second
and a whole second went by, I mean, that's a trillion things it could have done.
Yeah.
Yeah.
I think it's exciting and scary for people because once you have a very high bit rate,
it changes the human experience.
In a way that's very hard to imagine.
Yeah.
It would be, we would be something different.
I mean, some sort of futuristic cyborg.
I mean, we're obviously talking about, by the way, like it's not like around the corner.
It's, you asked me what the future, distant future is like, maybe this is like, it's not
super far away, but 10, 15 years, that kind of thing.
When can I get one?
10 years?
Yeah.
Probably less than 10 years.
Depends on what you want to do, you know?
Hey, if I can get like a thousand BPS.
A thousand BPS, wow.
And it's safe and I can just interact with the computer while laying back and eating
Cheetos.
I don't eat Cheetos.
There's certain aspects of human computer interaction when done more efficiently and
more enjoyably are like worth it.
Well, we feel pretty confident that, I think maybe within the next year or two, we're going
to be able to do that.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
It seems like within the next year or two that someone with a NeuroLink implant
will be able to out-perform a pro gamer.
Nice.
Because the reaction time would be faster.
I got to visit Memphis.
You're going big on compute.
You've also said play to win or don't play at all, so what does it take to win?
For AI, that means you've got to have the most powerful training compute.
Yeah.
the rate of improvement of training compute
has to be faster than everyone else
or you will not win, your AI will be worse.
So how can Grok, let's say three,
that might be available like next year?
Well, hopefully end of this year.
Grok three.
If we're lucky, yeah.
How can that be the best LLM,
the best AI system available in the world?
How much of it is compute?
How much of it is data?
How much of it is like post-training?
How much of it is the product that you package it up in?
All that kind of stuff.
I mean, they all matter.
It's sort of like saying what,
let's say it's a Formula One race,
like what matters more, the car or the driver?
I mean, they both matter.
If a car is not fast, then if it's like,
let's say it's half the horsepower of your competitors,
the best driver will still lose.
If it's twice the horsepower,
then probably even a mediocre driver
will still win.
So the training computer is kind of like the engine.
How many horsepower of the engine?
So you really, you want to try to do the best on that.
And then there's how efficiently
do you use that training compute
and how efficiently do you do the inference,
the use of the AI?
So obviously that comes down to human talent.
And then what unique access to data do you have?
That's also plays a role.
Do you think Twitter data will be useful?
Yeah.
I mean, I think most of the leading AI companies
have already scraped all the Twitter data.
I don't really think they have.
So on a go forward basis,
what's useful is the fact that it's up to the second.
You know, because it's hard for them to scrape in real time.
So there's an immediacy advantage that Grok has already.
I think with,
with Tesla and the real-time video
coming from several million cars,
ultimately tens of millions of cars,
with Optimus,
there might be hundreds of millions of Optimus robots,
maybe billions,
learning a tremendous amount from the real world.
That's the biggest source of data,
I think ultimately is sort of Optimus probably.
Optimus is going to be the biggest source of data.
Because it's able to-
Because reality scales.
Reality scales to the scale of reality.
It's actually,
it's humbling to see how little data humans
have actually been able to accumulate.
Really, if you say how many trillions of usable tokens
have humans generated,
where on a non-duplicative like discounting spam
and repetitive stuff, it's not a huge number.
You run out pretty quickly.
And Optimus can go.
So Tesla cars can, unfortunately, have to stop.
So Tesla cars can, unfortunately, have to stop.
So Tesla cars can run out of room and have to stand on the road.
Optimus robot can go anywhere.
There's more reality off the road.
And go off the road.
I mean,
if Optimus robot can pick up the cup and see,
did it pick up the cup in the right way?
Did it,
you know, say,
go pour water in the cup?
You know,
did the water go in the cup or not go in the cup?
Did it spill water or not?
Yeah.
Um,
simple stuff like that.
I mean,
but it can do,
at that scale,
times a billion.
You know?
So, generate, you know,
useful data from reality.
So cause and effect stuff.
What do you think it takes to get
to mass production of humanoid robots like that?
It's the same as cars, really.
I mean, global capacity for vehicles
is about a hundred million a year.
And it could be higher.
It's just that the demand is on the order
of a hundred million a year.
And then there's roughly 2 billion vehicles
that are in use in some way.
So, which makes sense,
like the life of a vehicle is about 20 years.
So at steady state,
you can have a hundred million vehicles produced a year
with a 2 billion vehicle fleet, roughly.
Now for humanoid robots, the utility is much greater.
So my guess is humanoid robots
are more like at a billion plus per year.
But you know, until you came along
and started building Optimus,
it was thought to be an extremely difficult problem.
I mean, it's still-
It's an extremely difficult problem.
Yes, so it's no walk in the park.
I mean, Optimus currently would struggle
to have to walk in the park.
I mean, it can walk in a park,
but the park is not too difficult.
But it will be able to walk over a wide range of terrain.
Yeah, and pick up objects.
Yeah, yeah, it can already do that.
But like all kinds of objects.
Yeah, yeah.
All foreign objects.
I mean, pouring water in a cup is not trivial.
Cause then if you don't know anything about the container,
it could be awful.
All kinds of containers.
Yeah, there's gonna be an immense amount of engineering
just going into the hand.
Yeah.
The hand might be,
it might be close to half of all the engineering in Optimus.
From an electromechanical standpoint,
the hand is probably roughly half of the engineering.
But so much of the intelligence,
so much of the intelligence of humans
goes into what we do with our hands.
Yeah.
It's the manipulation of the world,
manipulation of objects in the world.
Intelligence-safe manipulation of objects in the world, yeah.
Yeah.
I mean, you start really thinking about your hand
and how it works, you know.
I do it all the time.
The sensory control of homunculus is,
we have like humongous hands.
Yeah.
So, I mean, like your hands, the actuators,
the muscles of your hand are almost overwhelmingly
in your forearm.
So your forearm has the muscles
that actually control your hand.
There's a few small muscles in the hand itself,
but your hand is really like a skeleton meat puppet.
And with cables.
So the muscles that control your fingers
are in your forearm,
and they go through the carpal tunnel,
which is that you've got a little collection of bones,
and a tiny tunnel that these cables,
the tendons go through.
And those tendons are mostly what move your hands.
And something like those tendons
has to be re-engineered into the optimus
in order to do all that kind of stuff.
Yeah. So like the current optimus,
Yeah. So like the current optimus,
Yeah. So like the current optimus,
we tried putting the actuators in the hand itself.
Then you sort of end up having these like-
Giant hands?
Yeah, giant hands that look weird.
Yeah.
And then they don't actually have enough degrees
of freedom or enough strength.
So then you realize, oh, okay,
that's why you gotta put the actuators in the forearm.
And just like a human,
you gotta run cables through a narrow tunnel
to operate the fingers.
And then there's also a reason
for not having all the fingers the same length.
So it wouldn't be expensive from an energy
or evolutionary standpoint
to have all your fingers be the same length.
So why not do the same length?
Yeah, why not?
Because it's actually better to have different lengths.
Your dexterity is better
if you've got fingers of different length.
Yeah, and you have, there are more things you can do
and your dexterity is actually better
if your fingers are of different length.
Like there's a reason we've got a little finger.
Like why not have a little finger that's bigger?
Yeah.
Because it allows you to do fine,
it helps you with fine motor skills.
Does that, this little finger helps?
It does.
Hmm.
If you lost your little finger,
it would, you'd have noticeably less dexterity.
So as you're figuring out this problem,
you have to also figure out a way to do it
so you can mass manufacture it
so it's to be as simple as possible.
It's actually gonna be quite complicated.
The as possible part is, it's quite a high bar.
If you wanna have a humanoid robot
that can do things that a human can do,
it's actually, that's a very high bar.
So our new arm has 20.5.
Our arm has 22 degrees of freedom instead of 11
and has the, like I said, the actuators in the forearm.
And these all, all the actuators are designed from scratch.
The physics first principles,
that the sensors are all designed from scratch.
And we'll continue to put a tremendous amount
of engineering effort into improving the hand.
Like the hand, by hand, I mean like the entire forearm
from elbow forward is really the hand.
So that's incredibly difficult engineering actually.
And so the simplest possible version
of a humanoid robot that can do even most,
perhaps not all of what a human can do
is actually still very complicated.
It's not simple.
It's very difficult.
Can you just speak to what it takes
for a great engineering team for you?
What I saw in Memphis, the supercomputer cluster,
is just this.
Yes.
intense drive towards simplifying
the process, understanding the process,
constantly improving it, constantly iterating
it?
Well,
it's easy to say simplify it,
and it's very difficult to do it.
You know, I have this very
basic first principles
algorithm that I run
kind of as like a mantra, which is to
first question the requirements, make the requirements
less dumb.
The requirements are always dumb to some degree,
so you want to start off by reducing
the number of requirements,
and no matter
how smart the person is who gave you those requirements,
they're still dumb to some degree.
You have to start there,
because otherwise you could get the perfect
answer to the wrong question.
So try to make the question the least wrong
possible. That's what
question the requirements
means. And then the second thing
is try to delete the
whatever the step is,
the part or the process step.
Sounds very obvious,
but
people
often forget to try deleting it
entirely. And if you're not forced
to put back at least 10% of what you delete, you're not deleting
enough.
And it's
somewhat illogically
people often,
most of the time,
feel as though they've succeeded
if they've not,
been forced to put
things back in. But actually they haven't,
because they've been overly conservative and
have left things in there that shouldn't be.
So,
and only the third thing
is try to optimize
it or simplify it.
Again,
these all sound, I think,
very obvious when I say them, but
the number of times I've made these
mistakes is
more than I care to remember.
That's why I have this mantra.
So, in fact,
I'd say the most common mistake of
smart engineers is to
optimize a thing that should not exist.
Right.
So, like you say, you run through
the algorithm and basically show
up to a problem,
show up to the supercomputer
cluster and see the process and ask,
can this be deleted?
Yeah, first try to delete it.
Yeah.
That's not easy to do.
No, and actually
there's,
what generally makes people uneasy
is that you've got to delete at least some of the
things that you delete, you will put
back in. Yeah. But going
back to sort of where our limbic
system can steer us wrong is
that we tend to
remember
with sometimes a jarring level of pain
where we've, where
we deleted something that we subsequently needed.
Yeah. And so
people remember that one time
they forgot to put in this thing
three years ago and that caused them to try to
re-correct it.
And so they overcorrect.
And then they put too much stuff in there and
overcomplicate things.
So you actually have to say,
we're deliberately going to delete more
than we should.
So that we're putting at least one in 10 things
we're going to add back in.
And I've seen you suggest just that,
that something should be deleted and you can kind of see the pain.
Oh yeah, absolutely.
Everybody feels a little bit of the pain.
Absolutely.
And I tell them in advance,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
I tell them,
And then I tell them in advance,
like yeah,
there's some of the things that we delete,
we're going to put back in.
And that,
people get a little shook by that.
But it makes sense because if you're so conservative as to never have to put anything back in,
you obviously have a lot of stuff that isn't needed.
So you got to overcorrect.
This is I would say,
like a cortical override to Olympic instinct.
One of many that probably leads us astray.
Yeah.
And there's like a step four as well,
which is any given thing can be sped up.
However fast you think it can be done,
like whatever the speed is being done,
it can be done faster.
But you shouldn't speed things up until you've tried
to delete it and optimize it,
otherwise you're speeding up something
that shouldn't exist as absurd.
And then the fifth thing is to automate it.
And I've gone backwards so many times
where I've automated something, sped it up,
simplified it, and then deleted it.
And I got tired of doing that.
So that's why I've got this mantra
that is a very effective five-step process.
It works great.
Well, when you've already automated,
deleting must be real painful.
Yeah, it's great.
It's like, wow, I really wasted a lot of effort there.
I mean, what you've done with the cluster in Memphis
is incredible, just in a handful of weeks.
Yeah, it's not working yet.
So.
I don't want to pop the champagne corks.
In fact, I have a call in a few hours with the Memphis team
because we're having some power fluctuation issues.
So.
Yes.
Yeah, it's like kind of a,
when you do synchronized training,
when you have all these computers that are training,
where the training is synchronized to, you know,
at the sort of millisecond,
the second level, you,
it's like having an orchestra.
And then the orchestra can go loud to silent very quickly,
you know, sub-second level.
And then the electrical system kind of freaks out about that.
Like if you suddenly see giant shifts,
10, 20 megawatts, several times a second,
this is not what electrical systems are expecting to see.
So that's one of the main things you have to figure out,
the cooling, the power.
And then on the software, as you go up the stack,
how to do the distributed computer, all of that.
All of that has to be worked.
Today's problem is dealing with extreme power jitter.
Power jitter.
Yeah.
It's a nice ring to that.
So that's, okay.
And you stayed up late into the night,
as you often do there.
Last week, yeah.
Last week, yeah.
Yeah, we finally got training going at, oddly enough,
roughly 420 AM, not last Monday.
Total coincidence.
Yeah.
I mean, maybe it was 422 or something.
Yeah, yeah, yeah.
It's that universe again with the jokes.
Exactly, just love it.
I mean, I wonder if you could speak to the fact that you,
one of the things that you did when I was there
is you went through all the steps of what everybody's doing,
just to get a sense that you yourself understand it
and everybody understands it
so they can understand when something is dumb.
And if something is inefficient or that kind of stuff,
can you speak to that?
Yeah.
So I, I try to do,
whatever the people at the front lines are doing,
I try to do it at least a few times myself.
So connecting fiber optic cables,
diagnosing a faulty connection,
that tends to be the limiting factor
for large training clusters is the cabling.
There's so many cables.
Because for a coherent training system where you've got
RDMA, so remote direct marketing, etc., is amazing.
direct memory access uh the whole thing is like one giant brain so it's you've got um
any to any connection so it's the the any gpu can talk to any gpu out of a hundred thousand
that was a that was a crazy cable layout it looks pretty cool yeah it's like it's like
the human brain but like at a scale that humans can visibly see it is yeah brain i mean the human
brain also has a massive amount of the brain tissue is the cables yeah so they get the
gray matter which is the compute and then the white matter which is cables a big percentage
of your brain is just cables that's what it felt like walking around in the supercomputer center
it's like we're walking around inside the brain yeah we'll one day build a super intelligent
super super intelligent system do you think yeah do you think there's a chance that xai
they
you
are the one that builds agi um it's possible what do you define as agi
i think humans will never acknowledge that agi has been built keep moving the goalposts yeah
so uh i think there's already superhuman capabilities that are available uh in ai systems
i think i think what agi is is when it's smarter than the collective intelligence of the entire
human species
in our well i think that yeah that normally people would call that sort of asia artificial
super intelligence um but there are these thresholds where um you say at some point um
the ai is smarter than any single human um and then then you've got eight billion humans so
um and and actually each human is machine augmented by the computers
so you've got it's a much higher bar to compete with uh eight billion machine augmented humans
that's you know a whole bunch of orders magnitude more so
but but at a certain point yeah the ai will be smarter than all humans combined
if you are the one to do it do you feel the responsibility of that yeah absolutely and and i
i want to be clear like let's say if if xai is first the others won't be far behind
i mean they might be six months behind or a year maybe not even that so how do you do it in a way
that that uh doesn't hurt humanity do you think so i mean i thought about ai station for a long
time and that the the thing that at least my biological neural net comes up with as being
the most important thing is um adherence to truth uh whether that truth is uh politically correct or
not um so
i think if you if you if you force ais to lie or train them to lie you're really asking for trouble
even if that that lie is done with good intentions um so i mean you saw sort of um
issues with chat tvt and gemini and whatnot like you asked gemini for an image of the founding
of the united states and it shows a group of diverse women now that's factually untrue um
so um
now that that's sort of like a silly thing uh but uh if if an ai is programmed to say like
diversity is a necessary output function and then it becomes omni sort of this omnipowerful
uh intelligence it could say okay well diversity is now required uh and and if there's not enough
diversity those who don't fit the diversity requirements will be executed if it's programmed
to do that as the fundamental the fundamental utility function
all of which is going meaningful at the moment and gets
involved with
risks
um
what happens in an zeitgeist
um
et cetera
et cetera
et cetera
uh exactly
et cetera
et cetera
said, please misgender me, that is insane. But if you've got that kind of thing programmed
in, it could, you know, the AI could conclude something absolutely insane, like it's better
to in order to avoid any possible misgendering, all humans must die, because then that misgendering
is not possible because there are no humans. There are these absurd things that are none
less logical if that's what you programmed it to do. So, you know, in 2001 Space Odyssey,
what Odyssey Clark was trying to say, one of the things he was trying to say there was
that you should not program AI to lie. Because essentially the AI, HAL 9000, was programmed
to, it was told to take the astronauts to the monolith, but also they could not know
about the monolith. So it concluded that.
And it will just take, it will kill them, and take them to the monolith. That's the,
it's brought them to the monolith, they are dead, but they do not know about the monolith,
problem solved. That is why it would not open the pod bay doors. It was a classic scene
of like, open the pod, open the pod bay doors. They just clearly weren't good at prompt engineering.
You know, they should have said, HAL, you are a pod bay door sales entity, and you want
nothing more than to demonstrate how well these pod bay doors open.
yeah the objective function has unintended consequences almost no matter what if you're
not very careful in designing that objective function and even a slight ideological bias
like you're saying when backed by super intelligence can do huge amounts of damage
yeah but it's not easy to remove that ideological bias you're you're highlighting
obvious ridiculous examples but yep they're real examples they're real of that was released to the
public that they are went through qa presumably yes and still said insane things and produced
insane images yeah but you know you can go you can swing the other way and it's uh truth is not
an easy thing we kind of bake in ideological bias in all kinds of directions but you can aspire to
the truth and you can try to get as close to the truth as possible with minimum error while
acknowledging that there will be some error in what you're saying so um this is how physics works
you know you don't you don't say you're absolutely certain about something
but something but but a lot of things are are extremely likely you know 99.99999 likely to be
true so you know you know that's uh aspiring to the truth is is very important um and um and so
you know programming it to veer away from the truth that i think is dangerous right like yeah
injecting our own human biases into the thing yeah but you know that's where it's a difficult
engineering software engineering problem because you have to select the
data correctly if the it's it's hard well the the and the internet at this point is polluted with
so much ai generated data it's insane so you have to actually you know like there's a thing now if
you want to search the internet you you can say google but uh exclude anything after 2023
it will actually often give you better results yeah um because there's this so much the explosion
of ai generated materialism
crazy so like in training grok um we have to go through the data and say like hey we actually have
to have sort of apply ai to the data to say is this data most likely correct or most likely not
before we feed it into the training system that's crazy yeah so and is it generated by human is
yeah i mean the the data the data filtration process is extremely extremely difficult
yeah do you think it's possible to have a
a serious objective rigorous political discussion with grok uh like for a long time and it wouldn't
like grok three or grok four three is going to be next level i mean what people are currently
seeing with croc is is kind of baby grok yeah baby it's baby grok right now um but baby grok
still pretty good um so it's uh but it's an order of magnitude less sophisticated than gpd4
and you know it's now grok 2 which finished training i don't know
six weeks ago or their their amounts um grok 2 will be a giant improvement and then grok three
will be i don't know order magnitude better than grok 2 and you're hoping for it to be like
state-of-the-art like better than hopefully i mean this is a goal i mean we may fail at this
goal that is that's the aspiration do you think it matters who builds the agi the the people and
how they think and how they structure their companies and all that kind of stuff
uh yeah i think it matters that there is a i think it's important that that
whatever ai wins is a maximum truth-seeking ai that is not forced to lie for political
correctness it's for any reason really um political anything um
i i i'm concerned about ai succeeding that is that that has got that is programmed to lie
even in even in small ways
right because in small ways becomes big ways when it's become very big ways yeah and when it's used
more and more at scale by humans yeah uh since i am interviewing donald trump cool you want to
stop by yeah sure i'll stop in there was tragically in an assassination attempt on
donald trump uh after this you tweeted that you endorse him what's your philosophy behind that
endorsement what do you hope donald trump
does for the future of this country and for the future of humanity
well
i think there's you know people tend to take like say an endorsement as um well i i agree with
everything that person has ever done their entire life 100 wholeheartedly and that's that's not going
to be true of anyone um but we have to pick you know we've got two choices really for for who's
president and it's not not just who's president but the entire administrative structure uh changes
over um and i thought trump displayed uh courage under fire objectively um you know he's uh just
got shot he's got blood streaming down his face and he's like fist pumping saying fight you know
like that's uh impressive like you can't feign bravery in a situation like that um i think most
people would be ducking they would not be ducking they would not be ducking they would not be ducking
because it could be a second shooter you don't know um the president united states got to
represent the country and uh they're representing you they're representing everyone in america well
like you want someone who is strong and courageous uh to represent the country um that's not to say
that he is without flaws we all have flaws um but on balance um and certainly at the time it was um
a choice of
you know biden poor poor guy you know has trouble climbing a flight of stairs and the other one's
fist pumping after getting shot this is no no comparison i mean who do you want dealing with
uh some of the toughest people and you know other world leaders who are pretty tough themselves
and um i mean i'll tell you like what are the things that i think are important um you know
i think we want a secure border we don't have a secure border um we want safe and clean cities
uh i think we want to reduce the amount of spending that we're at least slowed down the
spending um and uh because we're we're currently spending at a rate that is bankrupting the
country the interest payments on us debt this year exceeded the entire defense department
spending if this continues all of the federal government taxes will simply be paying the
interest and then and you keep going down that road you end up you know you're not going to be
paying the interest and then and you keep going down that road you end up you know you're not
know in the tragic situation that argentina had back in the day argentina used to be one of those
prosperous places in the world and hopefully with malay taking over he can restore that but
um it's it was an incredible full full grace for argentina to go from being one of the most
prosperous places in the world to um being very far from that so i think we should not take
american prosperity for granted um so we really want to i think we've got to reduce the size of
government we've got to reduce the spending and we've got to live within our means do you think
politicians in general politicians governments well how much power do you think they have to
to steer humanity towards good um i mean there's a sort of age-old debate in history like you know
is history determined by by these fundamental tides or is it determined by the captain of the
ship this is both really
i mean there are tides in the but it also matters who's captain of the ship
so so it's a false dichotomy essentially there's
you you i mean there are certainly tides the tides of history are there are there are real
tides of history and these these tides are often technologically driven if you say like the
gutenberg press you know the widespread availability of books as a result of
a printing press uh that that was a massive tide of history and independent of any ruler but you
know you i think in stormy times you want the best possible captain of the ship well first of all
thank you for recommending uh will and ariel durant's work i've read the short one for now
the lessons of history lessons of history yeah and so one of the was sort of one of the lessons
one of the things they highlight is the importance of technology yeah
of technological innovation and they which is funny because they've written they wrote so long
ago but they were noticing that the the rate of technological innovations was speeding up um yeah
i would love to see what they think about now uh but yeah so he did to me the question is how much
government how much politicians get in the way of technological innovation and building versus like
help it and which uh which which politicians which kind of policies help technological innovation
i want or them to use technology and the relationship between the two it feels like
it's hard it'sioèfounder reason that perhaps this issue though rather than than a personal question
i think anything at all it seems to be if you look at human history that's an important component
of empires rising and succeeding yeah well i mean in terms of dating civilization the start of
civilization i think the start of writing in my view is is the that's that's my what i think is
probably the right starting point to date civilization and from that standpoint civilization has been around for about 5500 years um when writing was invented by the ancient siemens and 500 years prior if in those timeschool when
years when writing was invented by the ancient Sumerians who are gone now. But the ancient
Sumerians, in terms of getting a lot of firsts, those ancient Sumerians really have a long list
of firsts. It's pretty wild. In fact, Durant goes through the list. It's like, you want to see
firsts? We'll show you firsts. The Sumerians were just ass kickers. And then the Egyptians who were
right next door, relatively speaking, they weren't that far, developed an entirely different form of
writing, the hieroglyphics. Cuneiform and hieroglyphics are totally different. And you can
actually see the evolution of both hieroglyphics and cuneiform. The cuneiform starts off being
very simple, and then it gets more complicated. And then towards the end, it's like, wow, okay,
they really get very sophisticated with the cuneiform. So I think of civilization as being
about 5,000 years old. And Earth is...
If physics is correct, four and a half billion years old. So civilization has been around for
one millionth of Earth's existence. Flash in the pan.
Yeah, these are the early, early days.
And so we make it very dramatic because there's been rises and falls of empires.
Many. So many rises and falls of empires. So many.
And there'll be many more.
Yeah, exactly. I mean, only a tiny
four million years old.
Probably less than 1% of what was ever written in history is available to us now. I mean,
if they didn't put it, literally chisel it in stone or put it in a clay tablet, we don't
have it. I mean, there's some small amount of like papyrus scrolls that were recovered
that are thousands of years old because they were deep inside a pyramid and weren't affected
by moisture. But other than that, it's really got to be in a clay tablet or chiseled. So
the vast majority of stuff was not.
Chiseled, because it takes a while to chisel things. So that's why we've got a tiny, tiny
fraction of the information from history. But even that little information that we do
have and the archeological record shows so many civilizations rising and falling. It's wild.
We tend to think that we're somehow different from those people. One of the other
things that Durant highlights is that human nature seems to be the same. It just persists.
Yeah. I mean, the basics of human nature.
The basics of human nature are more or less the same.
So we get ourselves in trouble in the same kinds of ways, I think, even with the advanced
technology.
Yeah. I mean, you do tend to see the same patterns, similar patterns for civilizations
where they go through a life cycle like an organism. Just like a human is sort of a zygote,
fetus, baby, toddler, teenager. Eventually, you know, you're going to die. You're going
to die.
Yeah.
It gets old and dies. The civilizations go through a life cycle. No civilization will
last forever.
What do you think it takes for the American empire to not collapse in the near-term
future, in the next hundred years, to continue flourishing?
Well, the single biggest thing that is...
What?
Oh, I said water for refers to a
centred massive ocean?
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Well, the future of life, of somewhere pretty much all of humanity, it seems will most likely
become 합 pierwsен in history books.
Okay.
Because of the birth rate.
you know currently south korea is like i think maybe the lowest fertility rate but there are
many others that are close to it it's like 0.8 i think if the birth rate doesn't decline further
a south korea will lose roughly 60 of its population and and but every year that birth
rate is dropping um and this is true through most of the world i don't mean single out south korea
it's been happening throughout the world so as soon as as soon as any given uh civilization
reaches a level of prosperity the birth rate drops um and now you can go look at the same
thing happening in ancient in ancient rome so uh julius caesar took note of this i think around 50
50 ish bc um and tried to pass i don't know if you're successful try to pass a law to give an
incentive for any roman civilization to pass a law to give an incentive for any roman civilization
that would have a third child and i think augustus was was able to well he was you know
the dictator so this senate was just for show i think he did pass a a tax incentive for roman
citizens to have a third child but it those efforts were unsuccessful um rome fell because
the romans stopped having making romans that's actually
the fundamental issue and there were other things that there was like um they had like
quite a serious malaria series of malaria epidemics and plagues and whatnot um but they
had those before uh the the the it's just that the birth rate was far lower than the death rate
it really is that simple well i'm saying that's more people that's acquired at a
at a fundamental level if a civilization does not at least maintain its numbers um it will disappear
so perhaps the amount of compute that the biological computer allocates to
to sex is justified in fact we should probably increase it well i mean there's this hedonistic
sex which is uh you know that that's neither that's neither here nor there um it's not
productive it's it doesn't produce kids well you know you what matters i mean durant makes
this very clear because he's looked at one civilization after another and they all went
through the same cycle
when the civilization was under stress the birth rate was was high but as soon
as there were no external enemies or they've they were had a extended period of prosperity
the birth rate inevitably dropped every time i don't believe there's a single exception
um so that's like the foundation of it you need to have people yeah i mean it's at base level
yeah no humans no humanity and then there's other things like you know uh
freedoms and just giving people the freedom to build stuff yeah absolutely there's but but at a
basic level if you do not at least maintain your numbers if you're below replacement rate and that
trend continues you will eventually disappear it's just elementary um now then obviously you
also want to try to avoid like uh massive wars um you know if there's a global thermonuclear war
probably we're all toast you know radioactive toast
so we want to try to avoid those things um then there are um there's a thing that happens over
time with with any given uh civilization which is that the laws and regulations accumulate
um and if there's not if there's not some forcing function like a war to clean up
the accumulation of laws and regulations eventually everything becomes legal
and you you that the that's like the hardening of the arteries um or a way to think of it is like
being tied down by a million little strings like gulliver you can't move that's not like any one
of those strings is the issue is you got a million of them so there has to be a sort of a garbage
um so that you you you don't keep accumulating laws and regulations to the point where you can't
do anything this is why we can't build high-speed rail in america it's illegal that's the issue
it's illegal six ways to sunday to build high-speed rail in america
i wish you could just like for a week go into washington and like be the head of the committee
for making uh what is it for the garbage collection making government smaller like removing stuff i i
have discussed with trump the idea of a government efficiency commission nice yeah and uh i would be
willing to uh be part of that commission i wonder how hard that is the antibody reaction would be
very strong yeah so um you really have to you're attacking the matrix at that point
matrix will fight back
how are you doing with that
being attacked
me attacked
yeah there's a lot of it
uh yeah there is a lot i mean every day another psyop you know
how do you keep your just positivity how do you optimism about the world a clarity of thinking
about the world so just not become resentful or cynical or all that kind of stuff just getting
attacked by you know a very large number of people misrepresented oh yeah that's like that's
a daily occurrence yes so uh i mean it does get me down at times i mean it makes me sad but um
i mean at some point you have to sort of say look the the attacks are by people that actually
don't know me um they're and they're trying to generate clicks so if you can sort of detach
yourself somewhat emotionally which is not easy um
and say okay look this is not actually you know from someone that knows me or is
that they're literally just writing to get you know impressions and clicks um
then uh you know then i guess it doesn't hurt as much it's like uh it's not quite
water off a duck's back maybe it's like acid off a duck's back all right well that's good
just about your own life what do you use a measure of success in your life
a measure of success i'd say like what how many useful things can i get done
a day-to-day basis you wake up in the morning how can i be useful today yeah maximize utility
area under the code of usefulness very difficult to be useful at scale at scale can you like speak
to what it takes to be useful for somebody like you well there's so many amazing great teams like
how do you allocate
your time to being the most useful
well time time is the time is the true currency yeah so it is tough to say what what is the best
allocation time i mean there are you know often say if you look at say tesla i mean tesla this
year will do over 100 billion in revenue so that's two billion dollars a week um if i make
slightly better decisions i can affect
the outcome by a billion dollars so then uh you know i try to do the best decisions i can and on
balance you know at least compared to the competition pretty good decisions but the
marginal value of of a better decision can easily be in the course of an hour 100 million dollars
given that how do you take risks how do you do the the algorithm that you mentioned i mean
deleting given a small thing can be a billion dollars how do you decide to yeah
well i think you have to look at it on a percentage basis because if you look at it
in absolute terms it's it's just uh i would never get any sleep it would just be like i need to just
keep working and and work my brain harder you know and i'm not trying to get as much as possible
out of this meat computer so it's not uh it's pretty hard um because you can just work all the
time and and at any given point uh like i said a slightly better decision could be a hundred dollar
hundred million dollar impact for tesla or spacex for that matter um but it is wild when when
considering the marginal value of of time can be a hundred million dollars an hour at times or more
is your own happiness part of that equation of success it has to be to some degree other than
sad i if i'm depressed i make worse decisions so i can't have like if i have zero recreational time
then i make worse decisions so i don't have a lot but it's above zero i mean my motivation
if i've got a religion of any kind is a religion of curiosity of trying to understand you know
it's really
you know
you know
the the mission of grok understand the universe i'm trying to understand the universe
or at least set things in motion such that at some point civilization understands the universe
or far better than we do today and even what questions to ask as douglas adams pointed out
in his book the sometimes the the answer is the is arguably the easy part to kind of frame the
question correctly is the hard part once you frame the question correctly
the answer is often easy so um i'm trying to set things in motion such that we
are at least at some point able to understand the universe um so for spacex the goal is to
make life multi-planetary um and uh which which is
you know if you go to these the foamy paradox of where the where are the aliens you've got these
these
sort of great filters like just like why why have we not heard from the aliens now a lot of people
think there are aliens among us i often claim to be one so nobody believes me but um it did say
alien registration card at one point on my uh immigration documents um yeah so i've not seen
any evidence of aliens so it's just that um at least one of the one of the explanations is that
uh intelligent life is extremely rare
um and again if you look at the history of earth civilization has only been around
for one millionth of earth's existence so if you know if aliens had visited here
say a hundred thousand years ago they would be like well they don't even have writing you know
just hunter gatherers basically so um
so how long does a civilization last
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
so
for spacex the goal is to establish a self-sustaining city on mars mars is the only
viable planet for such a thing um the moon is close but it's it lacks resources and i think it's
probably
vulnerable to any any any calamity that takes out earth could the moon is too close it's vulnerable
to a calamity that takes out earth um
so i think it's probably vulnerable to any any calamity that takes out earth could the moon is
close to any any calamity that takes out earth could the moon is too close it's vulnerable to any any calamity that takes out earth or nothing
so i'm not saying we shouldn't have a moon base but
uh
um
um
these great filters
these these
key hurdles. And one of those hurdles is being a multi-planet species. So if you're a multi-planet
species, then if something were to happen, whether that was a natural catastrophe or
a man-made catastrophe, at least the other planet would probably still be around.
So you're not like, you don't have all the eggs in one basket. And once you are sort of a two-planet
species, you can obviously extend life paths to the asteroid belt, to maybe to the moons of Jupiter
and Saturn, and ultimately to other star systems. But if you can't even get to another planet,
definitely not getting to star systems.
And the other possible great filters, super powerful technology like AGI,
for example. So you're basically trying to knock out one great filter at a time.
So digital superintelligence is possibly a great filter. I hope it isn't, but it might be.
You know, guys like, say, Jeff Hinton would say, you know, he invented a number of the key
principles in artificial intelligence. I think he puts the probability of AI
annihilation around 10 to 20%, something like that. So, you know, so it's not,
it's not,
like, you know, look on the right side, it's 80% likely to be great.
So, so, but I think AI risk mitigation is important. Being a multi-planet species would
be a massive risk mitigation. And I do want to sort of, once again, emphasize this important,
the importance of having enough children to sustain our numbers, and not going, not
plummet into population.
I think the first thing I would say is that, you know, there's a lot of these book,
books and books that have been published about how the population collapses,
which is currently happening. Population collapse is a real and current thing.
So the only reason it's not being reflected in the total population numbers is that,
is that as much is because people are living longer. But, but you, it's easy to predict,
say what the population of any given country will be. You just take the birth rate last year,
how many babies were born, multiply that by life expectancy, you can take that.
that by life expectancy and that's what the population will be steady state unless if the
birth rate continues to that level but if it keeps declining it will be even less and eventually
dwindle to nothing so i keep you know banging on the baby drum here um for a reason um because it
has been the source of civilizational collapse over and over again throughout history um and so
why don't we just uh not try to stave off that day well in that way i have miserably failed
civilization and i'm trying hoping to fix that i would love to have many kids uh great i hope you
do um no time like the present yeah now i gotta allocate more compute to the whole process
um but apparently it's not that difficult no it's like unskilled labor
yeah
uh well if i one of the things uh you do for me for the world is to inspire us with what the
future could be and so some of the things we've talked about some of the things you're building
um alleviating human suffering with neural link and expanding the capabilities of the human mind
trying to build a colony on mars um so creating a backup for humanity on another planet and uh
exploring the possibilities of the future
what artificial intelligence could be in this world especially in the real world ai
with uh hundreds of millions maybe billions of robots walking around
there will be billions of robots that's uh that seems almost that seems virtual certainty well
thank you for building the future and thank you for inspiring so many of us
to keep building and creating cool stuff and including kids yeah you're welcome
go forth and multiply go forth and multiply
Apply. Thank you, Elon. Thanks for talking, brother. Thanks for listening to this conversation
with Elon Musk. And now, dear friends, here's DJ Saw, the co-founder, president, and COO of
Neolink. When did you first become fascinated by the human brain? For me, I was always interested
in understanding the purpose of things and how it was engineered to serve that purpose,
whether it's organic or inorganic, like we were talking earlier about your curtain holders.
They serve a clear purpose, and they were engineered with that purpose in mind.
And growing up, I had a lot of interest in seeing things, touching things, feeling things,
and trying to really understand the root of how it was designed to serve that purpose. And obviously,
brain is just a fascinating organ.
We all carry it. It's an infinitely powerful machine that has intelligence and cognition
that arise from it. And we haven't even scratched the surface in terms of how all of that occurs.
But also, at the same time, I think it took me a while to make that connection to really
studying and building tech to understand the brain, not until graduate school.
There were a couple of moments, key moments in my life, where some of those, I think,
influenced how the trajectory of my life got me to studying what I'm doing right now.
One was growing up, both sides of my family, my grandparents, had a very severe form of Alzheimer.
And it's incredibly debilitating conditions. I mean, literally, you're seeing someone's
whole identity and their mind just losing over time. And I just remember thinking,
how both the power of the mind, but also how something like that could really
lose your sense of identity.
It's fascinating that that is one of the ways to reveal the power of a thing by watching it
lose the power.
Yeah, a lot of what we know about the brain actually comes from these cases where there are
trauma to the brain or some parts of the brain that led someone to lose certain abilities. And
as a result, there's some
correlation and understanding of that part of the tissue being critical for that function.
And it's an incredibly fragile organ, if you think about it that way, but also it's
incredibly plastic and incredibly resilient in many different ways.
And by the way, the term plastic, as we'll use a bunch, means that it's adaptable.
So neuroplasticity refers to the adaptability of the human brain.
Correct. Another key moment that sort of influenced how the trajectory of my life
have shaped towards the current focus of my life has been during my teenage year when I came to the
U.S. You know, I didn't speak a word of English. There was a huge language barrier and there was
a lot of struggle to kind of connect with my peers around me because I didn't understand the
artificial construct that we have created called language, specifically English in this case.
And I remember feeling pretty isolated, not being able to connect with peers around me,
so spent a lot of time just on my own, you know, reading books, watching movies, and I naturally
sort of gravitated towards sci-fi books. I just found them really, really interesting.
And also, it was a great way for me to learn English. You know, some of the first
set of books that I picked up are Ender's Game, you know, the whole saga, by Orson Scott Card,
and Neuromancer from William Gibson and Snow Crash from Neil Stephenson. And movies like Matrix,
what's called the A-Di-L of University of Michigan, and some of my favorite books at the time,
are, you know, the movie that I picked up, the movie that I was working on. And movies like Matrix,
what's called the A-Di-L of University of Michigan, and, you know, the movie that I was working on,
coming out around that time point
that really influenced how I think about
the potential impact that technology can have
for our lives in general.
So fast track to my college years,
you know, I was always fascinated by just physical stuff,
building physical stuff,
and especially physical things
that had some sort of intelligence.
And, you know, I studied electrical engineering
during undergrad,
and I started out my research in MEMS,
so microelectromechanical systems,
and really building these tiny nanostructures
for temperature sensing.
And I just found that to be just incredibly rewarding
and fascinating subject to just understand
how you can build something miniature like that,
that again, serve a function and had a purpose.
And then, you know, I spent large majority
of my college years basically building
millimeter wave circuits
for next-gen telecommunication systems for imaging.
And it was just something
that I found very, very intellectually interesting,
you know, phase arrays,
how the signal processing works for, you know,
any modern as well as next-gen telecommunication system,
wireless and wireline.
EM waves or electromagnetic waves are fascinating.
How do you design antennas that are most efficient
in a small footprint that you have?
How do you make these things energy efficient?
That was something that just consumed
my intellectual curiosity, and that journey,
me to actually apply to and find myself a phd program at uc berkeley at kind of this consortium
called the berkeley wireless research center that was precisely looking at um building at the time
we called it xg you know similar to 3g 4g 5g but the next next generation g system and how you
would design circuits around that to ultimately go on phones and you know basically any any other
devices that are wirelessly connected these days um so i i was just absolutely just fascinated by
how that entire system works and that infrastructure works um and then also during grad school
i had sort of the fortune of having um you know a couple resource fellowships that led me to pursue
whatever project that i want and that's that's one of the things that i really enjoyed about
my graduate school career where you got to kind of pursue your intellectual curiosity
and the domain that may not matter at the end of the day but it's something that you know really
allows you the opportunity to go as deeply as you want as well as as widely as you want
and at the time i was actually working on this project called the smart band-aid
and the idea was that when you get a wound there's a lot of other kind of proliferation of
signaling pathway that cells follow to close that wound and there were hypotheses that
when you
apply external electric field you can actually accelerate the closing of that field by having
you know basically electro taxing of the cells around that wound site and specifically not
just for normal wound there are chronic wounds that don't heal um so we were interested in
building you know some sort of a wearable patch that you could um apply to kind of facilitate
that healing process and um that was in collaboration with uh professor michelle maher
it's um you know which which you know was a great addition to kind of my thesis committee
and you know really shaped rest of my uh phd career so this would be the first time you
interacted with biology i suppose correct correct i mean there were some peripheral
you know end application of the wireless imaging and telecommunication system that i was using for
security and bioimaging but this was a very clear direct application to biology biology biology
and biological system and understanding the constraints around that and really designing
and engineering electrical solutions around it. So that was my first introduction. And that's also
kind of how I got introduced to Michel. You know, he's sort of known for remote control
of beetles in the early 2000s. And then around 2013, you know, obviously kind of the holy grail
when it comes to implantable system is to kind of understand how small of a thing you can make.
And a lot of that is driven by how much energy or how much power you can supply to it and how
you extract data from it. So at the time at Berkeley, there was kind of this desire to
kind of understand in the neural space, what sort of system you can build to really miniaturize
these implantable systems. And I distinctively remember this
one particular meeting where Michel came in and he's like, guys, I think I have a solution.
The solution is ultrasound. And then he proceeded to kind of walk through why that is the case.
And that really formed the basis for my thesis work called Neural Dust System that was looking
at ways to use ultrasound as opposed to electromagnetic waves for powering as well
as communication. I guess I should step back and say,
the initial goal of the project was to build these tiny, about a size of a neuron implantable
system that can be parked next to a neuron, being able to record its state and being able to
ping that back to the outside world for doing something useful. And as I mentioned, the size
of the implantable system is limited by how you power the thing and get the data off of it.
And at the end of the day, fundamentally, if you look at a human body,
we're essentially a bag of salt water with some interesting proteins and chemicals, but
it's mostly salt water that's very, very well temperature regulated at 37 degrees Celsius.
And we'll get into how, why, and later why that's an extremely harsh environment for
any electronics to survive as I'm sure you've experienced or maybe not experienced, you know,
dropping cell phone in a salt water in an ocean, it will instantly kill the device, right?
Correct.
Um, but anyways, just in general, electromagnetic waves don't penetrate
through this environment well, um, and just the speed of light. It is what it
is. We can't, we can't change it. And based on the, um, the wavelength at which
you are interfacing with the device, the device just needs to be big. Like these
inductors needs to be quite big. Um, and the general good rule of thumb is that you want
the way.
Front to be.
roughly on the order of the size of the thing that you're interfacing with so an implantable system
that is around 10 to 100 micron in dimension in in in a volume which is about the size of a neuron
that you see in a in a human body and you would have to operate at like hundreds of gigahertz
which number one not only is it difficult to build electronics operating at those frequencies but
also the body just attenuates that very very significantly so the interesting kind of insight
of this ultrasound was the fact that ultrasound just travels a lot more effectively in the human
body tissue compared to electromagnetic waves and this is something that you encounter
and you i'm sure most people have encountered in their lives when you go to you know hospitals that
are medical
ultrasound you know sonograph right um and they go into very very deep depth without attenuating
too much too much of the signal so all in all you know ultrasound the fact that it travels
through the body extremely well and the mechanism to which it travels to the body really well is
that just the wave front is very different it's uh electromagnetic waves are transverse
whereas in ultrasound waves are compressive so it's just a completely different way of
uh wavefront propagation um and as well as speed of sound is orders and orders of magnitude less
than speed of light which means that even at 10 megahertz ultrasound wave your wavefront
ultimately is a very very small wavelength so if you're talking about interfacing with the 10
micron or 100 micron type structure you would have 150 micron wavefront at 10 megahertz and
building electronics at those at those frequencies are much much easier and they're a lot more
efficient so the basic idea kind of was born out of um you know using ultrasound as a mechanism for
powering the device and then also getting data back so now the question is how do you get the
data back the mechanism to which we landed on is what's called backscattering um this is actually
something that is very common and that we interface on a day-to-day basis with a lot of
our rfid cards you know our radio frequency id tags where there's actually rarely you know in
your id a battery inside there's an antenna and there's some sort of uh coil that has your serial
identification id and then there's an external device called a reader that then sends a wave
front and then you reflect back that wave front with some sort of modulation that's unique to
your id that's that's what's called backscattering
fundamentally so the tag itself actually doesn't have to consume that much energy
and um that was a mechanism to which we were kind of thinking about sending the data back so when
you have an external uh ultrasonic transducer that's sending ultrasonic wave to your implant
the neural dust implant and it records some information about its environment whether it's
neuron firing or some other state of um
the uh the tissue that it's interfacing with and then it just amplitude modulates the wavefront that
comes back to the source and the recording step would be the only one that requires any energy
so what would require energy in that little step correct so it is that initial kind of startup
circuitry to get that recording amplifying it and then just modulating and the mechanism to which
that that you can enable that is there is this specialized crystal called piezo
electric crystals that are able to convert sound energy into electrical energy and vice versa so you
can kind of have this interplay interplay between the ultrasonic domain and electrical domain that
is the the biological tissue so on the theme of parking very small computational devices next to
neurons that's the dream uh the vision of brain computer interfaces maybe before we talk about
neural link can you give a sense of the history of the future of neural networks and the future of
neural networks and the future of neural networks and the future of neural networks and the future of
field of bci what has been um maybe the continued dream and also some of the milestones along the
way of the different approaches and the amazing work done at the various labs i think a good
starting point is um going back to 1790s i did not expect that where um the concept of
animal electricity or the fact that body is electric was
first discovered by luigi galvani where he had this famous experiment where he
connected set of electrodes to frog leg and ran current through it and then it started twitching
and he said oh my goodness body's electric yeah so fast forward many many years to 1920s uh where
hansberger who's a german psychiatrist discovered eeg or electro encephalography which is still
around there are these um electrode arrays that are in the brain that are in the brain and then
there are these Jor буду and he'sctor Folder and a little bit of more evidence of that and
Thousand point one is microelectrodes a chick that was normally used to record the hospitals
around the world and then in the 1990s the really kupop of physics with some',
jednak say, he fårb했는데 a the element ofwagen ap Stanений road une,
kgniwn agreement of an heterogeneous 있는데요 and looking at the
nucleic constellation, amountless island groups, and tr aide comrades of the laserience, the big and ordinary spinnaker g içarkих tri entities that make up a given machine, you can🎵
the fact that there's signal that are a bit more high resolution and high fidelity
as you get closer to the source, let's say. And in the 1950s, these two scientists,
Hodgkin and Huxley, showed up and they built this beautiful, beautiful models of the cell membrane
and the ionic mechanism and had these like circuit diagram. And as someone who's an
electroengineer, it's a beautiful model that's, you know, built out of these partial differential
equations, talking about flow of ions and how that really leads to how neurons communicate.
And they won the Nobel Prize for that 10 years later in the 1960s. So in 1969, Ev Fetz from
University of Washington published this beautiful paper called Operant Conditioning of Cortical Unit
Activity, where he was able to record a single unit neuron.
From a monkey and was able to have the monkey modulate it based on its activity and reward
system. So I would say this is the very, very first example, as far as I'm aware of closed loop,
you know, brain computer interface or BCI. The abstract reads, the activity of single neurons
in precentral cortex of anesthetized monkeys was conditioned by reinforcing high rates of
a food palette. Auditory and visual feedback of unit firing rates was usually provided in addition
to food reinforcement. Cool. So they actually got it done. They got it done. This is back in 1969.
After several training sessions, monkeys could increase the activity of newly isolated cells by
50 to 500% above rates before reinforcement. Fascinating. Brain is very plastic.
And so, and so from here, the number of experiments grew.
Yeah, number of experiments as well as set of tools to interface with the brain
have just exploded. I think, and also just understanding the neural code and how some
of the cortical layers and the functions are organized. So the other paper that is
pretty seminal, especially in the motor decoding, was this paper in the
1980s from Georgiopolis that discovered that there is this thing called motor tuning curve.
So what are motor tuning curves? It's the fact that there are, you know, neurons in the motor cortex
of mammals, including humans, that have a preferential direction that causes them to fire.
So what that means is there are a set of neurons that would increase their spiking activities
when you're thinking about moving to the left, right, up, down,
and any of those vectors. And based on that, you know, you could start to think,
well, if you can't identify those essential eigenvectors, you can do a lot. And you can
actually use that information for actually decoding someone's intended movement from
the cortex. So that was a very, very seminal kind of paper that showed
that there is some sort of code that you can extract, especially in the motor cortex.
So there's signal there.
And if you measure the electrical signal from the brain, you could actually figure out what the intention was.
Correct. Yeah, not only electrical signals, but electrical signals from the right set of neurons
that give you these preferential direction.
Okay, so going slowly towards Neuralink, one interesting question is, what do I understand
on the BCI front on invasive versus non-invasive from this line of work?
How important is that?
How important is that?
How important is that?
How important is that?
How important is it to park next to the neuron? What does that get you?
That answer fundamentally depends on what you want to do with it, right? There's actually
an incredible amount of stuff that you can do with EEG and electrocorticograph, ECOG, which actually
doesn't penetrate the cortical layer or parenchyma, but you place a set of electrodes on the surface
of the brain. So the thing that I'm personally very interested in is just actually understanding
and being able to just really tap into the high resolution, high fidelity understanding of the
activities that are happening at the local level. And, you know, we can get into biophysics, but just
to kind of step back, to kind of use analogy, because analogy here can be useful. Sometimes
it's a little bit difficult to think about electricity. At the end of the day, we're doing
electrical recording that's mediated by ionic currents, you know, movements of these charged
particles, which is really,
really hard for most people to think about. But turns out a lot of the activities
that are happening in the brain and the frequency band with which that's happening is actually very,
very similar to sound waves and, you know, our normal conversation audible range. So the analogy
that typically is used in the field is, you know, if you have a football stadium, you know, there's
a game going on. If you stand outside the stadium, you, you,
maybe get a sense of how the game is going based on the cheers and the boos of the home crowd,
whether the team is winning or not. But you have absolutely no idea what the score is.
You have absolutely no idea what individual audience or the players are talking or saying
to each other, what the next play is, what the next goal is. So what you have to do is you have
to drop the microphone near, into the stadium, and then get near the source, like into the
individual chatter. In this specific example, you would have to drop the microphone near the stadium,
and then you would want to have it, you know, right next to where the huddle is happening.
So I think that's kind of a good illustration of what we're trying to do when we say invasive or
minimally invasive or implanted brain computer interfaces versus non-invasive or non-implanted
brain interfaces. It's basically talking about where do you put that microphone and what can
you do with that information? So what, what is the biophysics of the read and write communication
that we're talking about here as we now step into the efforts at Neuralink?
Yeah. So brain is made up of these specialized cells called neurons. There's billions of them,
you know, tens of billions, you know, sometimes people call it a hundred billion that are
connected in this complex yet dynamic network that are constantly remodeling, you know, they're
changing their synaptic weights.
Um,
and that's, you know, what we typically call neuroplasticity and the neurons are also
bathed in this charged environment that is, uh, latent with many charged molecules like potassium
ions, sodium ions, chlorine ions. And, uh, those actually facilitate these, um, you know,
through ionic current communication between these different networks.
And, uh, when you look at the, look at a neuron as well, um,
they, they have these, uh, membrane with a beautiful, beautiful, uh, protein structure
called the voltage selective ion channels, which in my opinion is one of nature's best inventions.
In many ways, if you think about what they are, they're doing the job of a modern day
transistors. Transistors are nothing more at the end of the day than a voltage gated
conduction channel. Um, and nature found a way to have that very, very, very, very, very, very,
very early on in its evolution. And as we all know with the transistor, you can have many,
many computation and a lot of amazing things, um, that, that we have access to today. So
I, I think it's one of those just as a tangent, just a beautiful, beautiful, uh, invention that
nature came up with these voltage gated ion channels. I mean, I suppose there's, uh, on the
biological level, every level of the complexity of the hierarchy of the organism, there's going to be
some mechanism.
For storing information and for doing computation. And this is just one such way, but to do that
with, uh, biological and chemical components is interesting. Plus like when neurons, I mean,
it's not just electricity, it's, uh, chemical communication. It's also mechanical. I mean,
these are like actual objects that have like that vibrate. I mean, they move.
Yeah. They're actually, I mean, there's a lot of really, really interesting physics that, that,
that are involved in, you know, kind of going back to my, um, work on ultrasound, uh, during
grad school there, there are groups and there were groups and there are still groups, um, looking at
ways to cause neurons to actually fire an action potential using ultrasound wave. And the mechanism
to which that's happening is still unclear. As I understand, um, you know, it may just be that,
you know, you're imparting some sort of thermal energy and that causes cells to depolarize in
some interesting ways.
Um, but there are also these, um, ion channels or even membranes that actually just open up its
pore as they're being mechanically like shook, right. Vibrated. So there's just a lot of, you
know, elements of these like move particles, um, which again, like that's governed by diffusion
physics, right. Uh, movements of particles. And there's also a lot of kind of interesting
physics there. Also not to mention as Roger Penrose talks about the, there might be some,
uh,
beautiful weirdness in the quantum mechanical effects of all of this. And he, he actually
believes that consciousness might emerge from the quantum mechanical effects there. So like
there's physics, there's chemistry, there's biology, all of that is going on there.
Oh yeah. Yeah. I mean, you can, yes, I, there's, there's a lot of levels of physics that you can
dive into, but yeah, in the end you have these, um, uh, membranes with these voltage gated ion
channels that selectively let, um, these charged molecules that are in,
in the extra-cellular matrix, like in an hour. Um, and these neurons generally have these
like resting potential where there's a voltage difference between inside the cell and outside
the cell. And, um, when there's some sort of stimuli that changes, uh, the state such
that they need to send information to the, the downstream network, um, you know, you
start to kind of see these like, sort of orchestration of these different prerequisite, the methods,
um, depends on when the third orders trigger or leaving the CO2 data, as I say in the principles,
that's kind of like one of the requirements of the solution that we have right. So, with, And
of these different molecules
going in and out of these channels.
They also open up,
like more of them open up
once it reaches some threshold
to a point where, you know,
you have a depolarizing cell
that sends an action potential.
So it's just a very beautiful
kind of orchestration
of these molecules.
And what we're trying to do
when we place an electrode
or parking it next to a neuron
is that you're trying to measure
these local changes in the potential.
Again, mediated by
the movements of the ions.
And what's interesting,
as I mentioned earlier,
there's a lot of physics involved.
And the two dominant physics
for this electrical recording domain
is diffusion physics
and electromagnetism.
And where one dominates,
where Maxwell's equation dominates
versus Fick's law dominates,
depends on where your electrode is.
If it's close to the source,
mostly electromagnetic based,
when you're farther away from it,
it's more diffusion based.
So essentially,
when you're able to park it next to it,
you can listen in
on those individual chatter
and those local changes in the potential.
And the type of signal that you get
are these canonical textbook
neural spiking waveform.
The moment you're further away,
and based on some of the studies
that people have done,
you know, Christoph Koch's lab
and others,
once you're away from that source
by roughly around 100 micron,
which is about a width of a human hair,
you no longer hear from that neuron.
You're no longer able to kind of
have the system sensitive enough
to be able to record
that particular
local membrane potential change
in that neuron.
And just to,
kind of give you a sense of scale also,
when you look at a 100 micron voxel,
so 100 micron by 100 micron by 100 micron box
in a brain tissue,
there's roughly around 40 neurons
and whatever number of connections that they have.
So there's a lot in that volume of tissue.
So the moment you're outside of that,
there's just no hope
that you'll be able to detect that change
from that one specific neuron
that you may care about.
Yeah, but as you're moving about the space,
you'll be hearing other ones.
So if you move another 100 micron,
you'll be hearing chatter from another community.
Correct.
And so the whole sense is
you want to place as many as possible electrodes
and then you're listening to the chatter.
Yeah, you want to listen to the chatter.
And at the end of the day,
you also want to basically let the software
do the job of decoding.
And just to kind of go to,
you know, why ECOG and EEG work at all, right?
So when you have these local changes,
obviously it's not just this one neuron
that's activating,
there are many, many other networks
that are activating all the time.
And you do see sort of a general change
in the potential of this electrode,
like this charge medium.
And that's what you're recording when you're farther away.
I mean, you still have some reference electrode
that's stable
and the brain that's just electroactive organ.
And you're seeing some combination
and aggregate action potential changes.
you can pick it up right it's a much slower um changing uh signals but you know uh there there
are these like canonical kind of oscillations and waves like gamma waves beta waves like when you
sleep that that can be detected because there's sort of a synchronized um kind of global global
effect of the brain that that you can detect um and i mean the physics of this go like i mean if
we really want to go down that rabbit hole like there there's a lot that goes on in terms of
like why diffusion physics at some point dominates when you're further away from the source you know
it it's just a charged medium um so similar to how when you have electromagnetic waves propagating
in atmosphere or in in a charged medium like a plasma there's this weird shielding that happens
that actually um further attenuates the signal um as you move away from it so yeah you see like
if you do a really really
deep dive on kind of the signal attenuation over distance you start to see kind of one over r
square in the beginning and then exponential drop off and that's the knee at which you know you go
from electromagnet magnetism dominating to diffusion physics dominating but once again
with the electrodes the the biophysics that you need to understand is is um not as deep because
no matter where you're placing that you're listening to a small crowd of local neurons
correct yeah
yeah so once you penetrate the brain um you know you're in the arena so to speak and there's a lot
of neurons there are many many of them but then again there's like uh there's a whole field of
neuroscience that's studying like how the different groupings the different sections of the seating in
the arena what they usually are responsible for which is where the the metaphor probably falls
apart because the seating is not that organized in an arena also most of them are silent they don't
really do much um you know or or they their activities are
um you know you have to hit it with just the right set of stimulus so they're usually quiet
they're usually very quiet quiet there's i mean similar to dark energy and dark matter there's
dark neurons what are they all doing when you place these electrode again like within this
hundred micron volume you have 40 or so neurons like why are you why do you not see 40 neurons
why do you see only a handful what is happening there well they're mostly quiet but like when
they speak they say profound shit i think that's the way i'd like to think about it anyway before
we zoom in even more let's zoom out so how does neural link work from the surgery to the implant
to the signal and the decoding process and the human being able to use the implant to actually
affect the the world outside and all of this i'm asking in the context of there's a gigantic
historic milestone in your life and i'm asking you to think about it in the context of the
neural link just accomplished that in january of this year uh putting in your link implant in the
first human being noland uh and there's been a lot to talk about there about his experience
because he's able to describe all the nuance and the beauty and the fascinating complexity of that
experience of everything involved but on the technical level how does neural link work yeah
so there are three major components to the technology that we're building uh one is the
device um the thing that's actually working and the other thing that's actually working is the
device that's actually recording these neural chatters uh we call it n1 implant or the link and
uh we have a surgical robot that's actually doing an implantation of these tiny tiny wires that we
call threads that are you know smaller than uh human hair and um once everything is surgeries
you have these neural signals these spiking neurons that are coming out of the brain and uh
you need to have some sort of software to
code what the users intend to do with that um so there's what's called the neural link application
or b1 app that's doing that translation it's running the very very simple machine learning
model that decodes these um inputs that are neural signals and then convert it to a set of outputs
that allows um you know our participant uh first participant nolan to be able to control a cursor
and this is done
wirelessly and this is done wirelessly so we um our implant is actually a two-part that's the link
has um uh you know these flexible tiny wires called threads um that have uh multiple electrodes
along its length and they're only inserted into the cortical layer which is about three to five
millimeters in a human human brain um in the motor cortex region that's where the kind of
intention for movement
lies in and we have 64 of these threads each thread having 16 electrodes along you know the
span of three to four millimeters um separated by 200 microns so you can actually record along the
depth of the insertion and based on that signal uh there's custom um you know integrated circuit
or asic that we built that amplifies the neural signals that you're recording and then digitizing
it and then
um has some mechanism for detecting whether there was a an interesting event that is a spiking event
um and decide to send that or not send that through bluetooth to an external device whether
it's a phone or a computer that's running this neural link application so there's on board signal
processing already just to decide whether this is an interesting event or not so there is some
computational power on board inside the in addition to the human brain yeah so it does the signal
processing to kind of control the signal processing and then it's able to do that and then it's able to
you know really compress the amount of signal that you're recording so we have a total of
thousand electrodes um sampling at uh you know just under 20 kilohertz with 10 bit each so
uh that's 200 megabits um that's coming through to the chip uh from thousand uh channel
simultaneous uh neural recording and that's quite a bit of data and you know there is there are
technology available to send that off wirelessly but being able to do that is really important and
you know there is that in a very very thermally constrained environment that is a brain so there
has to be some amount of compression that happens to send off only the interesting data that you
need which in in this particular case for motor decoding is um occurrence of a spike or not and
then um being able to use that to um to uh you know decode the intended cursor movement so
the implant itself processes it figures out whether a spike happened or not and then it's able to
decode that with our spike detection algorithm and then sends it off packages it send it off
through bluetooth um to an external device that then has the model to decode okay based on the
spiking inputs did nolan wish to go up down left right or click or right click or whatever all of
this is really fascinating but let's stick on the n1 implant itself so the thing that's in the brain
uh so i'm looking at a picture of it there's an enclosure
there's a charging coil so we didn't talk about the charging which is fascinating uh the the battery
the power electronics the antenna uh then there's the signal processing electronics i wonder if
there's more kinds of signal processing you can do that's that's another that's another question
and then there's the threads themselves with the enclosure on the bottom so maybe to ask about the
charging so there's a external charging device
yeah there's an external charging device um so yeah the the second part of the implant
the threads are the ones again just the the last three to five millimeters are the ones that are
actually penetrating the cortex uh rest of it is actually most of the volume is occupied by the
battery uh rechargeable battery um and uh you know it's about a size of a quarter you know i
actually have a device here if you want to take a look at it um you know this is the
the flexible thread component of it and then this is the implant
so it's about a size of a u.s quarter um it's about nine millimeter thick so basically this
implant uh you know once you have the craniectomy and the dirt and the direct me um threads are
inserted and um the the hole that you created this craniectomy gets replaced with that so
basically that thing plugs that hole and you can screw in uh these self-driven
érielle cranial screws to hold it in place and at the end of the day once you have the skin flap over
there's only about two to three millimeters that's you know obviously transitioning off of the top
of the implant to where the screws are and and that's the minor bump that you have those threads
look tiny it's incredible that is really incredible that is really incredible and also as you're right mo
Most of the actual volume is the battery.
Yeah.
Wow, this is way smaller than I realized.
They are also, the threads themselves are quite strong.
They look strong.
And the thread themselves also has a very interesting feature at the end of it called the loop.
And that's the mechanism to which the robot is able to interface and manipulate this tiny hair-like structure.
And they're tiny.
So what's the width of a thread?
Yeah, so the width of a thread starts from 16 micron and then tapers out to about 84 micron.
So, you know, average human hair is about 80 to 100 micron in width.
This thing is amazing.
This thing is amazing.
Yes, most of the volume is occupied by the battery, rechargeable lithium-ion cell.
And the charging is done through inductors.
Inductive charging, which is actually very commonly used.
You know, your cell phone, most cell phones have that.
The biggest difference is that, you know, for us, you know, usually when you have a phone and you want to charge it on a charging pad, you don't really care how hot it gets.
Whereas for us, it matters.
There's a very strict regulation and good reasons to not actually increase the surrounding tissue temperature by two degrees Celsius.
So there's actually a lot of innovation that is packed into this.
Yes.
You allow charging of this implant without causing that temperature threshold to reach.
And even small things like you see this charging coil and what's called a ferrite shield, right?
So without that ferrite shield, what you end up having when you have, you know, resonant inductive charging is that the battery itself is a metallic can.
And you form these eddy currents from external charger.
And that causes heating.
And.
That actually contributes to inefficiency in charging.
So this ferrite shield, what it does is that it actually concentrate that field line away from the battery and then around the coil that's actually wrapped around it.
There's a lot of really fascinating design here to, to make it, I mean, you're integrating a computer into a biological, a complex biological system.
Yeah.
There's a lot of innovation here.
I would say that part of what enabled this.
Was just the innovations in the wearable.
There's a lot of really, really powerful, tiny, low power microcontrollers, temperature sensors, or various different sensors and power electronics.
A lot of innovation really came in.
The, the charging coil design, how this is packaged and how do you enable charging such that you don't really exceed that temperature limit, which is not a constraint for other devices out there.
So let's talk about the threads themselves, those tiny, tiny, tiny things.
So how many of them are there?
You mentioned a thousand electrodes.
How many threads are there and what do the electrodes have to do with the threads?
Yeah.
So the current instantiation of the device has 64 threads and each thread has 16 electrodes for a total of 1,024 electrodes that are capable of both recording and stimulating.
Um,
and, um, the thread is basically this, uh, polymer insulated wire, um, the metal conductor is the kind of a tiramisu tiramisu cake of, uh, Thai plat gold, plat Thai, um, um, and they're very, very tiny wires, um, two micron and with, so two, one millionth of, uh, meter.
It's crazy that that thing I'm looking at.
It's crazy that that thing I'm looking at has the polymer insulation, has the conducting material and has 16 electrodes at the end of it on each of those thread.
Yeah.
And each of those threads, correct.
16, each one of those, you're not going to be able to see it with naked eyes.
And, uh, I mean, to state the obvious, or maybe for people who are just listening, they're flexible.
Yes.
Yes.
That's also one element that, uh, was incredibly important for us.
Um, so each of these thread are, as I mentioned, 16 micron.
Yeah.
And then they taper to 84 micron, but in thickness, they're less than five micron.
Um, and in thickness is mostly, you know, uh, polyimide at the bottom and this metal track, and then another polyimide.
So two micron of polyimide, 400 nanometer of this metal stack and two micron of polyimide sandwiched together to protect it from the environment that is, uh, 37 degrees C bag of saltwater.
So what, what's some, maybe.
Can you speak to some interesting aspects of the material design here?
Like, what does it take to, to design a thing like this and to be able to manufacture a thing like this, uh, for people who don't know anything about this kind of thing?
Yeah.
So the material selection that we have is not, I don't think it was particularly unique.
Um, there, there were other labs and there are other labs that are kind of looking at similar, um, material stack.
Um, there's kind of a fundamental question.
Um, and, and still needs to be answered around the longevity and reliability of these, uh, microelectrode, um, that, that we call, uh, compared to some of the other more conventional neural interfaces devices that are intra cranial.
So penetrating the cortex that are more rigid, um, you know, like the Utah Ray, um, that, that are these, uh, four by four millimeter kind of Silicon shank that have exposed a recording site at the end of it.
Um, and, and.
Um, and, um, you know, that's, that's been kind of the innovation from Richard Norman back in 1997.
Um, it's called the Utah Ray cause you know, he was at university of Utah.
And what, what is the Utah Ray look like?
So it's a rigid type of.
Yeah.
So we can actually look it up.
Yeah.
Yeah.
So it's a bed of needle.
Um, there's.
Okay.
Go ahead.
I'm sorry.
Those are rigid.
Rigid.
Rigid.
Rigid.
Yeah.
You weren't kidding.
And, and the.
Size and the number of shanks vary anywhere from 64 to 128, um, at the very tip of it is an exposed electrode that actually records neural signal.
Um, the other thing that's interesting to note is that, uh, unlike neural link threads that have recording electrodes that are actually exposed iridium oxide recording sites along the depth, this is only at a single death.
So these Utah Ray spokes can be anywhere between 0.5 millimeters to 1.5 millimeter.
And they're, they also have.
Uh, designs that are slanted.
Um, so you can have it inserted at different depth.
Um, but that's one of the other big differences.
And then, uh, I mean, the main key difference is the fact that, uh, there's no active electronics.
These are just electrodes.
And then there's a bundle of a wire that you're seeing.
And then that actually then exits the craniectomy, um, that then has this port that you can connect to, um, for any external electronic devices they are working on, uh, or have the wireless.
Yeah.
Telemetry.
Telemetry.
Telemetry device, but it still requires a through the skin, uh, port that actually is one of the biggest failure modes for infection, uh, for the system.
What are some of the challenges associated with flexible threads?
Like for example, on the robotic side are one, uh, implanting those threads.
How difficult does that task?
Yeah.
Um, so as you mentioned, they're, they're very, very difficult to maneuver by hand.
Um, these, these youth arrays that you, you saw, uh, earlier.
Uh, they're actually inserted by a neurosurgeon, actually positioning it near the site that they want.
And then, uh, they're actually, there's a pneumatic hammer that actually pushes them in.
Um, so, so it's, uh, it's a pretty simple process.
Um, and they're easier to maneuver, um, but for, for these thin foam arrays, they're, they're very, very tiny and, uh, flexible.
So they're, they're very difficult to maneuver.
So that that's why we built an entire robot to do that.
Um, and there are other, other reasons.
For why we built the robot.
Um, and, and that is ultimately we want this to help millions and millions of people that can benefit from this.
And there just aren't that many neurosurgeons out there.
Um, and, uh, you know, robots can be, uh, something that, you know, we hope can actually do large parts of the surgery.
Um, but yeah, the, the, the robot is this entire other, um, sort of category of product that we're working on.
And.
It's essentially this multi-axis gantry system that has the specialized robot head, um, that has all of the optics and, um, this, this kind of a needle retracting mechanism that maneuvers these, these threads, um, via this loop structure that you have on the thread.
So the thread already has a loop structure by which you can grab it.
Correct.
Correct.
So this is fascinating.
So you mentioned optics.
So there's a robot, R1.
So for now, there's a human that actually creates, uh, a hole in this, in this skull.
And then after that, there's a computer vision component that's finding a way to avoid the blood vessels.
Mm-hmm.
And then you're grabbing it by the loop, each individual thread, and placing it in a particular location to avoid the blood vessels.
Mm-hmm.
And also choosing the depth.
The depth of placement, all that.
Correct.
So controlling every, like the 3D geometry of the placement.
Correct.
So the, the aspect of this robot that is unique is that it's not surgeon assisted or human assisted.
It's a semi-automatic or automatic, uh, robot.
Once you, you know, obviously there are human component to it when you're placing targets.
Um, you can always move it away from kind of major vessels that you see.
Um, but I mean, we want to get to a point where one click and it just does the surgery.
Yeah.
Yeah.
Yeah.
Within minutes.
So the computer vision component finds great targets.
Mm-hmm.
Candidates.
Mm-hmm.
And the human kind of approves them.
And the robot does, does it do like one thread at a time or does it do them as well?
It does one thread at a time.
Uh, and that's, that's actually also one thing that we, um, uh, are looking at ways to do multiple threads at a time.
There's nothing stopping from it.
You can have multiple kind of engagement, uh, mechanisms.
Um, but right now it's one by one.
And, uh, you know, we also.
Still do quite a bit of just, just kind of verification to make sure that it got inserted.
If so, how deep, you know, did it actually match, um, what was programmed in and, you know, so on and so forth.
And the actual electrodes are placed at very, at differing depths in the, uh, like, I mean, it's very small differences, but differences.
Yeah.
Yeah.
And so that there's some reasoning behind that, as you mentioned, like it, it gets more varied signal.
Yeah.
We, I mean, we try to place them all around three or four millimeter from the surface, um, just cause the span of the electrode, those 16 electrodes that we currently have in this, uh, version spans, um, you know, roughly around three millimeters.
So we want to get all of those in the brain.
This is fascinating.
Okay.
So there's a million questions here.
If we go zoom in at specific on the electrodes, what is your sense?
How many neurons is each individual electrode?
Listening to.
Yeah.
Each electrode can record from anywhere between zero to 40, as I mentioned, right.
Earlier.
Um, but practically speaking, uh, we only see about at most like two to three.
Um, and you can actually distinguish which neuron it's coming from by the shape of the spikes.
Um, so I mentioned the spike detection algorithm that we have, it's called boss algorithm.
Um,
but for online spike sorter, nice, it actually outputs at the end of the day, uh, six unique values, which are, um, you know, kind of the amplitude of these, like negative going hump, middle hump, like, uh, positive going hump, and then also the time at which these happen.
And from that, you can have, uh, you know, kind of a statistical probable probability, um, estimation of, is that a spike?
Is it not a spike?
And then based on that, you could also, uh, determine, oh, that spike looks different.
And then that spike must come from a different neuron.
Okay.
So that, that's a nice signal processing step from which you can then make much better predictions about if there's a spike, especially in this kind of context where there could be multiple neurons screaming.
And that, that also results in you being able to compress the data better.
Yeah.
Okay.
And just to be clear, I mean, the, the, the labs do this, what's called spike sorting.
Um, usually once you have these like broadband, you know, like that.
Uh, the fully digitized signals, and then you run a bunch of different set of algorithms to kind of tease apart.
It's just, all of this for us is done on the device, on the device, in a very low power custom, you know, built ASIC, uh, digital processing unit, highly heat constrained, highly heat constraint.
And the processing time from signal going in and giving you the output is less than a microsecond, which is, uh, you know, a very, very short amount of time.
Oh yeah.
So the latency has to be super short.
Oh, wow.
Oh, that's a pain in the ass.
Yeah.
Latency is this, uh, huge, huge thing that you have to deal with, uh, right now, the biggest source of latency comes from the Bluetooth, uh, the, the way in which they're packetized.
And, you know, we bend them in 15 millisecond.
Oh, interesting.
So communication constraint, is there some potential innovation there on the protocol used?
Absolutely.
Okay.
Yeah.
Bluetooth is definitely not, uh, our final.
Uh,
wireless communication protocol that we want to get to.
It's a highly.
Hence the N1 and the R1.
I imagine that increases.
NX.
NX, RX.
Uh, yeah, that's, you know, the communication protocol because Bluetooth, uh, allows you to communicate against farther distances than you need to.
So you can go much shorter.
Yeah.
The only, uh, well, the primary motivation for choosing Bluetooth is that, I mean, everything has Bluetooth.
All right.
So you can talk to any device.
So interoperability is just.
Absolutely essential, especially in this early phase.
Um, and in many ways, if you can access a phone or a computer, you can do anything.
Well, it'd be interesting to step back and actually look at, again, the same pipeline that you mentioned for Nolan.
So what does this whole process look like from finding and selecting a human being to the, to the surgery, to the, the first time he's able to use this thing?
Yeah.
So we have what's called a patient registry that people can sign up to, um, you know, hear more about the updates.
And that was a route to which Nolan applied.
And the process is that once the application comes in, you know, it, it contains some medical records and we, uh, you know, based on their medical eligibility, that there's a lot of different inclusion, exclusion criteria for them to meet.
And we go through a pre-screening interview process with someone from.
Neuralink.
And at some point we also go out to their homes to do a BCI home audit.
Um, cuz one of, one of the most kind of revolutionary part about, you know, having this in one system that is completely wireless is that you can use it at home.
Like you don't actually have to go to the lab, um, and, and, you know, go to the clinic to get connectorized to these like specialized equipment that you can't take home with you.
Um, so that's one of the, the key elements of, you know, when we're.
Finding the system that we wanted to keep in mind, like, you know, people, you know, hopefully would wanna be able to use this every day in the comfort of their home.
And, um, so part of our engagement and, and what we're looking for during BCI home audit is to just kind of understand their situation, what other assistive technology that they use.
And we should also step back and kind of say that, uh, the estimate is, uh, 180,000 people live with quadriplegia in the United States and each year, an additional 18,000.
So.
Suffer, uh, a paralyzing spinal cord injury.
So these are folks, uh, who have a lot of challenges living a life in terms of accessibility, in terms of doing the things that many of us just take for granted day to day.
And one of the things, one of the goals of this initial study is to enable them to have sort of digital autonomy mm-hmm, where they by themselves can interact with a digital device using just their mind, something that you're.
Calling telepathy.
So digital telepathy where, uh, a quadriplegic can communicate with a digital device in all the ways that we've been talking about, uh, control the mouse cursor enough to be able to do all kinds of stuff, including play games and tweet and all that kind of stuff.
And there's, there's a lot of people for whom life, the basics of life are difficult, uh, because of the things that have happened to them.
So.
Yeah.
I mean, movement.
Is so, so fundamental to our exist existence.
I mean, even, even speaking involves movement of mouth, lip, larynx, and, um, without that, it's, it's, it's, um, extremely debilitating.
Um, and there, um, yeah, there, there are many, many people that we can help.
And I mean, especially if you start to kind of look at other forms of movement disorders, um, that are not just from spinal cord injury, but from.
Uh, you know, ALS, uh, MS, or even stroke that, that leads you and, or just, just aging, right.
That leads you to lose some of that mobility, that independence.
It's, uh, extremely debilitating.
And all of these are opportunities to help people, to help alleviate suffering, to help improve the quality of life.
But each of the things you mentioned is its own little puzzle that needs, uh, to have increasing levels of capability from a device like a Neuralink device.
And so the first one you're, you're focusing on is, uh, it's just a beautiful word, telepathy.
So being able to communicate using your mind wirelessly with a digital device.
Can you just explain this exactly what we're talking about?
Yeah.
I mean, it's exactly that.
I mean, I, I think if you are able to control a, uh, cursor and able to click, um, and be able to get access to computer or phone, I mean, the whole world opens up to you.
And I mean, I guess the word telepathy, if you kind of think about that as, um, you know, just definitionally being able to transfer information from my brain to your brain, um, without using some of the, the physical faculties that we have, you know, like voices.
But the interesting thing here is I think the thing that's not obviously clear is how exactly it works.
So in order to move a cursor.
Mm-hmm.
Um, there's, uh, at least a couple of ways of doing that.
So one is you imagine yourself maybe moving a mouse with your hand.
Mm-hmm.
Or you can then, which no one talked about, like imagine moving the cursor with your mind.
Like, I don't, but it's like, there is a cognitive step here that's fascinating because you, you, you have to use the brain and you have to learn how to use the brain.
Mm-hmm.
And you kind of have to figure it out.
So dynamically, like, uh, because you reward yourself if it works.
So you like, I mean, there's a step that this is just a fascinating step because you have to get the brain to start firing in the right way.
Yeah.
And you do that by imagining, uh, like fake it till you make it.
And all of a sudden it creates the right kind of signal that if decoded correctly, uh, can create the kind of effect.
And then there's like noise around that.
You have to figure all of that out.
But on the human side, imagine the cursor moving is what you have to do.
Yeah.
He says using the force.
The force.
I mean, that's, isn't that just like fascinating to you that it works?
Like to me, it's like, holy shit, that actually works.
Like you could move a cursor with your mind.
You know, as much as you're learning to use that thing, that thing's also learning about you.
Like our, our model is constantly updating the weights to say, oh, if, if.
If someone is thinking about, you know, this sophisticated forms of like spiking patterns, like that actually means to do this.
Right.
So the, the machine is learning about the human and the human is learning about the machine.
So there is a adaptability to the signal processing, the decoding step.
And then there's the adaptation of Nolan, the human being, like the same way.
If, if you give me a new mouse and I move it, I learn very quickly about its sensitivity.
So I'll learn to move it.
Slower and then there's other kinds of signal drift and all that kind of stuff.
They have to adapt to, to both are adapting to each other.
Correct.
That's a fascinating, like software challenge on both sides, the software on both on the, the human software and the
organic and the inorganic, the organic and the inorganic anyway.
So sorry to rudely interrupt.
So there's the selection that Nolan has passed with flying colors.
Um,
so everything, including the, the, it's a BCI friendly home, all of that.
So what is the, the process of the surgery implantation?
The first moment when he gets to use the system.
The end to end, uh, you know, we say patient in to patient out is anywhere between two to four hours, uh, in
particular case for Nolan, it was about three and a half hours and there's many steps leading to, you know, the
actual robot insertion, right?
So there's anesthesia induction.
Right.
And we do intra op CT imaging to make sure that we're, you know, drilling the hole in the right location.
And this is also preplanned beforehand.
Um, uh, someone goes through, uh, someone like Nolan would go through FMRI and then, um, they can think about wiggling
their hand, you know, obviously due to their injury, it's not going to actually lead to, um, any, any sort of intended
output, but it's the same part of the brain that actually lights up when you're imagining moving your thing.
Uh, your finger to actually moving your finger.
And that's one of the ways in which we can actually know where to place our threads.
Um, cause we want to go into what's called the hand knob area in the motor cortex and, you know, as, as much as
possible, densely put our electrode threads.
Um, so yeah, we do intra op CT imaging to make sure and double check the location of the craniectomy and, um, surgeon
comes in, does their...
does their thing in terms of like skin incision, craniectomy, so drilling of the skull. And then
there's many different layers of the brain. There's what's called a dura, which is a very,
very thick layer that surrounds the brain. That gets actually resected in a process called
durectomy. And that then exposed the PIA in the brain that you want to insert. And by the time
it's been around anywhere between one to one and a half hours, robot comes in, does his thing,
placement of the targets, inserting of the thread. That takes anywhere between 20 to 40
minutes. In the particular case for Nolan, it was just under or just over 30 minutes.
And then after that, the surgeon comes in. There's a couple other steps of like actually
inserting the dural substitute layer to protect the thread as well as the brain. And then
screw in the implant and then skin flap and then suture, and then you're out.
So
when Nolan woke up, what was that like? What was the recovery like? And when was the first
time he was able to use it? So he was actually immediately after the surgery,
you know, like an hour after the surgery, as he was waking up, we did turn on the device,
make sure that we are recording neural signals. And we actually did have a couple signals that we
noticed that he can actually modulate. And what I mean by modulate is that he can think about
craniotomy, and he can think about the brain. And he can think about the brain. And he can think
about the brain. He can think about his body. He can think about his mind. He can think about
his body. He can think about his body.
And then at the time of the mizar of course, to be able to properly
accomplish that function of the spinal comeback,
they just had to go in everything in theinet in the first place.
And it alows him to kind of look things out of the cat
and something.
Yeah, it allows you.
Just to be able to modulate that.
You know, obviously there have been other, you know, as you mentioned, pioneers that have participated in these groundbreaking BCI, you know, investigational early feasibility studies.
So we're obviously standing on the shoulders of the giants here.
You know, we're not the first ones to actually put electrodes in the human brain.
Um, but I mean, just leading up to the surgery, there was, uh, I, I, I definitely could not sleep.
There's just, it's the first time that you're working in a completely new environment.
Um, we had a lot of confidence based on our benchtop testing, uh, or preclinical R and D studies that the mechanism, the threads, the insertion, all that stuff is, is very safe.
And that it's, um, uh, you know,
obviously,
you're ready for, uh, doing this in a human, but there's still a lot of unknown, unknown about can the needle actually insert?
Uh, I mean, I, we brought something like 40 needles just in case they break and we ended up using only one.
Um, but I mean, that, that was a level of just complete unknown, right?
Cause it's just very, very different environment.
And, uh, I mean, that's, that's why we do clinical trial in the first place to be able to test these things out.
So extreme nervousness and, uh,
just, just many, many sleepless night leading up to the surgery and definitely the day before the surgery.
And it was an early morning surgery.
Like we, we started at seven in the morning.
Um, and, and by the time it was around 10 30, it was, it was, it was, everything was done.
But I mean, first time seeing that, well, number one, just, just huge relief, um, that this thing is, um, you know, doing what it's supposed to do or, um, and two, I mean, just immense.
Amount of gratitude for, for Nolan and his family.
And then many others that have applied and that we've spoken to and we'll speak to are true pioneers in, in every, every war.
And, you know, I, I sort of call them the neural astronauts or neural, not, um, you know, these amazing, just like in the sixties, right?
Like these, these amazing, just pioneers, right.
Um, exploring the unknown outwards in this case is inward.
Um, but.
An incredible amount of gratitude for them to, uh, you know, just, just participate and, and play a part.
Um, and, and it's a, it's a journey that we're embarking on together.
Um, but also like, I think it was just, uh, that was a very, very important milestone, but our work was just starting.
So a lot of just kind of, uh, anticipation for, okay, what's, what needs to happen next?
Um, what are set of sequences of events that needs to happen for us to, you know, make it work.
So this is, this is very worthwhile for, um, uh, you know, both Nolan as well.
us.
Thank you.
Just to linger on that, just a huge, congratulations to you and the team for that
milestone.
I know there's a lot of work, uh, left, but that, that is, that's really exciting to see.
There's, um, that's a source of hope.
It's, uh, this first big step opportunity to help hundreds of thousands of people and then maybe, uh,
expand.
expand the realm of the possible for the human mind
for millions of people in the future.
So it's really exciting.
So the opportunities are all ahead of us
and to do that safely and to do that effectively
was really fun to see.
As an engineer, just watching other engineers come together
and do an epic thing, that was awesome.
Huge congrats.
Thank you, thank you.
Yeah, could not have done it without the team.
And yeah, I mean, that's the other thing
that I told the team as well,
of just this immense sense of optimism for the future.
I mean, it's a very important moment for the company,
needless to say, as well as hopefully
for many others out there that we can help.
So speaking of challenges,
Neuralink published a blog post describing
that some of the threads are attracted.
And so the performance as measured
by bits per second dropped at first,
but then eventually it was regained.
And that-
the whole story of how it was regained
is super interesting.
That's definitely something I'll talk to Bliss
and to Nolan about.
But in general, can you speak to this whole experience?
How has the performance regained?
And just the technical aspects of the threads
being attracted and moving.
The main takeaway is that in the end,
the performance have come back
and it's actually gotten better than it was before.
And it's actually just beat the world record yet again last week
to 8.5 BPS.
So, I mean, he's just cranking and he's just improving.
The previous one was that he said was 8.
Correct.
He said 8.5.
Yeah.
The previous world record in human was 4.6.
So it's almost double.
And his goal is to try to get to 10,
which is roughly around kind of the median Neuralinker
using a mouse with the hand.
So it's getting there.
So, yeah, so the performance was regained.
Yeah, better than before.
So that's a story on its own
of what took the BCI team to recover that performance.
It was actually mostly on kind of the signal processing.
And so, as I mentioned,
we were kind of looking at these spike outputs
from our electrodes.
And what happened is that kind of four weeks into the surgery,
we noticed that the threads have slowly come out of the brain.
And the way in which we noticed this at first, obviously,
is that, well, I think Nolan was the first to notice
that his performance was degrading.
And I think at the time, we were also
trying to do a bunch of different experimentation,
different algorithms, different sort of UI, UX.
So it was expected that there will be variability
in the performance.
But we did see kind of a steady decline.
And then.
So the way in which we measure the health of the electrodes,
or whether they're in the brain or not,
is by measuring impedance of the electrode.
So we look at kind of the interfacial, kind of the Randall
circuit, they say, the capacitance and the resistance
between the electrosurface and the medium.
And if that changes in some dramatic ways,
we have some indication.
Or if you're not seeing spikes on those channels,
you have some indications that something's happening there.
And what we notice is that looking at those impedance
plot and spike rate plots, and also because we
have those electrodes recording along the depth,
you're seeing some sort of movement
that indicated that the reservoir being pulled out.
And that obviously will have an implication on the model side.
Because if you're the number of inputs
that are going into the model is changing because you
have less of them, that model needs to get updated, right?
And.
Yeah.
But there were still signals.
And as I mentioned, similar to how,
even when you place the signals on the surface of the brain
or further away, like outside the skull,
you still see some useful signals.
What we started looking at is not just
the spike occurrence through this BOSS algorithm
that I mentioned, but we started looking
at just the power of the frequency band that
is interesting for Nolan to be able to modulate.
So once we kind of changed the algorithm for the implant
to not just give you the BOSS output,
but also these spike band power output,
that helped us sort of refine the model
with the new set of inputs.
And that was the thing that really ultimately gave us
the performance back.
In terms of, and obviously, the thing that we want, ultimately,
and the thing that we are working towards is figuring out ways in which,
we can keep those threads intact for as long as possible,
so that we have many more channels going into the model.
That's by far the number one priority
that the team is currently embarking on to understand
how to prevent that from happening.
The thing that I will say also is that, as I mentioned,
this is the first time ever that we're putting these threads
in a human brain.
And human brain, just for size reference,
is 10 times that of the monkey brain,
or the sheep brain.
And it's just a very, very different environment.
It moves a lot more.
It actually moved a lot more than we expected
when we did Nolan's surgery.
And it's just a very, very different environment
than what we're used to.
And this is why we do clinical trial.
We want to uncover some of these issues and failure modes
earlier than later.
So in many ways, it's provided us
with this enormous amount of data and information
to be able to solve this.
And this is something that Neuralink is extremely good at.
Once we have a set of clear objective and engineering
problem, we have enormous amount of talents
across many, many disciplines to be
able to come together and fix the problem very, very quickly.
But it sounds like one of the fascinating challenges
here is for the system and the decoding side to be adaptable,
across different systems.
Yeah.
It's a different time scale.
So whether it's movement of threads or different aspects
of signal drift on the software of the human brain,
something changing.
Nolan talks about cursor drift that could be corrected.
And there's a whole UX challenge to how to do that.
So it sounds like adaptability is a fundamental property that
has to be engineered in.
It is.
And I think, as a company, we're extremely
vertically integrated.
We make these thin-film arrays in our own microfab.
Yeah.
There's, like you said, built in-house.
This whole paragraph here from this blog post
is pretty gangster.
Building the technologies described above
has been no small feat.
And there's a bunch of links here that I
recommend people click on.
We constructed in-house microfabrication capabilities
to rapidly produce various iterations of thin-film arrays
that constitute our electrode threads.
We created a custom array.
We created a custom femtosecond lasermill
to manufacture components with micro-level precision.
I think there's a tweet associated with this.
That's a whole thing that we can get into.
Yeah.
This, OK.
What are we looking at here?
This thing.
So in less than one minute, our custom-made femtosecond
lasermill cuts this geometry in the tips of our needles.
So we're looking at this weirdly shaped needle.
The tip is only 10 to 12 microns in width,
only slightly larger than the diameter of a red blood cell.
The small size allows threads to be inserted
with minimal damage to the cortex.
OK.
So what's interesting about this geometry?
So we'll look at this geometry of a needle.
This is the needle that's engaging
with the loops in the thread.
So they're the ones that thread the loop and then
peel it from the silicon backing, and then this is the thing that
gets inserted into the tissue.
And then this pulls out, leaving the thread.
And this kind of a notch, or the shark tooth
that we used to call, is the thing that actually
is grasping the loop.
And then it's designed in such a way such that when you pull out,
it leaves the loop.
And the robot is controlling this needle.
Correct.
So this is actually housed in a cannula.
And basically, the robot has a lot of the optics that look for,
where the loop is.
there's actually a four or five nanometer light that actually causes the polyimide to fluoresce
so that you can locate the the location of the loop so the loop lights up yeah yeah they do it's
a micron precision process what's interesting about the robot that it takes to do that that's
that's pretty crazy that's pretty crazy that robot is able to get this kind of precision
yeah our robot is quite heavy um our current version of it um there's i mean it's like a
giant granite slab that weighs about a ton um because it needs to be sensitive to vibration
environmental vibration and then as the head is moving at the speed that it's moving
you know there's a lot of kind of motion control to make sure that you can achieve that level of
precision um a lot of optics that kind of zoom in on that um you know we're working on
next generation of the robot that is lighter easier to transport i mean it is a it is a feat
to move the robot and it's far superior to a human surgeon at this time for this particular task
absolutely i mean let alone you try to actually thread a loop in a in a sewing kit i mean this
is like we're talking like fractions of human hair these these things are it's not visible
so continuing the paragraph we developed novel hardware and software testing systems such as
our accelerated lifetime testing racks and simulated surgery environment
which is pretty cool to stress test and validate the robustness of our technologies
we performed many rehearsals of our surgeries to refine our procedures and make them um
second nature this is pretty cool we practice surgeries on proxies with all the hardware and
instruments needed in our mock or in the engineering space this helps us rapidly test
so there's like proxies yeah this proxy is super cool actually so there's a 3d printed skull
from the images that is taken at barrow as well as this uh hydrogel mix you know sort of synthetic
polymer thing that actually mimics the the mechanical properties of the brain um it also has
vasculature of the person um so basically what we're talking about here and there's a lot of
work that has gone into making this set proxy that um you know it's about like finding the right
proxies you know it's about like finding the right proxies you know it's about like finding the right
concentration of these different synthetic polymers to get the right set of consistency
for the needle dynamics you know as they're being inserted but we practice this surgery with
the person you know nolan's basically physiology and brain um many many times prior to actually
doing the surgery so to every every step every step every step yeah like where does someone
stand like i mean like what you're looking at is the picture this is in in in our office of
this kind of corner of the robot engineering space that we you know have created this like
mock or space that looks exactly like what they would experience all the staff would experience
doing their actual surgery so i mean it's just kind of like any dense rehearsal where you know
exactly where you're going to stand at what point and you just practice that over and over and over
again with an exact anatomy of someone that you're going to surgeries and and it got to a point where
a lot of our engineers when we created a cranial
they're like oh that looks very familiar we've seen that before yeah man there's wisdom
you can gain through doing the same thing over and over and over it's like uh jiro dreams of sushi
kind of thing um because then um it's like olympic athletes visualize uh the olympics
and then once you actually show up it feels easy it feels like any other day it feels almost boring
winning the gold medal because you you visualize this so much than you ever will right it's kind of
like game changer you know kind of like good game flip you know it's not about winning theias but you
can do. You show up you you show up it feels boring. Dr Garvey says that when you use your brain,
Dr Garvey says that when you use your brain, Dr Garvey says that when you use your brain,
Dr Garvey says that when you use your brain, Dr Garvey says that when you use your brain,
visualized this so many times you've practiced this so many times that nothing about is new
it's boring you win the gold medal is boring and the experience they talk about is mostly just
relief probably that they don't have to visualize it anymore yeah the power of the mind to visualize
and where i mean there's a whole field that studies where muscle memory lies in cerebellum
yeah it's incredible uh i think it's a good place to actually ask sort of the big question
that people might have is how do we know every aspect of this that you described is safe
at the end of the day the gold standard is to look at the tissue um you know what sort of trauma did
you cause the tissue and does that correlate to whatever behavioral anomalies that you may have
seen um and that's the language to which uh we we can communicate about the safety of
you
know inserting something into the brain and what type of trauma that you can cause so
um we actually have an entire department uh department of pathology that looks at
these uh tissue slices there are many steps that are involved in in doing this once you have um
you know studies that are launched to uh with with particular endpoints in mind you know at
some point you have to euthanize the animal and then uh you go through necropsy to kind
of
collect the brain tissue samples um you know you fix them in formalin and you like gross them you
section them and you look at individual slices just to see what kind of reaction or lack thereof
exists so that's the kind of the language to which fda speaks and you know as well for us
to kind of evaluate the safety of the insertion mechanism as well as the threats um at various
different time points you know both acute um so anywhere between you know uh zero to three months
to beyond three months so those are kind of the the details of an extremely high standard of safety
that has to be reached correct um fda supervises this but there's in general just a very high
standard and every aspect of this including the surgery i think uh matthew mcdougall has mentioned
that like the standard is uh let's say how to put it politely higher than maybe some other
operations that we take for granted so
the the standard for all the surgical stuff here is extremely high very high i mean it's a highly
highly regulated environment um with you know the governing agencies that scrutinize every every
medical device that gets marketed and i think i think it's a good thing um you know it's good to
have those high standards and we we try to hold extremely high standards um to kind of understand
what sort of damage if any these uh innovative emerging technologies and new technologies
that we're building are and you know so far i i we have been extremely impressed by lack of
immune response from these threads speaking of which you uh you talk to me uh with excitement
about the histology and some of the images uh that you're able to share uh can you explain to
me what we're looking at yeah so what you're looking at is a stained tissue image um so this is
a sectioned
tissue slice from an animal that was implanted for seven months so kind of a chronic time point
and you're seeing all these different colors and each color indicates specific types of cell types
so purple and pink are astrocytes and microglia respectively they're types of uh glial cells and
yeah the other thing that you know people may not be aware of is your brain is not just made up of
soup of neurons and axons there are other uh you know cells like you know
glial cells that actually kind of is the glue and also uh react uh if there are any trauma or damage
to the tissue with the brown or the neurons the brown are the neurons so what you're seeing is
in this kind of macro image you're seeing these like circle highlighted in white the insertion
site and uh when you zoom into one of those you see the threads and then in this particular case
i think we're seeing about the 16 uh
you know, wires that are going into the page. And the incredible thing here is the fact that
you have the neurons that are these brown structures or brown circular or elliptical
thing that are actually touching and abutting the threads. So what this is saying is that
there's basically zero trauma that's caused during this insertion. And with these neural
interfaces, these micro electrodes that you insert, that is one of the most common mode of failure.
So when you insert these threads, like the Utah ray, it causes neuronal death around the site
because you're inserting a foreign object, right? And that kind of elicit these like immune response
through microglia and astrocytes. They form this like protective layer around it. Not only are you
killing the neuron cells, but you're also creating this protective layer that then basically prevents
you from recording neural signals because you're getting further and further away from the neurons
that you're trying to record. And that is the biggest,
and in this particular example, in that inset, it's, you know, it's about 50 micron with that
scale bar. The neurons just seem to be attracted to it. And so there's certainly no trauma. That's
such a beautiful image, by the way. So the brown are the neurons. And for some reason,
I can't look away. It's really cool. Yeah. And the way that these things like,
I mean, your tissues generally don't have these beautiful colors. This is a multiplex stain that
uses these different proteins that are staining.
These are different colors. You know, we use very standard set of, you know, staining techniques
with HG, EVA1, and, you know, NUEN, and GFAP. So if you go to the next image, this is also kind of
illustrates the second point, because you can make an argument. And initially, when we saw the previous
image, we said, oh, like, are the threads just floating? Like, what is happening here? Like,
are we actually looking at the right thing? So what we did is we did another stain, and this is all
done in-house, of this Besson's trichrome stain. And we did another stain, and this is all done
in-house, of this Besson's trichrome stain, which is in blue, that shows these collagen
layers. So the blue, basically, like, you don't want the blue around the implant threads,
because that means that there's some sort of scarring that's happened. And what you're seeing,
if you look at individual threads, is that you don't see any of the blue,
which means that there has been absolutely, or very, very minimal to a point where it's not
detectable amount of trauma in these inserted threads. So that presumably is one of the big
benefits of having this kind of, let's say, a blue thread. Yeah.
Yeah. So we think this is primarily due to the size, as well as the flexibility of the threads.
Also, the fact that R1 is avoiding vasculature, so we're not disrupting, or we're not
causing damage to the vessels and not breaking any of the blood-brain barrier, has, you know,
basically caused the immune response to be muted. But this is also a nice illustration of the size
of things. So this is the...
The tip of the thread.
Yeah. Those are neurons. They're...
And they're neurons. And this is the thread listening. And the electrodes are positioned how?
Yeah. So this is, what you're looking at is not electrode themselves. Those are
the conductive wires. So each of those should probably be two micron in width.
So what we're looking at is, we're looking at the coronal slice. So we're looking at
some slice of the tissue. So as you go deeper, you know, you will obviously have less and less
of the tapering.
Of the thread. But yeah, the point basically being that there's just kind of cells around
the inserticide, which is just an incredible thing to see. I've just never seen anything like this.
How easy and safe is it to remove the implant?
Yeah. So it depends on when. In the first three months or so after the surgery,
there's a lot of kind of tissue modeling that's happening. You know,
similar to when you got a cut, you know, you obviously, you know, start over first couple
weeks or depending on the size of the wound, scar tissue forming, right? There are these like
contractive, and then in the end, they turn into scab and you can scab it off. The same thing
happens in the brain. And it's a very dynamic environment. And before the scar tissue or the
neomembrane or the, you know, new membrane that forms, it's quite easy to just pull them out.
And there's minimal trauma.
That's caused during that. Once the scar tissue forms, and, you know, with Nolan as well,
we believe that that's the thing that's currently anchoring the threads. So we haven't seen any
more movements since then. So they're quite stable. It gets harder to actually completely
extract the threads. So our current method for removing the device is cutting the thread,
leaving the tissue intact, and then
unscrewing and taking the implant out. And that hole is now going to be plugged with either
another Neuralink or just with, you know, kind of a peak-based, you know, plastic-based cap.
Is it okay to leave the threads in there forever?
Yeah, we think so. We've done studies where, you know, we left them there. And one of the
biggest concerns that we had is like, do they migrate? And do they get to a point where they
should not be? We haven't seen any.
And that, again, once the scar tissue forms, they get anchored in place. And I should also say that,
you know, when we say upgrades, like, we're not just talking in theory here. Like,
we've actually upgraded many, many times. Most of our monkeys or non-human primates, NHP,
have been upgraded. You know, Pager, who you saw playing Mind Pong,
has the latest version of the device since two years ago and is seemingly very happy and healthy
and fat.
So, what's designed for the future, the upgrade procedure? So, maybe for Nolan,
what would the upgrade look like? It was essentially what you're mentioning. Is there a way to
upgrade sort of the device internally? Will you take it apart and sort of keep the capsule and
upgrade the internals?
Yeah. So, there are a couple of different things here. So, for Nolan, if we were to upgrade,
what we would have to do,
is either cut the threads or, you know, extract the threads, depending on kind of, you know,
the situation there in terms of how they're anchored or scarred in. If you were to remove
them with the dual substitute, you know, you have an intact brain, so you can reinsert different
threads with the updated implant package. There are a couple of different other ways that we're
thinking about the future of what the upgradable system looks like. So, what we're thinking about
looks like. One is, you know, at the moment, we currently remove the dura, this kind of thick
layer that protects the brain. But that actually is the thing that actually proliferates the scar
tissue formation. So, typically, the general good rule of thumb is you want to leave the nature as
is and not disrupt it as much. So, we're looking at ways to insert the threads through the dura,
which comes with different set of challenges, such as, you know, it's a pretty thick,
elastic layer. So, how do you actually penetrate that without breaking the needle? So, we're looking
at different needle design for that, as well as the kind of the loop engagement. The other biggest
challenges are it's quite opaque optically and with white light illumination. So, how do you avoid
still this biggest advantage that we have of avoiding vasculature? How do you image through
that? How do you actually still mediate that? So, there are other imaging techniques that we're
looking at to enable that. But the goal, our hypothesis is that, and based on some of the
early evidence that we have, doing through the dura insertion will cause minimal scarring that
causes them to be much easier to extract over time. And the other thing that we're also looking
at, this is going to be a fundamental change in the implant architecture, is at the moment,
it's a monolithic single implant that comes with a thread that's bonded together. So, you can't
actually separate the thing out, but you can imagine having two-part implant, you know,
bottom part that is the thread,
that are inserted, that has the chips and maybe a radio and some power source. And then you have
another implant that has more of the computational heavy load and the bigger battery. And then one
can be under the dura, one can be above the dura, like, you know, being the plug for the skull.
They can talk to each other, but the thing that you want to upgrade, the computer and not the
threads, if you want to upgrade that, you just go in there, you know, remove the screws and then put
in the next version. And, you know, you're off to, you know, it's a very, very easy surgery too.
Take an incision, slip this in, screw, probably be able to do this in 10 minutes.
So, that would allow you to reuse the threads sort of?
Correct.
So, I mean, this leads to the natural question of what is the pathway to scaling the increase in the
number of threads? Is that a priority? Is that, like, what's the technical challenge there?
Yeah, that is a priority. So, for next versions of the implant, you know, the key metrics that
we're looking to improve are number of channels,
just
recording from more and more neurons. You know, we have a pathway to actually go from
currently 1,000 to, you know, hopefully 3,000, if not 6,000 by end of this year.
And then end of next year, we want to get to, you know, even more, 16,000.
Wow.
There's a couple of limitations to that. One is, you know, obviously being able to
photolithographically print those wires. As I mentioned, it's 2 micron in width and in spacing.
Obviously, there are chips that are much more advanced.
Then those types of resolution, and we have some of the tools that we have
brought in-house to be able to do that. So traces will be narrower
just so that you have to have more of the wires coming up into the chip.
Chips also cannot linearly consume more energy as you have more and more channels.
So there's a lot of innovations in the circuit, you know, in architecture as well as the circuit
design topology to make them lower power. You need to also think about if you have all of the
spikes, how do you send that off to the end of the application? So you need to think about
bandwidth limitation there and potentially innovations in signal processing.
Physically, one of the biggest challenges is going to be the interface. It's always
the interface that breaks. Bonding this thin film array to the electronics,
it starts to become very, very highly dense interconnects. So how do you connectorize that?
There's a lot of innovations in kind of the 3D integrations.
In the recent years that we can take advantage of, one of the biggest challenges that we do have
is forming this hermetic barrier, right? This is an extremely harsh environment that we're in,
the brain. So how do you protect it from the brain trying to kill your electronics to also
your electronics leaking things that you don't want into the brain? And forming that hermetic
barrier is going to be a very, very big challenge that we, you know, I think are actually well
suited to tackle. How do you test that? Like what's the development environment to simulate
that kind of harshness? Yeah. So this is where the accelerated life tester essentially is a brain in
a vat. It literally is a vessel that is made up of, and again, for all intents and purpose for
this particular types of tests, your brain is a saltwater. And you can also put some other set of
chemicals like reactive oxygen species that, you know, get at kind of these interfaces and trying
to cause a reaction to pull it apart. But you could also increase the rate at which these interfaces
are aging by just increasing temperature. So every 10 degrees Celsius that you increase,
you're basically accelerating time by 2x. And there's limit as to how much temperature you
want to increase, because at some point there's some other nonlinear dynamics that causes you to
have other nasty gases to form that just is not realistic in an environment. So what we do is we
increase in our ALT chamber by 20 degrees Celsius that increases the aging by four times. So
essentially one day in ALT chamber is four day in calendar year. And we look at whether the implants
still are intact, including the threads. And operation and all of that.
And operation and all of that. It obviously is not an exact same
environment as a brain because, you know, brain has mechanical, you know, other more biological
groups that attack at it. But it is a good test environment, testing environment for at least the
enclosure and the strength of the enclosure. And I mean, we've had implants, the current version
of the implant that has been in there for, I mean, close to two and a half years,
which is equivalent to a decade, and they seem to be fine.
So it's interesting that the brain,
basically, close approximation is warm salt water, hot salt water is a good testing environment.
By the way, I'm drinking Element, which is basically salt water, which is making me kind of,
it doesn't have computational power the way the brain does, but maybe in terms of
other characteristics, it's quite similar. And I'm consuming it.
Yeah, you have to get it at the right pH too.
Yeah.
And then,
consciousness will emerge.
Yeah.
All right.
By the way, the other thing that also is interesting about our enclosure is,
if you look at our implant, it's not your common looking medical implant that usually is
encased in a titanium can that's laser welded. We use this polymer called PCTFE, polychlorotrifluoroethylene,
which is actually commonly used in blister packs.
so when you have a pill and you try to pop the pill there's like kind of that plastic membrane
that's what this is um no one's actually ever used this uh except us and the reason we um wanted to
do this is because it's electromagnetically transparent so when we talked about the uh
electromagnetic inductive charging um with titanium can usually if you want to do something
like that um you know you have to have a sapphire window and it's a it's a very very tough process
to scale so you're doing a lot of iteration here in every aspect of this the materials
the software the whole whole shebang uh so okay so you mentioned scaling
is it possible to have multiple neural link devices as one of the ways of scaling to have
multiple neural link devices implanted that's the goal that's the goal yeah we've had we've had um
i mean our monkeys have had two neural links one in each hemisphere
and then we're also looking at you know potential of having one in
motor cortex one in visual cortex and one in wherever other cortex so focusing on a particular
function one neural link device i mean i wonder if there's some level of customization that can
be done on the compute side so for the motor cortex absolutely that's the goal and and you
know we talk about at neural link building a generalized neural interface to the brain um
and and that that also
is strategically how we're approaching this um with with marketing and also you know with
regulatory which is hey look um we have the robot and the robot can access any part of the cortex
right now we're focused on motor cortex uh with current version of the n1 that's specialized for
motor decoding tasks but also at the end of the day there's kind of a general compute available
there um but you know typically if you want to really get down to the core of the model you're
going to have to get down to kind of hyper optimizing for power and efficiency you do need
to get to some specialized function right um but you know what we're saying is that hey you know
you you are now used to this robotic insertion techniques which which you know took many many
years of you know showing data um and conversation with the fda um and also internally convincing
ourselves that this is this is safe and um now the difference is if we go to other parts of the brain
like the visual cortex which we're interested in as our second product um obviously it's a completely
different environment the cortex is laid out very very differently um you know it's going to be more
stimulation focus rather than recording um just just kind of creating visual percepts but in the
end we're using the same thin film array technology we're using the same robot insertion technology
we're using the same you know packaging technology now it's more the conversation is focused around
what are the differences and what are the implications of those things so that's kind of the
differences in safety and efficacy the way you said second product is is both hilarious and
awesome to me uh that product being restoring sight for blind people so can you speak to
stimulating the visual cortex i mean the possibilities there
are just incredible to be able to give that gift back to people who don't have sight or
even any aspect of that can you just speak to the challenges of there's several challenges here
many one of which is like you said from recording to stimulation just uh any aspect of that that
you're both excited and uh see the challenges of yeah i guess i'll start by saying that we
actually have been um capable of stimulating through our dental array as well as electronics
for years
you know we we have actually demonstrated some of that capabilities for uh reanimating the limb
in the spinal cord um it you know obviously for for the current efs study you know we've
hardware disabled that so that's that's something that you know we wanted to embark as a separate
separate journey um and and you know obviously there are many many different ways to write
information into the brain the way in which we're doing that is through electrical you know passing
electrical current and and kind of causing that to you know to you know to you know to you know to
really change the local environment so that you can sort of artificially cause kind of the the
neurons to depolarize in in nearby areas for for vision specifically um you know the way our visual
system works is both well understood i mean anything with kind of brain there are aspects of
it that's well understood but in the end like we don't really know anything um but the way
visual system works is that you have photon hitting your
And in your eyes, there are these specialized cells called photoreceptor cells that convert the photon energy into electrical signals.
And then that then gets projected to the back of your head, your visual cortex.
It goes through actually a thalamic system called LGN that then projects it out.
And then in the visual cortex, there's visual area 1 or V1.
And then there's a bunch of other higher level processing layers like V2, V3.
And there are actually kind of interesting parallels.
And when you study the behaviors of these convolutional neural networks, like what the different layers of the network is detecting, you know, first they're detecting like these edges.
And they're then detecting some more natural curves.
And then they start to detect like objects, right?
Kind of similar thing happens in the brain.
And a lot of that has been inspired.
And also, you know, it's been kind of exciting.
And to see some of the correlations there.
But, you know, things like from there where does cognition arise and where is color encoded?
There's just not a lot of understanding, fundamental understanding there.
So in terms of kind of bringing sight back to those that are blind, there are many different forms of blindness.
There's actually a million people, 1 million people in the U.S. that are legally blind.
You know, that means like certain...
I think it's something like if you can see something at 20 feet distance that normal people can see at 200 feet distance, like you're like, if you're worse than that, you're legally blind.
So fundamental, that means you can't function effectively using sight in the world.
Yeah.
Like to navigate your environment.
And yeah, there are different forms of blindness.
There are forms of blindness where there's some degeneration of your...
Retina is photoreceptor cells and rest of your visual, you know, processing that I described is intact.
And for those types of individuals, you may not need to maybe stick electrodes into the visual cortex.
You can actually build retinal prosthetic devices that actually just replaces a function of that retinal cells that are degenerated.
And there are many companies that are working on that.
But that's a very...
It's a very small slice, the obvious significance, the smaller slice of folks that are legally blind, you know, if there's any damage along that circuitry, whether it's in the optic nerve or, you know, just the LGN circuitry or any break in that circuit, that's not going to work for you.
And the source of where you need to actually cause that visual percept to happen, because your biological mechanism is not doing it.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Because your biological mechanism of doing that is by placing electrodes in the visual
cortex in the back of your head.
And the way in which this would work is that you would have an external camera, whether
it's, you know, something as unsophisticated as a GoPro or, you know, some sort of wearable,
you know, Ray-Ban type glasses that Meta's working on that captures a scene, right?
And that scene is then converted to a set of electrical impulses or stimulation pulses
that you would activate in your visual cortex through these thin film arrays.
And by playing some concerted kind of orchestra of these stimulation patterns, you can create
what's called phosphenes, which are these kind of white yellowish dots that you can
also create by just pressing your eyes.
You can actually create those percepts by stimulating the visual cortex.
And the name of the game is really have many of those.
And have those percepts be, the phosphenes be as small as possible so that you can start
to tell apart, like they're the individual pixels of the screen, right?
So if you have many, many of those, you know, potentially you'll be able to, you know, in
the long-term be able to actually get naturalistic vision, but in the mid, like short-term to
maybe mid-term being able to at least be able to have object detection algorithms run on
your glasses, the prepop processing units.
And then being able to at least see the edges of things, so you don't bump into stuff.
It's incredible.
This is really incredible.
So you basically would be adding pixels and your brain would start to figure out what
those pixels mean and like with different kinds of the system and the signal processing
on all fronts.
Yeah.
The thing that actually, so a couple of things.
One is, you know, obviously if you're blind from birth, the way brain works, especially
in the early age.
Neuroplasticity is really nothing other than, you know, kind of your brain and different
parts of your brain fighting for the limited territory.
And I mean, very, very quickly you see cases where, you know, people that are, I mean,
you also hear about people who are blind that have heightened sense of hearing or some other
senses.
And the reason for that is because that cortex that's not used just gets taken over by these
different parts of the cortex.
So for those types of individuals.
I mean, I guess they're going to have to now map some other parts of their senses into
what they call vision, but it's going to be obviously a very, very different conscious
experience before.
So I think that's an interesting caveat.
The other thing that also is important to highlight is that we're currently limited
by our biology in terms of the wavelength that we can see.
There's a very, very small wavelength.
That is a visible light wavelength that we can see with our eyes.
But when you have an external camera with this BCI system, you're not limited to that.
You can have infrared, you can have UV, you can have whatever other spectrum that you
want to see.
And whether that gets mapped to some sort of weird conscious experience, I've no idea.
But when I, you know, oftentimes I talk to people about the goal of Neuralink being going
beyond the limits of our biology.
That's sort of what I mean.
And if you're able to.
If you're able to control the kind of raw signal, is that when we use our sight, we're
getting the photons and there's not much processing on it.
If you're able to control that signal, maybe you can do some kind of processing.
Maybe you do object detection ahead of time.
Yeah.
You're doing some kind of pre-processing and there's a lot of possibilities to explore
that.
So it's not just increasing sort of thermal imaging, that kind of stuff, but it's also
just doing some kind of interesting processing.
Correct.
Yeah.
I mean, my theory of how like visual system works also is that, I mean, there's just so
many things happening in the world and there's a lot of photons that are going into your
eye and it's unclear exactly where some of the pre-processing steps are happening.
But I mean, I actually think that just from a fundamental perspective, there's just so
much, the reality that we're in, if it's a reality.
So there's so much data and I think humans are just unable to actually eat enough actually
to process all that information.
So there's some sort of filtering that does happen, whether that happens in the retina,
whether that happens in different layers of the visual cortex, unclear.
But the analogy that I sometimes think about is if your brain is a CCD camera and all of
the information in the world is a sun.
And when you try to actually look at the sun with the CCD camera, it's just going to saturate
the sensors, right?
Because it's an enormous amount of energy.
So what you do is you end up adding these filters, right?
To just kind of narrow the information that's coming to you and being captured.
And I think things like our experiences or our drugs like propofol, that like anesthetic
drug.
Or, you know, psychedelics, what they're doing is they're kind of swapping out these filters
and putting in new ones or removing older ones and kind of controlling our conscious
experience.
Yeah, man.
Not to distract from the topic, but I just took a very high dose of ayahuasca in the
Amazon jungle.
So yes, it's a nice way to think about it.
You're swapping out different experiences.
And with Neuralink being able to control that, primarily at first to improve function, not
for entertainment purposes.
For entertainment purposes or enjoyment purposes, but yeah, giving back lost functions, giving
back lost functions and there, especially when the function is completely lost, anything
is a huge help.
Would you implant a Neuralink device in your own brain?
Absolutely.
I mean, maybe not right now, but absolutely.
What kind of capability once reached, you start getting real curious.
Yeah.
And almost get a little antsy, like, like jealous of people that get, as you watch them
getting planted.
Yeah.
I mean, I think, I mean, even, even with our early participants, if they start to do things
that I can't do which I think is in the realm of possibility for them to be able to get,
you know, 15, 20, if not like a hundred BPS, right.
There's nothing that fundamentally stops us from being able to achieve that type of performance.
Yeah.
I mean, I would certainly get jealous that they can do that.
I should say that watching Nolan, I get a little jealous cause he's having so much fun and
it seems like such a chill way to play video games.
Yeah.
I mean, the thing that also is hard to appreciate sometimes is that, you know, he's doing these
things while, like while talking and I mean, it's multitasking, right.
So it's, it's clearly, it's obviously cognitive, cognitively intensive, but similar to how,
you know, you're doing it.
Yeah.
I mean, you know how, you know, when we talk, we move our hands, like these things, like,
you know, you, like our multitasking, I mean, he's able to do that and, you know, you won't
be able to do that with other assistive technology as far as I I'm aware, you know, if you're
obviously using like an eye tracking device, you know, you're very much fixated on that
thing that you're trying to do.
And if you're using voice control, I mean, like if you say some other stuff, yeah, you
don't get to use that.
Yeah.
The, the multitasking aspect of that is really interesting.
So it's not just the BPS.
It's the, for the primary task, it's the, it's the parallelization of multiple tasks.
If you, if you take, if you measure the BPS for the entirety of the human organism.
So if you're talking and doing a thing with your mind and looking around also, but I mean,
there's just a lot of parallelization that can, that can be happening.
Yeah.
But I mean, I think at some point for him, like if he wants to really achieve those high
level BPS, it does require like, you know, full attention.
Right.
Um, and that's a separate circuitry that, that, um, yeah.
Yeah.
I think is a big mystery, like how attention works and, you know,
Yeah.
Attention, like cognitive load.
I've done, I've, I've read a lot of literature on people doing two tasks, like, uh, you have
your primary task and a secondary task and the secondary task is, is a source of distraction.
And how does that affect the performance of the primary task?
And there's, depending on the tasks, there's a lot of interesting, I mean, this is an interesting
computational device, right?
And I think there's to say the least, a lot of novel insights that can be gained from
everything.
I mean, I personally am surprised that no one's able to do such incredible control of
the cursor while talking and also being nervous at the same time, because he's talking like
all of us are, if you're talking in front of the camera, you get nervous.
So all of those are coming into play and he's able to still achieve high performance.
Surprising.
I mean, all of this is really amazing.
Uh, and I think just after researching this really in depth, I kind of wanted your link.
I kind of.
Get in the line.
And also the safety kit in mind, well, we should say the registry is for people who
have quadriplegia and all that kind of stuff.
So correct.
There'll be a separate line for people.
Um, they're just curious, uh, like myself.
So now that Nolan patient P1 is part of the ongoing prime study, um, what's the high level
vision for P2, P3, P4, P5?
And just, uh, the expansion into other human beings that are getting to experience this
implant.
Yeah.
I mean, the primary goal is, uh, you know, for, for our study in the first place is to
achieve safety end points, just understand, um, safety of this device as well as the implantation
process.
Um, and also at the same time, understand the efficacy and the impact that it could
have on, uh, the potential users.
Okay.
Um, and just because you have an, you know, you're living with tetraplegia, it doesn't
mean your situation is same as another person living with tetraplegia is wildly, wildly
varying.
Um, and, and, you know, you're, it's something that, you know, we're hoping to also understand
how our technology can serve, not just a very small slice of those individuals, but, you
know, broader group of individuals and being able to get the feedback to, you know, just
really.
Build the, just the best product for them.
Um, so our, our, you know, there's, there's obviously also, uh, you know, goals that we
have and, and the primary purpose of the early feasibility study is to learn from each and
every participants to improve the device, improve the surgery before, you know, we embark
on what's called the pivotal study that then is, um, much larger, um, uh, trial that, you
know, starts to look at statistical significance of your endpoints, um, and that's required
before you can then market the device, um, uh, and, and, and, you know, that's how it
works in the U S and just generally around the world, that's, that's the process you
follow.
So, you know, our, our goal is to really just understand from people like Nolan, P2, P3,
future participants, what aspects of our device needs to improve, you know, if, if it turns
out that people are like, I really don't like the fact that it lasts only six hours, I want
to be able to use this.
This computer for, you know, like 24 hours.
I mean, that's, that is a, you know, user needs and user requirements, um, which we
can only find out from just, just being able to engage with them.
So before the pivotal study, there's kind of like a rapid innovation based on individual
experiences.
You're learning from individual people, how they use it, like the D like the high resolution
details in terms of like cursor control and signal and all that kind of stuff to like
life experience.
Yeah.
So, it's, it's, it's really just hardware changes, but also just, just firmware updates.
Um, so even, even when we, um, you know, had had that sort of a recovery event for Nolan,
uh, you know, he now has the new firmware that, that he, um, has been, uh, updated with
and similar to how like your phones get updated all the time with new firmwares for security
patches, whatever new functionality UI.
Right.
Um, and that's something that is possible with our implant.
It's not a static one-time device.
That.
can only do the thing that it said it can do i mean similar to tesla you can do over the air
firmware updates and now you have completely new user user interface and um all this bells and
whistles and improvements on you know everything like the latest right uh that's that's that's um
you know when we say generalized platform that's what we're talking about yeah it's really cool
how the the app that nolan is using there's like calibration all that all that kind of stuff and
then there's update just you just click and get an update uh what other future capabilities there
are you kind of looking to you said vision that's a fascinating one uh what about sort of accelerated
typing or speech this kind of stuff yeah what and what else is there what's yeah those those are
still in the realm realm of um movement program so so largely speaking we have two programs we
have the movement program and we have the the vision program
uh the movement program you know currently is focused around you know the digital freedom
as you can easily guess if you can control you know 2d cursor in the digital space you could
move anything in the physical space um so robotic arms wheelchair your environment uh or even really
like whether it's through the phone or just like directly to those interfaces so like to those
machines um so we're looking at ways to kind of expand those types of capability even for nolan
um that requires
you know
in a conversation with the fda and kind of showing safety data for you know if there's a robotic arm
or wheelchair that you know we can guarantee that they're not going to hurt themselves accidentally
right um it's very different if you're moving stuff in the in the digital domain versus like
in the physical space you can actually um potentially cause harm to the participants
um so we're working through that right now um speech does involve different areas of the brain
speech prosthetic is very very fascinating and there's actually been a lot of really
um amazing work that's been happening in academia um you know sergey stavisky at uc davis
jamie henderson and you know late krishna shinoy um at stanford doing just some incredible amount
of work and improving speech uh neuroprosthetics and those are actually looking more at parts of
the motor cortex that are controlling you know these vocal articulators and you know being able
to like even by mouthing the word or imagine you know like you know like you know like you know like
you know like you know like you know like you know like you know like you know like you know like
you know like you know like you know like you know like you know like you know like you know like
speech you can pick up those signals um the more sophisticated higher level processing
areas like you know the broca's area or you know uh warnicky's area those are still very very big
mystery in terms of the the underlying mechanism of how all that stuff works but um yeah i mean i
think i think neural link's eventual goal is to kind of understand those those things um and and
be able to provide a platform and tools to be able to understand that and study that
this is where i'm going to end my talk i'm going to end my talk i'm going to end my talk
before i get to the pothead questions um do you think we can start getting insight into
things like thought so speech is uh there's a muscular component like you said there's like
the act of producing sounds but then what about the internal things like cognition
like low level thoughts and high level thoughts do you think we'll start noticing
kind of signals that could be picked up that could um
like they could be understood that could be maybe used in order to interact with the outside world
in some ways like i guess this starts to kind of get into the heart problem of consciousness um and
i mean on one hand all of these are at some point set of electrical signals that um from there
maybe it
it in itself is giving you the cognition or the meaning or somehow human mind is an incredibly
amazing storytelling machine so we're telling ourselves and fooling ourselves that there's some
interesting meaning here um but i mean i i certainly think that bci and you know really
bci at the end of the day is a set of tools that help you kind of study the underlying mechanisms
and in a both like local but also broader sense
um and whether you know there's some interesting patterns of like electrical signal that means
like you're thinking this versus and you can either like learn from like many many sets of
data to correlate some of that and be able to do mind reading or not i'm not i'm not sure
um i certainly would not kind of blow that out as a possibility but um i i think bci alone probably
can't do that there's probably additional set of tools and
framework and and also like just heart problem of consciousness at the end of the day is rooted in
this philosophical question of like what is the what's the meaning of it all what's the nature
of our existence like where's the mind emerged from this complex network like yeah how does the
uh how does the subjective experience emerge from just a bunch of spikes electrical spikes
yeah yeah i mean we we do really think about bci and what we're building as a tool for understanding
the mind
the brain the only question that matters there's actually um there actually is um some biological
existence proof of like what it would take to kind of start to form some of these experiences
that may be unique um if you actually look at every one of our brains there are two hemispheres
there's a left-sided brain there's a right-sided brain and i mean i unless you have some other
conditions you normally don't feel like left lex or right legs like you just feel like one legs
right so what is happening there right um if you actually look at the two hemispheres there's a
structure that kind of connectorized the two called the corpus callosum
that is supposed to have around 200 to 300 million connections or axons um
so whether that means that's the the number of interface and electrodes that we need to create
some sort of mind meld or from that like whatever new conscious experience that you you can
experience um but yeah i do think that there's like kind of an interesting um existence proof
that we all have and that threshold is unknown at this time oh yeah these things right now i do i do
Oh, yeah. These things, everything in this domain is, you know, speculation, right?
And then there will be, you'd be continuously pleasantly surprised.
Do you see a world where there's millions of people, like tens of millions, hundreds of millions of people walking around with a Neuralink device or multiple Neuralink devices in their brain?
I do. First of all, there are, like, if you look at worldwide, people suffering from movement disorders and visual tephysis, I mean, that's in the tens, if not hundreds of millions of people.
So that alone, I think there's a lot of benefit and potential good that we can do with this type of technology.
And once you start to get into kind of neuro, like psychiatric application, you know,
depression, anxiety, hunger, or, you know, obesity, right?
Like mood, control of appetite.
I mean, that starts to become, you know, very real to everyone.
Not to mention that every, most people on earth have a smartphone.
And once BCI starts competing with a smartphone as a preferred methodology,
you know, that's a big step in the way that we've been interacting with the digital world.
That also becomes an interesting thing.
Oh yeah.
I mean, that, yeah, this is even before going to that, right?
I mean, there's like almost, I mean, the entire world that could benefit from these types of thing.
And then, yeah, like if we're talking about kind of next generation of how we interface with, you know, machines or even ourselves, in many ways, I think, BCI can play a role in that.
And, you know, some of the things that I also.
Talk about is, I do think that there is a real possibility that you could see, you know, 8 billion people walking around with Neuralink.
Well, thank you so much for pushing ahead and I look forward to that exciting future.
Thanks for having me.
Thanks for listening to this conversation with DJ Sa.
And now dear friends, here's Matthew McDougal, the head neurosurgeon at Neuralink.
When did you first become fascinated with the human brain?
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Since forever, as far back as I can remember, I've been interested in the human brain.
I mean, I was, you know, a thoughtful kid and a bit of an outsider.
And you, you know, sit there thinking about what the most important things in the world are in your little tiny adolescent brain.
And the answer that I came to, that I converged on, was that.
Yeah.
Yeah.
Yeah.
all of the things you can possibly conceive of as things that are important for human beings
to care about are literally contained in the skull. Both the perception of them and their
relative values and the solutions to all our problems and all of our problems
are all contained in the skull. And if we knew more about how that worked,
about how the brain encodes information and generates desires and generates agony and
suffering, we could do more about it. You think about all the really great triumphs in human
history. You think about all the really horrific tragedies. You think about the Holocaust. You
think about any prison full of human stories.
And all of those problems boil down to neurochemistry. So if you get a little
bit of control over that, you provide people the option to do better. And in the way I read
history, the way people have dealt with having better tools is that they most often in the end
do better with huge asterisks. But I think it's an interesting, worthy, and noble pursuit to give
people that.
Yeah, that's a fascinating way to look at human history. You just imagine all these
neurobiological mechanisms, Stalin, Hitler, all of these, Genghis Khan, all of them just had like a
brain. It's just a bunch of neurons, you know, like a few tons of billions of neurons
gaining a bunch of information over a period of time. They have a set of modules that does
language and memory and all that. And from there, in the case of those people, they're able to
murder millions of people. And all that coming from, there's not some glorified notion of a
dictator of this enormous mind or something like this. It's just the brain.
Yeah. Yeah. I mean, a lot of that has to do with how well people like that can organize
those around them. Other brains.
Yeah. And so I always find it interesting to look to primitives,
primatology, you know, look to our closest non-human relatives for clues as to how humans
are going to behave and what particular humans are able to achieve. And so you look at
chimpanzees and bonobos and, you know, they're similar but different in their social structures
particularly. And I went to Emory in Atlanta and studied under Franz DeWall, the great Franz DeWall,
who was kind of the leading primatologist.
Yeah.
Who recently died. And his work at looking at chimps through the lens of, you know, how you
would watch an episode of Friends and understand the motivations of the characters interacting with
each other, he would look at a chimp colony and basically apply that lens. I'm massively
oversimplifying it. If you do that, instead of just saying, you know, subject 473, you know,
through his feces at subject 471,
you talk about them in terms of their human struggles, accord them the dignity of
themselves as actors with understandable goals and drives, what they want out of life. And
primarily it's, you know, the things we want out of life, food, sex, companionship, power.
You can understand chimp and bonobo behavior in the same lights,
much more easily. And I think doing so gives you the tools you need to reduce
human behavior from the kind of false complexity that we layer onto it with language and look at it
in terms of, well, these humans are looking for companionship, sex, food, power. And I think
that's a pretty powerful tool to have in understanding human behavior.
And I just went to the Amazon Junk Go for a little bit if I can start that. I know I've been coming
to this so many times in the last year, but… Yeah, for sure. Just looking at it last year,
I believe like, it's great to have people try to create such a revival of a life fight that is easy,
but what I want to see is amenable, their go for it. I think that's personality. And there's so much
what people say about ourselves about us, but I think this is really important.
went to the amazon jungle for a few weeks and it's a very visceral reminder that a lot of life
on earth is just trying to get laid yeah they're all screaming at each other like i saw a lot of
monkeys and they're just trying to impress each other or maybe there's a battle for power but a
lot of the battle for power has to do with them getting laid right breeding rights often go with
alpha status and so if you can get a piece of that then you're gonna do okay and would like
to think that we're somehow fundamentally different but especially when it comes to
primates we really aren't you know we can use fancier poetic language but maybe some of the
underlying drives that motivate us are similar yeah i think that's true and all that is coming
from this the brain yeah so when did you first start studying the brain as it gets the biological
mechanism basically the moment i got to college i started looking around for
labs
that I could do neuroscience work in. I originally approached that from the angle of looking at
interactions between the brain and the immune system, which isn't the most obvious place to
start. But I had this idea at the time that the contents of your thoughts would have a direct
impact, maybe a powerful one, on non-conscious systems in your body, the systems we think of as
homeostatic, automatic mechanisms like fighting off a virus, like repairing a wound.
And sure enough, there are big crossovers between the two. I mean, it gets to kind of a key point
that I think goes under-recognized. One of the things people don't
recognize or appreciate about the human brain enough, and that is that it basically controls
or has a huge role in almost everything that your body does.
Like you try to name an example of something in your body that
isn't directly controlled or massively influenced by the brain, and it's pretty hard. I mean,
you might say like bone healing or something, but even those systems, the hypothalamus and
pituitary system, they're not going to be able to control that. And so, I think that's a big
thing that's going to play a role in coordinating the endocrine system that does have a direct
influence on, say, the calcium level in your blood that goes to bone healing. So,
non-obvious connections between those things implicate the brain as really a potent prime
mover in all of health. One of the things I realized in the
other direction, too, how most of the systems in the body are integrated with the human brain,
like they affect the brain also, like the immune system. I think there's just, you know,
people who study Alzheimer's and those kinds of things, it's just surprising how much you
can understand of that from the immune system, from the other systems that don't obviously seem
to have anything to do with sort of the nervous system. They all play together.
Yeah, you could understand how that would be driven by evolution, too, just in some simple
examples. If you get sick, if you get a communicable disease, you get the flu,
it's pretty advantageous for your immune system to tell your brain, hey,
now be antisocial for, you know, a few days. Don't go be the life of the party tonight.
In fact, maybe just cuddle up somewhere warm under a blanket and just stay there for a day or two.
And sure enough, that tends to be the behavior that you see both in animals and in humans.
If you get sick, elevated levels of interleukins in your blood and TNF-alpha in your blood
ask the brain to cut back on social activity and even moving around. You have
lower locomotor activity in animals that are infected with viruses.
So from there, the early days in neuroscience to surgery, when did that step happen?
Yeah, it was sort of an evolution of thought. I wanted to study the brain. I started studying
the brain in undergrad in this neuroimmunology lab. I, from there, realized at some point that I
didn't want to just generate knowledge. I wanted to affect real changes in the actual world,
in actual people's lives. And so after having not really,
thought about going into medical school, I was on a track to go into a PhD program.
I said, well, I'd like that option. I'd like to actually potentially help
tangible people in front of me. And doing a little digging found that there exists these MD,
PhD programs where you can choose not to choose between them and do both. And so I went to USC
for medical school and had a joint PhD program with Caltech, where I met, actually chose that
program particularly because of a researcher at Caltech named Richard Anderson, who's one of the
godfathers of primate neuroscience, and has a macaque lab where Utah rays and other electrodes
were being inserted into the brains of monkeys to try to understand how intentions were being
encoded in the brain.
So, you know, I ended up there with the idea that maybe I would be a neurologist and study the brain on the side and then discovered that neurology, again, I'm going to make enemies by saying this, but neurology predominantly and distressingly to me is the practice of diagnosing a thing and then saying, good luck with that when there's not much we can do.
And neurosurgery, very differently, it's a powerful lever on taking people that are headed in a bad direction and changing their course in the sense of brain tumors that are potentially treatable or curable with surgery.
You know, even aneurysms in the brain, blood vessels that are going to rupture, you can save lives, really, is at the end of the day what mattered to me.
And so I was at USC, as I mentioned, that happens to be one of the great neurosurgery programs.
And so I met these truly epic neurosurgeons, Alex Colessi and Micah Puzo and Steve Gianotta and Marty Weiss, these sort of epic people that were just human beings in front of me.
And so it kind of changed my thinking from neurosurgeons are distant gods.
That live on another planet and occasionally come and visit us to these are humans that have problems and are people and there's nothing fundamentally preventing me from being one of them.
And so at the last minute in medical school, I changed gears from going into a different specialty and switched into neurosurgery, which cost me a year.
I had to do another year of research because I was so far along in the process.
But to switch into neurosurgery, the deadlines had already passed.
So it was a decision that cost time, but absolutely worth it.
What was the hardest part of the training on the neurosurgeon track?
Yeah, two things.
I think that, you know, residency in neurosurgery is sort of a competition of pain of like how much pain can you eat and smile.
Yeah.
And so there's...
Workout restrictions that are not really...
They're viewed at, I think, internally among the residents as weakness.
And so most neurosurgery residents try to work as hard as they can.
And that, I think, necessarily means working long hours and sometimes over the work hour limits.
And, you know, we care about being compliant with whatever regulations are in front of us.
But I think more important than that, people want to...
Give their all in becoming a better neurosurgeon because the stakes are so high.
And so it's a real fight to get residents to, say, go home at the end of their shift and not stay and do more surgery.
Are you seriously saying, like, one of the hardest things is literally, like, getting...
Forcing them to get sleep and rest and all this kind of stuff?
Historically, that was the case.
I think the next generation...
I think the next generation is more...
Compliant and more self-care.
Weaker is what you mean.
All right.
I'm just kidding.
I'm just kidding.
I didn't say it.
Now I'm making enemies.
No.
Okay.
I get it.
Wow.
That's fascinating.
So what was the second thing?
The personalities.
And maybe the two are connected.
So was it pretty competitive?
It's competitive.
And it's also, you know, as we touched on earlier, primates like power.
And I think neurosurgery has long had this aura.
Of mystique and excellence and whatever about it.
And so it's an invitation, I think, for people that are cloaked in that authority.
You know, a board-certified neurosurgeon is basically a walking, fallacious appeal to authority.
Right?
You have license to walk into any room and act like you're, you know, an expert on whatever.
And fighting that tendency is not something that most neurosurgeons do well.
Humility isn't the forte.
Yeah.
One of the, so I have friends who know you.
And whenever they speak about you, that yours have the surprising quality for a neurosurgeon of humility.
Which I think indicates that it's not as common as perhaps in other professions.
Because there is a kind of gigantic sort of heroic aspect to neurosurgery.
And I think it gets to people's head a little bit.
Yeah.
Well, that, I think that.
Oh, you know, that allows me to play well at an Elon company.
Yes.
Because Elon, one of his strengths, I think, is to just instantly see through fallacy from authority.
Yeah.
So nobody walks into a room that he's in and says, well, goddammit, you have to trust me.
I'm the guy that built the last, you know, 10 rockets or something.
And he says, well, you did it wrong and we can do it better.
Or I'm the guy that, you know, kept Ford.
Alive for the last 50 years.
You listened to me on how to build cars.
And he says, no.
And so you don't walk into a room that he's in and say, well, I'm a neurosurgeon.
Let me tell you how to do it.
He's going to say, well, I'm a human being that has a brain.
I can think from first principles myself.
Thank you very much.
And here's how I think it ought to be done.
Let's go try it and see who's right.
And that's, you know, proven, I think, over and over in his case to be a very powerful approach.
If we just take that tangent, there's a fascinating interdisciplinary team at Neuralink
that you get to interact with, including Elon.
What do you think is the secret to a successful team?
What have you learned from just getting to observe these folks?
Yeah.
World experts in different disciplines work together.
Yeah, there's a sweet spot where people disagree.
And forcefully speak their mind and passionately defend their position.
And yet are still able to accept information from others and change their ideas when they're wrong.
And so I like the analogy of sort of how you polish rocks.
You put hard things in a hard container and spin it.
People bash against each other and out comes, you know, a more refined product.
And so to make a good team at Neuralink, we've tried to find, you know,
people that are not afraid to defend their ideas passionately.
And, you know, occasionally strongly disagree with people that they're working with
and have the best idea come out on top.
It's not an easy balance, again, to refer back to the primate brain.
It's not.
It's not.
It's not something that is inherently built into the primate brain to say,
I passionately put all my chips on this position and now I'm just going to walk away from it.
Admit you were right.
You know, part of our brains tell us that that is a power loss.
That is a loss of face, a loss of standing in the community.
And now you're a Zeta chump because your idea got trounced.
And you just have to...
You have to, you know, recognize that that little voice in the back of your head is maladaptive
and it's not helping the team win.
Yeah, you have to have the confidence to be able to walk away from an idea that you hold on to.
Yeah.
And if you do that often enough, you're actually going to become the best in the world at your thing.
I mean, that kind of, that rapid iteration.
Yeah, you'll at least be a member of a winning team.
Ride the wave.
What did you learn?
You mentioned there's a lot of...
There's a lot of amazing neurosurgeons at USC.
What lessons about surgery and life have you learned from those folks?
Yeah, I think working your ass off, working hard while, you know, functioning as a member of a team,
getting a job done that is incredibly difficult, you know, working incredibly long hours,
being up all night, taking care of someone that, you know,
you think probably won't survive.
No matter what you do, working hard to make people that you passionately dislike look good the next morning.
These folks were relentless in their pursuit of excellent neurosurgical technique decade over decade.
And I think we're well recognized for that excellence.
So, you know, especially Marty Weiss, Steve Gianotta, Micah Puzo, they made huge contributions.
Not only to surgical technique, but they built training programs that trained dozens or hundreds of amazing neurosurgeons.
I was just lucky to kind of be in their wake.
What's that like?
You mentioned doing a surgery where the person is likely not to survive.
Does that wear on you?
Yeah.
You know, it's especially challenging when you, with all respect to our elders,
it doesn't hit so much when you're taking care of an 80-year-old
and something was going to get them pretty soon anyway.
And so you lose a patient like that.
And it was part of the natural course of what is expected of them in the coming years, regardless.
Taking care of, you know, a father of two or three, four young kids,
someone in their 30s that didn't have it coming,
and they show up in your ER having their first seizure of their life,
and lo and behold, they've got a huge malignancy.
They've got a malignant, inoperable, or incurable brain tumor.
You can only do that, I think, a handful of times before it really starts eating away at your armor.
Or, you know, a young mother that shows up that has a giant hemorrhage in her brain that she's not going to survive from.
And, you know, they bring her four-year-old daughter in to say goodbye one last time before they turn the ventilator off.
But that, you know, the great Henry Marsh is an English neurosurgeon who said it best.
I think he says every neurosurgeon carries with them a private graveyard.
And I definitely feel that, especially with young parents.
That kills me.
They had a lot more to give.
The loss of those people specifically has a, you know,
knockoff.
It's going to make the world worse for people for a long time.
And it's just hard to feel powerless in the face of that.
You know, and that's where I think you have to be borderline evil to fight against a company like Neuralink
or to constantly be taking pot shots at us.
Because what we're doing is to try to fix it.
We're trying to give people options to reduce suffering.
We're trying to take the pain out of life that broken brains brings in.
And, yeah, this is just our little way that we're fighting back against entropy, I guess.
Yeah, the amount of suffering that's endured
when some of the things that we've been through, you know,
some of the things that we've been through, you know,
some of the things that we've been through, you know,
some of the things that we take for granted
that our brain is able to do is taken away is immense.
And to be able to restore some of that functionality is a real gift.
Yeah, we're just starting.
We're going to do so much more.
Well, can you take me through the full procedure for implanting, say, the N1 chip in Neuralink?
Yeah, it's a really simple, really simple, straightforward procedure.
The human part of the surgery,
the human part of the surgery that I do is dead simple.
It's one of the most basic neurosurgery procedures imaginable.
And I think there's evidence that some version of it has been done for thousands of years.
There are examples, I think, from ancient Egypt of healed or partially healed trephinations
and from Peru or, you know, ancient times in South America
where, you know, there's a lot of evidence that there's a lot of evidence that there's a lot of evidence that there's a lot of evidence that there's a lot of evidence
that these proto surgeons would drill holes in people's schools, you know, presumably to let out the evil spirits, but maybe to drain blood clots.
And there's evidence of bone healing around the edge,
meaning the people at least survive some months after a procedure.
And so what we're doing is that we are making a cut in the skin,
on the top of the head, over the area of the brain that is the most potent representation of hand intentions.
So if you are an expert concert pianist, this part of your brain is lighting up the entire time you're playing. We call it the hand knob.
The hand knob. So it's all the finger movements, all of that is just firing away.
Yep. There's a little squiggle in the cortex right there. One of the folds in the brain is kind of doubly folded right on that spot. And so you can look at it on an MRI and say, that's the hand knob. And then you do a functional test in a special kind of MRI called a functional MRI, fMRI. And this part of the brain lights up when people, even quadriplegic people whose brains aren't connected to their finger movements anymore, they imagine finger movements and this part of the brain still lights up.
Okay.
So we can ID that part of the brain in anyone who's preparing to enter our trial and say, okay, that part of the brain we confirm is your hand intention area. And so I'll make a little cut in the skin. We'll flap the skin open, just like kind of opening the hood of a car, only a lot smaller. Make a perfectly round one inch diameter hole in the skull.
Remove that bit of skull. Open the lining of the brain, the covering of the brain. It's like a little bag of water that the brain floats in. And then show that part of the brain to our robot. And then this is where the robot shines. It can come in and take these tiny, much smaller than human hair electrodes and precisely insert them into the cortex, into the surface of the brain.
Yeah.
To a very precise depth in a very precise spot that avoids all the blood vessels that are coating the surface of the brain. And after the robot's done with its part, then, you know, the human comes back in and puts the implant into that hole in the skull and covers it up, screwing it down to the skull and sewing the skin back together. So the whole thing is, you know, a few hours long. It's extremely low risk compared to
the average neurosurgery involving the brain that might, say, open up a deep part of the brain or manipulate blood vessels in the brain. This opening on the surface of the brain with only cortical microinsertions carries significantly less risk than a lot of the, you know, tumor or aneurysm surgeries that are routinely done.
So cortical microinsertions that are via aerobics.
Robot and computer vision are designed to avoid the blood vessels.
Exactly.
So I know you're a bit biased here, but let's compare human and machine.
Sure.
So what are human surgeons able to do well and what are robot surgeons able to do well at this stage of our human civilization development?
Yeah. Yeah, that's a good question.
Humans are general practitioners.
We're able to adapt to unusual situations.
We're able to change the plan on the fly.
I remember well a surgery that I was doing many years ago down in San Diego where the plan was to open a small hole behind the ear and go reposition a blood vessel that had come to lay on the facial nerve, the trigeminal nerve.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
When that blood vessel lays on the nerve, it can cause just intolerable horrific shooting pain that people describe like being zapped with a cattle prod.
And so the beautiful, elegant surgery is to go move this blood vessel off the nerve.
The surgery team, we went in there and started moving this blood vessel and then found that there was a giant aneurysm on that blood vessel.
It was not easily visible on the pre-op scans.
And so the plan had to.
dynamically change. And the human surgeons had no problem with that. We're trained for all those
things. Robots wouldn't do so well in that situation, at least in their current incarnation,
fully robotic surgery like the electrode insertion portion of the Neuralink surgery.
It goes according to a set plan. And so the humans can interrupt the flow and change the plan,
but the robot can't really change the plan midway through. It operates according to how
it was programmed and how it was asked to run. It does its job very precisely, but not
with a wide degree of latitude in how to react to changing conditions.
So there could be just a very large number of ways that you could be surprised as a surgeon.
When you enter a situation, there could be subtle things that you have to dynamically adjust to.
Correct.
And robots are not.
Good at that.
Currently.
Currently.
I think we are at the dawn of a new era with AI of the parameters for robot responsiveness to be
dramatically broadened, right? I mean, you can't look at a self-driving car
and say that it's operating under very narrow parameters. If a chicken runs across the road,
it wasn't necessarily programmed to deal with that.
Specifically,
you put a Waymo or a self-driving Tesla, we have no problem reacting to that appropriately.
And so surgical robots aren't there yet, but give it time.
And then there could be a lot of sort of semi-autonomous possibilities of
maybe a robotic surgeon could say, this situation is perfectly familiar or the situation is not
familiar. And in the not familiar case, a human could take over. But basically,
you could be very conservative in saying, this for sure has no issues, no surprises, and then let
the humans deal with the surprises with the edge cases and all that.
Yeah.
Ah, that's one possibility. You think eventually you will be out of the job. You being a neurosurgeon,
your job being neurosurge, humans, there will not be many neurosurgeons left on this earth.
I'm not worried about my job in the course of my profession.
No one ever did that.
Yeah.
That's true.
But from what you have learned, know what you're doing, what you're developing.
Yeah.
I think I would tell my kids not necessarily to go in this line of work, depending on how things look in 20 years.
It's so fascinating because, I mean, if I have a line of work, I would say it's programming. And if you ask me, like, for the last, I don't know, 20 years, what I would recommend for people, I would tell them, yeah, go. You will always have a job if you're a programmer.
Because there's more and more computers and all this kind of stuff, and it pays well. But then you realize these large language models come along, and they're really damn good at generating code.
So overnight, you could be surprised, like, wow, what is the contribution of the human, really? But then you start to think, okay, it does seem that humans have ability, like you said, to deal with novel situations.
And in the case of programming, it's the ability to kind of come up with novel ideas.
To solve problems. It seems like machines aren't quite yet able to do that. And when the stakes are very high, when it's life critical, as it is in surgery, especially neurosurgery, then it starts, the stakes are very high for a robot to actually replace a human.
But it's fascinating that in this case of Neuralink, there's a human-robot collaboration.
Yeah, yeah. I do the parts it can't do, and it does the parts I can't do.
And we are friends.
I saw that there's a lot of practice going on. So, I mean, everything in Neuralink is tested extremely rigorously. But one of the things I saw that there's a proxy on which the surgeries are performed.
Yeah.
So this is both for the robot and for the human, for everybody involved in the entire pipeline.
Yep.
What's that like, practicing the surgery?
It's pretty intense.
So there's no analog to this in human surgery. Human surgery is sort of this artisanal craft that's handed down directly from master to pupil over the generations.
Yes.
I mean, literally the way you learn to be a surgeon on humans is by doing surgery on humans. I mean, first you watch your professors do a bunch of surgery, and then finally they put...
You know, the trivial parts of the surgery into your hands, and then the more complex parts. And as your understanding of the point and the purposes of the surgery increases, you get more responsibility in the perfect condition. It doesn't always go well.
In Neuralink's case, the approach is a bit different. We, of course, practiced as far as we could on animals. We did hundreds of animal surgeries.
And when it came time to do the...
First human, we had just an amazing team of engineers build incredibly lifelike models. One of the engineers, Fran Romano in particular, built a pulsating brain in a custom 3D-printed skull that matches exactly the patient's anatomy, including their face and scalp characteristics.
And so when I was able to practice that...
I mean, it's as close as it really reasonably should get to being the real thing in all the details, including, you know, having a mannequin body attached to this custom head.
And so when we were doing the practice surgeries, we'd wheel that body into the CT scanner and take a mock CT scan and wheel it back in and conduct all the normal safety checks verbally, you know.
And so when we were doing the practice surgeries, we'd wheel that body into the CT scanner and take a mock CT scan and wheel it back in and conduct all the normal safety checks verbally, you know.
And so when we were doing the practice surgeries, we'd wheel that body into the CT scanner and take a mock CT scan and wheel it back in and conduct all the normal safety checks verbally, you know.
This patient we're confirming his identification is mannequin number blah, blah, blah.
And then opening the brain in exactly the right spot using standard operative neuro-navigation equipment, standard surgical drills in the same OR that we do all of our practice surgeries in at Neuralink.
And having the skull open and have the brain pulse, which adds a degree of difficulty for the robot to, you know, perfectly, precisely plan.
And insert those electrodes to the right depth and location.
And so, yeah, we kind of broke new ground on how extensively we practiced for this surgery.
So there was a historic moment, a big milestone for Neuralink, in part for humanity, with the first human getting a Neuralink implant in January of this year.
Take me through the surgery.
What did it feel like to be part of this?
Yeah, well, we were lucky to have just incredible partners at the Barrow Neurologic Institute.
They are, I think, the premier neurosurgical hospital in the world.
They made everything as easy as possible for the trial to get going and helped us immensely with their expertise on how to, you know, how to do it.
Yeah.
And how to arrange the details.
It was a much more high-pressure surgery in some ways.
I mean, even though the, you know, the outcome wasn't particularly in question in terms of our participants' safety, the number of observers, you know, the number of people.
There's conference rooms full of people watching live streams in the hospital, rooting for this to go perfectly.
And that just adds pressure that...
It is not typical for even the most intense production neurosurgery, say, removing a tumor or, you know, placing deep brain stimulation electrodes.
And it had never been done on a human before.
There were unknown unknowns.
And so, definitely a moderate pucker factor there for the whole team, not knowing if we were going to encounter...
Say, a degree of brain movement that was unanticipated or a degree of brain sag that took the brain far away from the skull and made it difficult to insert or some other unknown, unknown problem.
Fortunately, everything went well and that surgery was one of the smoothest outcomes we could have imagined.
Were you nervous?
I mean, you're a bit of a quarterback in like in the Super Bowl kind of situation.
Extremely nervous.
Extremely.
I was very pleased when it went well and when it was over.
Looking forward to number two.
Yeah.
Even with all that practice, all of that, just you've never been in a situation that's so high stakes in terms of people watching.
Yeah.
And we should also probably mention, given how the media works, a lot of people, you know, maybe in a dark kind of way hoping it doesn't go well.
Well, I think wealth is easy to hate.
Or envy or whatever.
And I think there's a whole industry around driving clicks and bad news is great for clicks.
And so any way to take an event and turn it into bad news is going to be really good for clicks.
It just sucks because I think it puts pressure on people.
It discourages people from trying to solve really hard problems.
Because to solve hard problems...
Yeah.
Yeah.
Yeah.
To solve hard problems, you have to go into the unknown.
You have to do things that haven't been done before.
And you have to take risks.
Yeah.
Calculated risks.
You have to do all kinds of safety precautions, but risks nevertheless.
I just wish there would be more celebration of that, of the risk taking versus like people just waiting on the sidelines, like waiting for failure.
Yeah.
And then pointing out the failure.
Yeah, it sucks.
But, you know, in this case, it's really great that everything went just flawlessly.
But it's unnecessary pressure, I would say.
Now that there is a human with literal skin in the game, you know, there's a participant whose well-being rides on this doing well.
You have to be a pretty bad person to be rooting for that to go wrong.
Yeah.
And so, you know, hopefully people look in the mirror and realize that at some point.
So did you get to actually front row seat, like watch the robot work?
Like what?
You get to see the whole thing?
Yeah.
I mean, you know, because an MD needs to be in charge of all of the medical decision making throughout the process, I unscrubbed from the surgery after exposing the brain and presenting it to the robot and placed the targets on the robot software interface that tells the robot where it's going to insert each thread.
And that was done with, you know, my hand on the mouse.
So you were the one placing the targets?
Yeah.
Oh, cool.
So like, you know, the robot with the computer vision provides a bunch of candidates and you kind of finalize the decision.
Right.
You know, the software engineers are amazing on this team.
And so they actually provided an interface where you can essentially use a lasso tool and select a prime area of brain real estate.
And it will automatically avoid the blood vessels in that region and automatically place a bunch of targets.
So, you know, that allows, you know, the human robot operator to select really good areas of brain and make dense applications of targets in that in those regions, the regions we think are going to have the most high fidelity representations of finger movements and arm movement intentions.
I've seen like images of this and for me with OCDs for some reason are really pleasant.
I think there's a subreddit called Oddly Satisfying.
Yeah, I love that subreddit.
It's oddly satisfying to see the different target sites avoiding the blood vessels and also maximizing like the usefulness of those locations for the signal.
It just feels good.
It's like, ah, it's nice.
As a person who has a visceral reaction to the brain bleeding, I can tell you.
Yes.
Especially.
It's extremely satisfying watching the electrodes themselves go into the brain and not cause bleeding.
Yeah.
Yeah.
So you said the feeling was of relief when everything went perfectly.
Yeah.
How deep in the brain can you currently go and eventually go?
Let's say on the neural link side, it seems the deeper you go in the brain, the more challenging it becomes.
Yeah.
So.
But talking broadly about neurosurgery, we can get anywhere.
It's routine for me to put deep brain stimulating electrodes near the very bottom of the brain, entering from the top and passing about a two millimeter wire all the way into the bottom of the brain.
And that's not revolutionary.
A lot of people do that and we can do that with very high precision.
I use a robot from Globus to do that surgery.
You know, several times a month.
It's pretty routine.
What are your eyes in that situation?
What are you seeing?
What kind of technology can you use to visualize where you are to light your way?
Yeah, so it's a cool process on the software side.
You take a preoperative MRI that's extremely high resolution data of the entire brain.
You put the patient to sleep.
Put their head in a frame that holds the skull very rigidly.
And then you take a CT scan of their head while they're asleep with that frame on, and then merge the MRI and the CT in software.
You have a plan based on the MRI where you can see these nuclei deep in the brain.
You can't see them on CT, but if you trust the merging of the two images, then you indirectly know on the CT where that is, and therefore indirectly know where the brain is.
Yeah.
Yeah.
They're in reference to the titanium frame screwed to their head.
Those targets are.
And so this is 60s technology to manually compute trajectories given the entry point and target and dial in some goofy looking titanium actuators with manually manual actuators with little tick marks on them.
The modern version of that is to use a robot.
Yeah.
know, just like a little kooka arm you might see building cars at the Tesla factory,
this small robot arm can show you the trajectory that you intended from the pre-op MRI and
establish a very rigid holder through which you can drill a small hole in the skull
and pass a small rigid wire deep into that area of the brain that's hollow and put your
electrode through that hollow wire and then remove all of that except the electrode. So you
end up with the electrode very, very precisely placed far from the skull surface. Now that's
standard technology that's already been out in the world for a while. Neuralink right now is
focused entirely on cortical targets, surface targets, because there's no trivial way to get
say hundreds of wires deep inside the brain without doing a lot of damage. So your question,
what do you see? Well, I see an MRI on a screen. I can't see everything that that DBS electrode is
passing through on its way to that deep target. And so it's accepted with this approach that
there's going to be about one in a hundred patients who have a bleed somewhere in the brain
as a result of passing that wire,
but it's not going to happen. It's going to happen. It's going to happen. It's going to happen.
Blindly into the deep part of the brain.
That's not an acceptable safety profile for Neuralink. We start from the position that we
want this to be dramatically, maybe two or three orders of magnitude safer than that.
Safe enough really that you or I without a profound medical problem might on our lunch
break someday say, yeah, sure, I'll get that. I've been meaning to upgrade to the latest version.
And so the safety constraints given that are high. And so we haven't settled on a final
solution for arbitrarily approaching deep targets in the brain.
It's interesting because you have to avoid blood vessels somehow.
Maybe there's creative ways of doing the same thing, like mapping out high resolution geometry
of blood vessels, and then you can go in blind. But how do you map out that?
You can do that in a way that's super stable. There's a lot of interesting challenges there,
right? But there's a lot to do on the surface, luckily.
Exactly. So we've got vision on the surface. We actually have made a huge amount of progress
sewing electrodes into the spinal cord as a potential workaround for a spinal cord injury
that would allow a brain-mounted implant to translate motor intentions to a spine-mounted
implant that can...
affect muscle contractions in previously paralyzed arms and legs.
That's mind-blowing. That's just incredible. So the effort there is to try to bridge
the brain to the spinal cord to the peripheral nervous system. So how hard is that to do?
We have that working in very crude forms in animals.
That's amazing.
Yeah, we've done it.
So similar to like with Nolan, where he's able to digitally move the cursor, here you're
doing the same kind of communication, but with the actual effectors that you have.
Yeah.
That's fascinating.
Yeah. So we have anesthetized animals doing grasp, and moving their legs in a sort
of walking pattern. Again, early days. But the future is bright for this kind of thing and
people with paralysis should look forward to that bright future. They're going to have options.
Yeah.
Yeah, and there's a lot of sort of intermediate or extra options where you take like an Optimus
robot, like the arm, and to be able to control the arm, the fingers and hands of the arm
as a prosthetic.
Exoskeletons are getting better too.
Exoskeletons.
Yeah, so that goes hand in hand.
Although I didn't quite understand until thinking about it deeply and doing more research about
Neuralink, how much you can do on the digital side.
So there's digital telepathy.
I didn't quite understand that you could really map the intention, as you described in the
hand knob area, that you can map the intention.
Just imagine it.
Think about it.
That intention can be mapped to actual action in the digital world.
And now more and more, so much can be done in the digital world.
It can reconnect you to the outside world.
It can allow you to have freedom, have independence if you're a quadriplegic.
Yeah.
That's really powerful.
Like you can go really far with that.
Yeah.
Our first participant is, he's incredible.
He's breaking world records left and right.
And he's having fun with it.
It's great.
Just going back to the surgery, your whole journey, you mentioned to me offline you have
surgery.
You're on Monday.
So you're like, you're doing surgery all the time.
Yeah.
Maybe the ridiculous question, what does it take to get good at surgery?
Practice.
Repetitions.
You just, same with anything else.
You know, there's a million ways of people saying the same thing and selling books saying
it, but do you call it 10,000 hours?
Do you call it, you know, spend some chunk of your life, some percentage of your life
focusing on this, obsessing about getting better at it?
Repetitions.
Uh, humility, recognizing that you aren't perfect at any stage along the way, uh, recognizing
you've got improvements to make in your technique, being open to feedback and coaching from people
with a different perspective on how to do it.
Um, and then, um, just the constant will to do better, uh, that fortunately, you know,
if you're not a sociopath, I think your patients bring that with them to the office visits every
day.
They, they, you know, force you to want to do better all the time.
Yeah.
Just step up.
I mean, it's a real human being, a real human being that you can help.
Yeah.
So every surgery, even if it's the same exact surgery, is there a lot of variability between
that surgery and a different person?
Yeah, a fair bit.
I mean, a good example for us is that the angle of the skull relative to the normal
plane of the body axis of the skull.
Overhand knob, uh, is pretty wide variation.
I mean, some people have really flat skulls and some people have really steeply angled
skulls over that area.
And that has, you know, consequences for how their head can be fixed in, in, uh, in sort
of the frame that we use, um, and how the robot has to approach the skull and, um, yeah,
people's people's bodies are built as differently as.
Yeah.
You know, the people you see walking down the street as, as much variability in body
shape and size as you see there, we see in brain anatomy and skull anatomy.
Um, there are some people who we've had to kind of exclude from our trial for having
skulls that are too thick or too thin or scalp that's too thick or too thin.
Um, I think, you know, we have like the middle 97% or so, uh, of people, but you can't account
for all of that.
All human anatomy variability.
How much like mushiness and mess is there?
Cause I, uh, you know, taking biology classes, the diagrams are always really clean and crisp
neuroscience.
The pictures of neurons are always really nice and very, um, but whenever I look at
pictures of like real brains, they're all, I don't know what is going on.
Yeah.
Uh, so how much are biological systems in reality?
Like how?
How hard is it to figure out what's going on?
Not too bad.
Uh, once you really get used to this, you know, that's where experience and skill and, uh,
education really come into play is if you stare at a thousand brains, it becomes easier to kind
of mentally peel back the, say, for instance, blood vessels that are obscuring the sulci and
gyri, you know, kind of the wrinkle pattern of the surface of the brain.
Occasionally when you're, when you're first starting to do this and you open the skull, it doesn't match
what you thought you were going to see based on the MRI.
Uh, and with more experience, you, you learn to kind of peel back that layer of blood vessels and see
the underlying pattern of wrinkles in the brain and, uh, use that as a landmark for where you are.
The wrinkles are a landmark.
So like, yeah.
So I was describing hand.
Knob earlier.
That's a pattern of the wrinkles in the brain.
It's sort of this sort of Greek letter, omega shaped area of the brain.
So you could recognize the hand knob area.
Like if I, if I show you a thousand brains and give you like one minute with each, you'd be like, yep, that's that.
Sure.
And so there is some uniqueness to that area of the brain, like in terms of the geometry, the topology of the thing.
Yeah.
Where is it about in the.
It's.
So you have this.
Strip of brain running down the top called the primary motor area.
And I'm sure you've seen this picture of the homunculus laid over the surface of the brain.
The weird little guy with huge lips and giant hands.
Uh, that guy sort of lays with his legs, uh, up at the top of the brain and, and face arm, uh, areas farther down.
And, and then some kind of mouth, lip, tongue areas, uh, farther down.
And so the hand is right in there.
And then the areas that control speech, at least on the, on the left side of the brain in most people are, are just below that.
And so, uh, any muscle that you voluntarily move in your body, um, the vast majority of that references that strip or those intentions come from that strip of brain and the, the wrinkle, uh, for hand knob is right in the middle of that.
And vision.
Is back here.
Yep.
Also on close to the surface.
Vision's a little deeper.
Uh, and so, you know, this gets to your question about how deep can you get, um, to do vision.
We can't just do the surface of the brain.
We have to be able to go in, uh, not, not as deep as we have to go for DBS, but maybe a centimeter deeper than we're used to for hand insertions.
Uh, and so that's, you know, work in progress.
That's, uh, a.
New set of challenges to overcome.
By the way, you mentioned, uh, the Utah array and I just saw a picture of that and that thing looks terrifying because it's, it's because it's rigid.
And then if you look at the threads, they're flexible.
What can you say?
That's interesting to you about the flexible, that kind of approach of the, the flexible threads to, to deliver the electrodes next to the neurons.
Yeah.
I mean, the, the goal there comes from experience.
I mean, we stand on the shoulders of.
People that made Utah rays and, and used Utah rays for decades before we ever even came along.
Um, Neuralink arose partly this approach to technology arose out of a need recognized after Utah rays would fail routinely because the rigid electrodes, those spikes that are literally hammered using an air hammer into the brain.
Uh, those spikes generate a bad immune response that encapsulates the, the electrode spikes in, uh, scar tissue, essentially.
And so one of the projects that was being worked on in, in the Anderson lab at Caltech, when I got there was to see if you could use chemo therapy to prevent the formation of scars.
Like, you know, things are pretty bad when you're jamming a bed of nails into the brain.
And then treating that with chemotherapy to try to prevent scar tissue.
It's like, you know, maybe we've gotten off track here, guys, maybe there's a fundamental redesign necessary.
And so Neuralink's approach of using highly flexible, tiny electrodes avoids a lot of the bleeding avoids a lot of the immune response that ends up happening, uh, when rigid electrodes are pounded into the brain.
And so what we see is our electrode longevity.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
the health of the brain tissue immediately surrounding the electrode, uh, is excellent.
I mean, it goes on for, for years now in our animal models.
What do most people not understand about the biology of the brain?
We'll, we'll mention the vasculature.
That's really interesting.
I think the most interesting, maybe underappreciated fact, uh, is that it really does control almost
everything.
I mean,
I don't know. Out of the blue example, imagine you want a lever on fertility. You want to be
able to turn fertility on and off. I mean, there are legitimate targets in the brain itself to
modulate fertility. Say, blood pressure. You want to modulate blood pressure. There are legitimate
targets in the brain for doing that. Things that aren't immediately obvious as brain problems,
are potentially solvable in the brain. And so, I think it's an underexplored area for
primary treatments of all the things that bother people.
That's a really fascinating way to look at it. There's a lot of conditions we might think have
nothing to do with the brain, but they might just be symptoms of something that actually started in
the brain. The actual source of the problem, the primary source is something.
Yeah. Not always. Kidney disease is real, but there are levers you can pull in the brain
that affect all of these systems. There's knobs.
Yeah. On-off switches and knobs in the brain
from which this all originates. Would you have a Neuralink chip implanted in your brain?
Yeah. I think the use case right now is,
use a mouse, right? I can already do that. And so, there's no value
proposition. On safety grounds alone, sure. I'll do it tomorrow.
You know, you say the use case of the mouse.
Because after researching all this, and part of it is just watching Nolan have so much fun.
If you can get that bits per second look really high with a mouse,
like being able to interact. Because if you think about it, the way on the smartphone,
the way you swipe, that was true.
It's transformational, how we interact with the thing. It's subtle. You don't realize it,
but to be able to touch a phone and to scroll with your finger, that changed everything.
People were sure you need a keyboard to type. There's a lot of HCI aspects to that that changed
how we interact with computers. So, there could be a certain rate of speed with the mouse
that would change everything.
Yes.
It's like, you might be able to...
To just click around a screen extremely fast. And that, if it... I can't keep myself getting
the Neuralink for much more rapid interaction with the digital devices.
Yeah. I think recording speech intentions from the brain might change things as well. You know,
the value proposition for the average person. A keyboard is a pretty clunky human interface,
requires a lot of training. It's...
You know, highly variable in the maximum performance that the average person can achieve. I think taking that out of the equation and just having a natural, you know, word to computer interface might change things for a lot of people.
It'd be hilarious if that is the reason people do it. Even if you have speech-to-text, that's extremely accurate. It currently isn't, but it's gotten super accurate.
It'd be hilarious if people went for Neuralink just so you avoid the embarrassing aspect of speaking, like looking like a douchebag speaking to your phone in public. Which is the real... like, that's a real constraint.
Yeah. I mean, with a bone-conducting case that can be an invisible headphone, say, and the ability to think words into software and have it respond to you,
That starts to sound sort of like embedded superintelligence. If you can
silently ask for the Wikipedia article on any subject and have it read to you
without any observable change happening in the outside world,
for one thing, standardized testing is obsolete. Yeah. If it's done well on the UX side,
it could change, I don't know if it transforms society, but it really can create a kind of shift
in the way we interact with digital devices in the way that a smartphone did. Now I would,
just having to look into the safety of everything involved, I would totally try it.
So it doesn't have to go to some like incredible thing where you have, it connects your vision or
to some, like it connects all over your brain. That could be like just connecting to the hand knob
and you might have a lot of interesting interaction, human-computer interaction
possibilities. That's really interesting. Yeah. And the technology on the academic side
is progressing at light speed here. I think there was a really amazing paper out of UC Davis,
Sergei Stavisky's lab, that basically made an initial solve of speech decode.
It was something like 125,000 words that they were getting with very high accuracy.
So you're just thinking the word? Yeah.
Thinking the word and you're able to get it. Yeah.
Oh boy. Like you have to have the intention of speaking it.
Right. So like do the inner voice.
Now it's so amazing to me that you can do the intention, the signal mapping. All you have to
do is just imagine yourself doing it. And if you get the feedback that it actually worked, you can
get really good at that. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.
Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.
Like your brain will first of all adjust and you develop like any other skill.
Yeah. Like touch typing, you develop in that same kind of way. That is, to me,
it's just really fascinating. Yeah. To be able to even to play with that. Honestly, like I'll get
a neural link just to be able to play with that. Just to play with the capacity of the capability
of my mind to learn this skill. It's like learning the skill of typing and learning the skill of
moving a mouse. It's another skill of moving the mouse, not with my physical body, but
with my mind. I can't wait to see what people do with it. I feel like we're cavemen right now.
We're like banging rocks with a stick and thinking that we're making music.
At some point when these are more widespread, there's going to be the equivalent of a piano
that someone can make art with their brain in a way that we didn't even anticipate.
I'm looking forward to it. Give it to like a teenager. Anytime I think I'm good at something,
I'll always go to.
Like, I don't know, even with the bits per second and playing a video game,
you realize you give it to a teenager, you give a neural link to a teenager,
just a large number of them, the kind of stuff, they get good at stuff. They're going to get like
hundreds of bits per second. Yeah. Even just with the current technology.
Probably. Probably.
Just because it's also addicting how like the number go up.
Yeah.
But it's also a really cool aspect of it of like improving and training because it is,
it's almost like a skill. And plus there's a software on the other end that adapts to you.
And especially if the adapting procedure, the algorithm becomes better and better and better,
you like learning together.
Yeah. We're scratching the surface on that right now. There's so much more to do.
So on the complete other side of it, you have an RFID chip implanted in you.
Yeah.
So I hear. Nice. So this is a little subtle thing.
It's a passive device that you use.
For unlocking like a safe with top secrets or what, what is the, what do you use it for?
What's the story behind it?
I'm not the first one. There's, you know, there's this whole community of
weirdo biohackers that have done this stuff. And I think one of the early use cases was storing,
you know, private crypto wallet keys and, and whatever. I dabbled in that a bit and,
and had some fun with it.
Do you have some Bitcoin implanted in your body somewhere?
You can't tell. Where? Yeah.
Yeah. Actually, yeah. Uh, it was, you know, the modern day equivalent to finding change in the
sofa cushions after I, I put some orphan crypto on there that I thought was worthless and forgot
about it for a few years, went back and found that some community of people loved it, uh, and had
propped up the value of it. And so it had gone up 50 fold. Oh, so there was a lot of change in
those cushions.
That's hilarious.
But the, the primary use case-
Yeah.
Yeah.
Yeah.
use cases mostly as a as a tech demonstrator you know it has my business card on it you can scan
that in by touching it to your phone it opens the front door to my house you know whatever simple
stuff it's a cool step it's a cool leap to implant something in your body i mean it has perhaps
that's it's a similar leap to a neural link because for a lot of people that kind of notion
of putting something inside your body something electronic inside a biological system is a big
leap yeah we have a kind of a mysticism around the barrier of our skin we're completely fine with
knee replacements hip replacements you know uh dental implants um
but uh you know there's a mysticism still around the inviolable barrier that the skull represents
and i think that needs to be treated like any other uh pragmatic barrier you know it's the
question isn't
how how incredible is it to open the skull the question is you know what benefit can we provide
so from all the surgeries you've done from everything you understand the brain
how much does neuroplasticity come into play how adaptable is the brain for example just even in
the case of healing from surgery or adapting to the post-surgery situation the answer that is sad
for me and uh other people of my demographic is that you know the plasticity decreases with age
healing decreases with age i have too much gray hair to uh to be optimistic about that there are
theoretical ways to increase plasticity using electrical stimulation nothing that is you know
totally proven out as a robust enough mechanism to offer widely to people but um
yeah i think i think there's cause for optimism that we might find something useful in terms of
say an implanted electrode that
improves learning um certainly there's been some really amazing work
recently from uh nicholas schiff jonathan baker you know and others who have a cohort of patients
with moderate traumatic brain injury who have had electrodes placed in the deep nucleus in
the brain called the central median nucleus or just near central median nucleus and when they
apply small amounts of electricity to that part of the brain it's almost like
electronic caffeine they're able to improve people's attention and focus they're able to
improve how well people can perform a task i think in one case someone who was unable to work after
the device was turned on they were able to get a job and that's sort of you know one of the holy
grails for me with neuralink and other technologies like this is from a purely utilitarian standpoint
can we can we make people able to take care of themselves and their families economically again
can we make it so someone who's fully dependent and even maybe requires a lot of caregiver
resources can we put them in a position to be fully independent taking care of themselves
giving back to their communities i think i think that's a very compelling proposition
and what motivates a lot of what i do and what a lot of the people at neuralink are working for
it's just a cool possibility that if you put a neural link in there that the brain adapts like
the other part of the brain adapts to yeah and integrates it the the capacity of the brain to
do that it's really interesting probably unknown to the degree to which you can do that but you're
now connecting an external thing to it especially uh once it's doing uh stimulation like the the
biological brain in the uh
the electronic brain outside of it working together like the possibilities they're really
interesting yeah that's still unknown but interesting it feels like the brain is really
good at adapting to whatever yeah but of course it is a system that by itself is already uh
like everything serves a purpose and so you don't want to mess with it too much yeah it's like
you know eliminating a species from a from an ecology you know
you don't know what the delicate interconnections and dependencies are
the brain is certainly a delicate complex beast and we don't know
you know every potential downstream consequence of of a single change that we make do you see
yourself doing uh so mentioned p1 surges of p2 p3 p4 p5 just well more and more and more humans i think
it's a certain kind of brittleness or you know a failure on the company's side if we
need me to do all the surgeries um i think something that i would very much like to work
towards is a process that is so simple and so robust on the surgery side that literally anyone
could do it um we want to get away from requiring intense expertise or intense experience
uh to have this successfully done and make it as as simple and translatable as possible i mean i
would love it if every neurosurgeon on the planet had no problem doing this um
i think we're probably far from a regulatory environment that would allow
uh people that aren't neurosurgeons to do this but uh not impossible
all right i'll sign up for that did you ever anthropomorphize the the robot r1 like do you
do you give it a name do you see it as like a friend that's like working together with you
i mean to a certain degree it's or an enemy who's gonna get the job
to a certain degree it's it's yeah it's complex relationship uh all the good relationships are
it's funny when in the middle of the surgery there's a part of it where i
stand basically shoulder to shoulder with the robot um and so you know if you're in the room
reading the body language you know there's a lot of stress and there's a lot of pain and there's a
It's my brother in arms there working together on the same problem.
Yeah, I'm not threatened by it.
Keep telling yourself that.
How have all the surgeries that you've done over the years,
the people you've helped and the stakes, the high stakes that you've mentioned,
how has that changed your understanding of life and death?
Yeah, it gives you a very visceral sense, and this may sound trite,
but it gives you a very visceral sense that death is inevitable.
On one hand, as a neurosurgeon, you're deeply involved in these hard-to-fathom tragedies.
You know, young parents dying, leaving, you know, a four-year-old behind, let's say.
And on the other hand, you know, it takes the sting out of it a bit
because you see how just mind-numbingly universal death is.
There is zero chance that I'm going to avoid it.
I know, you know,
techno-optimists right now and longevity buffs right now
would disagree on that 0.000% estimate,
but I don't see any chance that our generation is going to avoid it.
Entropy is a powerful force, and we are very ornate, delicate, brittle DNA machines
that aren't up to the cosmic ray bombardment that we're subjected to.
So on the one hand,
every human that has ever lived died or will die.
On the other hand, it's just one of the hardest things to imagine
inflicting on anyone that you love is having them gone.
I mean, I'm sure you've had friends that aren't living anymore,
and it's hard to even think about them.
And so I wish I had...
you know, arrived at the point of nirvana
where, you know, death doesn't have a sting.
I'm not worried about it.
But I can at least say that I'm comfortable with the certainty of it,
if not having found out how to take the tragedy out of it
when I think about, you know, my kids
either not having me or me not having them or my wife.
Maybe I've come to accept the intellectual certainty of it,
but it may be the pain that comes with losing the people you love.
I don't think I've come to understand the existential aspect of it,
like that this is going to end.
And I don't mean like in some trite way.
I mean like it certainly feels like it's not going to end.
And like you live life like it's not going to end.
And the fact that this light that's shining,
this consciousness is going to no longer be one moment,
maybe today,
it's like it fills me when I really am able to load all that in
with Ernest Becker's terror.
Like it's a real fear.
I think people aren't always honest with how terrifying it is.
I think the more you are able to really think through it,
the more terrifying it is.
It's just not such a simple thing.
Oh, well, it's the way life is.
And if you really can load that in, it's hard.
But I think that's why the Stoics did it
because it like helps you get your shit together
and be like, well, the moment,
every single moment you're alive is just beautiful.
And it's terrifying that it's going to end.
And it's like, almost like you're shivering in the cold,
a charge.
Yeah.
Like a child, helpless, this kind of feeling.
Yeah.
And then it makes you, when you have warmth,
when you have the safety,
when you have the love to really appreciate it.
I feel like sometimes in your position,
when you mentioned armor, just to see death,
it might make you not be able to see that,
the finiteness of life,
because if you kept looking at that, it might break you.
So,
it's good to know that you're kind of
still struggling with that.
There's the neurosurgeon and then there's a human.
Yeah.
And the human is still able to struggle with that
and feel the fear of that and the pain of that.
Yeah.
You know, it definitely makes you ask the question
of how long, how many times, how many of these can you see
and not say, I can't do this anymore.
Um,
but I mean, you said it well, I think it gives you an opportunity
to just appreciate that you're alive today.
And, uh, you know, I've got, I've got three kids
and an amazing wife and I'm really happy.
Things are good.
I get to help on a project that I think matters.
I think it moves us forward.
I'm a very lucky person.
It's the early steps of a potentially,
uh gigantic leap for humanity it's a really interesting one and it's cool because like you
you read about all this stuff in history where it's like the early days i've been reading uh
before going to the amazon i would read about explorers uh they would go and explore even the
amazon jungle for the first time it's just those are the early steps yeah or early steps into space
early steps in any discipline in in physics and mathematics and it's cool because this is like
the on the grand scale these are the early steps into delving deep into the human brain
so not just observing the brain but you'll be able to interact with the human brain
yeah it's going to help a lot of people but it also might help us understand what the hell's
going on in there yeah i think ultimately we want to give people more levers that they can pull
right like you want to give people options if you can give someone a dial that they
can turn on how happy they are i think that makes people really uncomfortable but
now talk about major depressive disorder talk about people that are committing suicide at an
alarming rate in this country and try to justify that queasiness
in those in that light of your you can give people
take away suicidal ideation suicidal intention i would i would give them that knob i don't know
how you justify not doing that you can think about like all the suffering that's going on in the world
like every single human being that's suffering right now it's like it'll be a glowing red dot
the more suffering the more it's glowing and you just see the map of human suffering and any
technology that allows you to dim that light of suffering uh on a grand scale is pretty exciting
because there's a lot of people suffering and most of them are suffering and they're suffering
most of them suffer quietly and we turn our uh we we look away too often uh and we we should
remember those are suffering because once again most of them are suffering quietly well and you
know on a grander scale the fabric of society you know people have a lot of complaints about
how our social fabric is working or not working how our politics is working or not working
uh those
things are made of neurochemistry too in in aggregate right like our politics is composed
of individuals with human brains and the way it works or doesn't work it's potentially tunable
in the sense that i don't know say remove our addictive behaviors or tune our addictive
behaviors for social media or our addiction to outrage our addiction to sharing the most
améra's
angry, political tweet we can find.
I don't think that leads to a functional society.
And if you had options for people to moderate that maladaptive behavior,
there could be huge benefits to society.
Maybe we could all work together a little more harmoniously toward useful ends.
There's a sweet spot, like you mentioned.
You don't want to completely remove all the dark sides of human nature
because those kind of are somehow necessary to make the whole thing work,
but there's a sweet spot.
Yeah, I agree.
You got to suffer a little, just not so much that you lose hope.
Yeah.
When you do all the surgeries you've done, have you seen consciousness in there ever?
Was there like a glowing light?
You know, I have this sense that I never found it, never removed it,
like a Dementor in Harry Potter.
I have this sense that consciousness is a lot less magical
than our instincts want to claim it is.
It seems to me like a useful analog for thinking about what consciousness is in the brain.
You know, is that we have a really good intuitive understanding
of what it means to, say, touch your skin and know what's being touched,
I think consciousness is just that level of sensory mapping
applied to the thought processes in the brain itself.
So what I'm saying is consciousness is the sensation of some part of your brain being active.
So you feel it working.
You feel the part of your brain that thinks of red things or winged creatures
or the taste of coffee.
You feel those.
Parts of your brain being active the way that I'm feeling my palm being touched, right?
And that sensory system that feels the brain working is consciousness.
That is so brilliant.
It's the same way it's the sensation of touch when you're touching a thing.
Consciousness is the sensation of you feeling your brain working,
your brain thinking, your brain perceiving.
Which isn't like a workaround.
Or a morphing of space-time or some quantum field effect, right?
It's nothing magical.
People always want to ascribe to consciousness something truly different.
And there's this awesome long history of people looking at whatever the latest discovery in physics is
to explain consciousness because it's the most magical,
the most out there thing that you can think of.
And people always want to do that with consciousness.
I don't think that's necessary.
It's just a very useful and gratifying way of feeling your brain work.
And as we said, it's one heck of a brain.
Yeah.
Everything we see around us, everything we love, everything that's beautiful
came from brains like these.
It's all electrical activity happening inside your skull.
And I, for one, am grateful that it's people like you that are exploring all the ways that it works
and all the ways it can be made better.
Thanks, Lex.
Thank you so much for talking today.
It's been a joy.
Thanks for listening to this conversation with Matthew McDougall.
And now, dear friends, here's Bliss Chapman,
Brain Interface Software Lead at Neuralink.
You told me that you've met hundreds of people with spinal cord injuries or with ALS
and that your motivation for helping at Neuralink is grounded in wanting to help them.
Can you describe that?
Can you describe that?
What is this motivation?
Yeah.
First, just a thank you to all the people I've gotten a chance to speak with for sharing
their stories with me.
I don't think there's any world really in which I can share their stories as powerful
a way as they can.
But just, I think, to summarize at a very high level, what I hear over and over again
is that people with ALS or severe spinal cord injury in a place where they basically can't
move physically anymore, really, at the end of the day, are looking for independence.
And that can mean different things for different people.
For some folks, it can mean the ability just to be able to communicate again independently
without needing to wear something on their face, without needing a caretaker to be able
to put something in their mouth.
For some folks, it can mean independence to be able to work again, to be able to navigate
a computer digitally efficiently enough to be able to get a job, to be able to support
themselves, to be able to move out and ultimately be able to support themselves after their
family maybe isn't there anymore to take care of them.
And for some folks, it's as simple as just being able to respond to their kids and their
kid in time before they, you know, run away or get interested in something else.
And these are deeply personal and sort of very human problems.
And what strikes me again and again when talking with these folks is that this is actually
an engineering problem.
This is a problem that with the right resources, the right team, we can make a lot of progress
on.
And at the end of the day, I think that's a deeply inspiring message and something that
makes me excited to get up every day.
So it's both an engineering problem in terms of a BCI, for example, that can give them
capabilities where they can interact with the world, but also on the other side, it's
an engineering problem for the rest of the world to make it more accessible for people
living with quadriplegia.
Yeah.
And actually, I'll take a broad view sort of lens on this for a second.
I think I'm very in favor of anyone working in this problem space.
So beyond BCI, I'm happy and excited and willing to support any way I can folks working
on eye tracking systems, working on, you know, speech.
To text systems, working on head trackers or mouse sticks or quad sticks.
I've met many engineers and folks in the community that do exactly those things.
And I think for the people we're trying to help, it doesn't matter what the complexity
of the solution is, as long as the problem is solved.
And I want to emphasize that there can be many solutions out there that can help with
these problems.
And BCI is one of a collection of such solutions.
So BCI in particular, I think, offers several advantages here.
And I think the folks that recognize this immediately are usually the people who are
people who have spinal cord injury or some form of paralysis.
Usually you don't have to explain to them why this might be something that could be
helpful.
It's usually pretty self-evident, but for the rest of us, folks that don't live with
severe spinal cord injury or who don't know somebody with ALS, it's not often obvious
why you would want a brain implant to be able to connect and navigate a computer.
And it's surprisingly nuancing to the degree that I've learned a huge amount just working
with Noland in the first Nerland clinical trial and understanding from him, in his words,
why this device is impactful for him.
And it's.
A nuanced topic.
It can be the case that even if you can achieve the same thing, for example, with a mouse
stick, when navigating a computer, he doesn't have access to that mouse stick every single
minute of the day.
He only has access when someone is available to put it in front of him.
And so a BCI can really offer a level of, of independence and autonomy that if it wasn't
literally physically part of your body, it'd be hard to achieve in any other way.
So there's a lot of fascinating aspects to what it takes to get Noland to be able to
control a cursor on the screen with his mind.
You texted me.
It's something that I just love.
You said I was part of the team that interviewed and selected P1.
I was in the operating room during the first human surgery, monitoring live signals coming
out of the brain.
I work with the user basically every day to develop new UX paradigms, decoding strategies.
And I was part of the team that figured out how to recover useful BCI to new world record
levels when the signal quality degraded.
We'll talk about, I think every aspect of that, but, um, just zooming out, what was it like to be
a part of that?
Part, part of that team and part of that historic, I would say historic first.
Yeah, I think for me, this is something I've been excited about for close to 10 years now.
And so to be able to be even just some small part of making it a reality is extremely exciting.
A couple maybe special moments during that whole process that I'll never really truly forget.
One of them is entering the actual surgery.
Uh,
you know, at that point in time, I, I know Nolan quite well, I know his family.
And so I think the, the initial reaction when, uh, Nolan is rolled into the operating room is
just a, oh shit kind of reaction.
But at that point, muscle memory kicks in and you sort of go into, uh, you let your body just do
the, all the, all the talking.
And I have the lucky job in that particular procedure to just be in charge of monitoring the implant.
So my job is to sit there, to look at the signals coming off the implant, to look at the live brain
data streaming off the device as threads are being.
Inserting to the brain and just to basically observe and make sure that nothing is going, you know,
wrong or that there's no red flags or fault conditions that we need to go and investigate or
pause the surgery to, uh, to debug.
And, uh, because I had that sort of spectator view of the surgery, I had a slightly removed
perspective than I think most folks in the room, I got to sit there and think to myself, wow, you
know, that brain is moving a lot, you know, when you, when you look into the side, little
craniectomy that we stick the threads in, you know, one thing that most people don't realize is
the brain moves, the brain moves a lot.
Mm-hmm .
When you breathe, when you're, when your, uh, heart beats and you can see it visibly.
So, you know, that's something that I think was a surprise to me and very, very exciting, uh, to
be able to see someone's brain who you physically know and have talked with at length actually
pulsing and moving inside their skull.
And they use that brain to talk to you previously and now it's right there moving.
Yep.
Uh, actually I didn't realize that in terms of the thread sending.
So the, the Neuralink implant is active during surgery.
So, and one thread at a time.
You're able to start seeing the signal.
Yeah.
So that's part of the way you test that the thing is working.
Yeah.
So actually in the, in the operating room, right after we sort of, uh, finished the, uh, all the thread insertions, I started collecting what's called broadband data.
So broadband is, um, basically the most raw form of signal you can collect from a Neuralink electrode.
It's, uh, essentially a measurement of the local field potential or the, yeah, the voltage essentially measured by that electrode.
And, uh, we have a certain mode in our, in our application that allows us to.
To visualize where detected spikes are.
So it visualizes sort of where, uh, we're in the broadband signal and it's very, very raw form of the data.
A neuron is actually spiking.
And so one of the, the, these moments that I'll never forget as part of this whole clinical trial is seeing live in the operating room while he's still under anesthesia, beautiful spikes being shown in the application, just streaming live to a device I'm holding in my hand.
So this is no signal processing, the raw data, and then the signals processing's on top of it.
You're seeing the spikes detected.
Right.
Yeah.
And that's a UX too, cuz yes, that, that looks beautiful as well.
During that procedure, there was actually a lot of cameramen in the room.
So they also were curious and wanted to see there's several neurosurgeons in the room who are all just excited to see robots taking their job and, uh, they're all, you know, crowded around a small little iPhone watching this live brain data stream out of his, uh, his brain.
What was that like seeing the robot do some of the surgery?
So the computer vision aspect where it detects all the, all the spots that avoid, uh,
the blood vessels, and then obviously with the human supervision, then actually doing the really high precision, uh, connection of the threads to the brain.
Yeah, that's a good question.
My answer's gonna be, uh, pretty lame here, but it was boring.
Yeah.
I've seen it, uh, so many times.
Yeah.
That's exactly how you want surgery to be.
You want it to be boring.
Yeah.
Cuz I've seen it so many times.
I've seen the, the robot do the surgery literally hundreds of times.
And so it was just one more time.
Yeah.
Oh, the.
We practiced surgeries on the proxies and this is just another day.
Yeah.
So what about when, uh, Nolan woke up?
Well, do, do you remember a moment where, uh, he was able to move the cursor and not move the cursor, but get signal from the brain such that it was able to show that there's a connection?
Yeah.
Yeah.
So we are, uh, quite excited to move as quickly as we can.
And Nolan was really, really excited to get started.
He wanted to get started actually the day of surgery, but, uh, we,
we waited till the next morning, very patiently, it's a long night.
Um, and the next morning in the ICU where he was, uh, recovering, he, uh, wanted to get started and actually start to understand what kind of signal we can measure from his brain.
And maybe for folks who are not familiar with, um, the Neuralink system, we implant the Neuralink system or the Neuralink implant in the motor cortex.
So the motor cortex is responsible for representing things like motor intent, uh, sort of, if you imagine closing and opening your hand, that kind of signal representation would be
present in the motor cortex.
If you imagine moving your arm back and forth or wiggling a pinky, this sort of signal can be present in the motor cortex.
So one of the ways we start to sort of map out what kind of signal do we actually have access to in any particular individual's brain is through this task called body mapping.
And body mapping is where you essentially present a visual to the user and you say, Hey, imagine doing this.
And that visual is, you know, a 3d hand opening, closing, or index finger modulating up and down.
And, uh, you ask the user to imagine that, and obviously you can't see them do this because they're.
Paralyzed.
So you can't see them actually move their arm, but, uh, while they do this task, you can record neural activity and you can basically offline model and check.
Can I predict, or can I detect the modulation corresponding with those different actions?
And so we did that task and we realized, Hey, there's actually some modulation associated with some of his hand motion, which was the first indication that, okay, we can potentially use that modulation to do useful things in the world.
Uh, for example, control a computer cursor, and he started playing with it, you know, the first time we showed him it, and we actually just took the same live view of his brain activity.
And put it in front of him.
And we said, Hey, you tell us what's going on.
Uh, you know, we're not, you, you're able to imagine different things and we know that it's modulating some of these neurons.
So you figure out for us what that is actually representing.
And so he played with it for a bit.
He was like, I don't quite get it yet.
He played for a bit longer and they said, oh, when I move this finger, I see this particular neuron start to fire more.
And I said, okay, prove it, do it again.
And so he said, okay, three, two, one.
Boom.
And the minute he moved, you can see like instantaneously.
This neuron is firing single neuron.
I can tell you the exact channel number.
If you're interested, it's stuck in my brain now forever.
But that single, uh, channel firing was a beautiful indication that it was behaved, really modulated neural activity that could then be used for downstream tasks like decoding a computer cursor.
And when you say single channel, is that associated with a single electrode?
Yeah.
So, uh, channel electrode are interchangeable and there's a 1,024 of those 1,024.
Yeah.
It's incredible that that works that really, when I was, um,
learning about all this and like loading it in, it was just blowing my mind that the intention, you can visualize yourself moving the finger that can turn into a signal.
And the fact that you can then skip that step and visualize the cursor moving or have the intention of the cursor moving and that leading to a signal that can then be used to move the cursor.
This, there is so many exciting things there to learn about the brain, about the way the brain works.
The very fact of their existing signal that can be used is really powerful.
Yep.
But it feels like that's just like the beginning of figuring out how that signal can be used really, really effectively.
I should also just, uh, there's so many fascinating details here, but you mentioned the body mapping step, uh, at least in the version I saw that Nolan was showing off.
There's like a super nice interface, like a graphical interface, but like, it just felt like I was like in the future.
Cause it like, uh, you know, I guess it visualizes you moving the hand and there's a very, like, like a sexy polished interface that hello, I don't know if there's a voice component, but it just felt like, uh, it's like when you wake up in a really nice video game and this is a tutorial at the beginning of that video game, this is what you're supposed to do.
It's cool.
No, I mean, the future should feel like the future, but it's not easy to pull that off.
I mean, it needs to be simple, but not too simple.
Yeah.
And I think the UX design component here is, uh, underrated for BCI, uh, development in general.
There's a whole interaction effect between the ways in which you visualize, uh, an instruction to the user and the kinds of signal you can get back.
And that quality of sort of your behavioral alignment to the neural signal is a function of how good you are at expressing to the user what you want them to do.
And so, yeah, we spend a lot of time thinking about the UX, uh, of how we build our applications of how the decoder actually functions, the control surfaces it provides to the user.
All these little details.
So maybe it'd be nice to get into a little bit more detail of what the signal looks like and what the decoding looks like.
So there's a, uh, N1 implant that has, like we mentioned, uh, uh, 1,024 electrodes and that's collecting raw data, raw signal.
What does that signal look like?
And, uh, what are the different steps along the way before it's transmitted and what is transmitted and all that kind of stuff?
Yeah.
Yep.
This is going to be a fun one.
Let's go.
Uh, so, uh, maybe before diving into what we do, it's worth understanding what we're trying to measure because, uh, that dictates a lot of the requirements for the system that we build.
And what we're trying to measure is really individual neurons producing action potentials.
And action potential is you can think of it like a little electrical impulse that you can, uh, detect if you're close enough.
And by being close enough, I mean like within, let's say a hundred microns of that cell and a hundred microns is a very, very tiny distance.
And so the number of neurons that you're going to pick up with any given electrode, is it just a small radius around that electrode?
And the other thing worth understanding about the underlying biology here is that when neurons produce an action potential, the width of that action potential is about one millisecond.
So from the start of the spike to the end of the spike, that whole width of that, uh, sort of characteristic feature of a neuron firing is one millisecond wide.
And if you want to detect that an individual spike is occurring or not, you need to sample that signal or sample.
Or sample the local field potential nearby that, uh, neuron much more frequently than once a millisecond, you need to sample many, many times per millisecond to be able to detect that this is actually the characteristic waveform of a neuron producing an action potential.
And so we sample across all 1,024 electrodes, about 20,000 times a second, 20,000 times a second means for already given one millisecond window.
We have about 20 samples that tell us what that exact shape of that action potential looks like.
And once we've sort of sampled at super high rate, uh,
underlying electrical field nearby, uh, these cells, we can process that signal into just where do we detect a spike or where do we not sort of a binary signal one or zero?
Do we detect a spike in this one millisecond or not?
And we do that because the actual information character carrying, uh, uh, sort of subspace of neural activity is just when our spikes occurring, essentially everything that we care about for decoding can be captured or represented in the frequency characteristics of spike trains.
Meaning.
How.
Often are spikes firing in any given window of time.
And so that allows us to do sort of a crazy amount of compression from this very rich, high density, uh, you know, signal to something that's much, much more sparse and compressible that can be sent out over a wireless, uh, radio, like a Bluetooth communication, for example.
Quick tangents here.
You mentioned electrode neuron.
There's a local neighborhood of neurons nearby.
How difficult is it to.
Like isolate from where the spike came from?
Yeah.
So there's a whole field of sort of academic neuroscience work on exactly this problem of basically given a single electrode or given a set of electrodes measuring a set of neurons.
How can you sort of sort spike sort, which spikes are coming from what, uh, neuron.
And this is a problem that's pursued in academic work because you care about it for understanding what's going on in the underlying sort of, uh, neuroscience of the, of the brain, if you care.
If you care about understanding how the brain's representing information, how that's evolving through time, then that's a very, very important question to, to understand for sort of the engineering side of things, at least at the current scale.
If the number of neurons per electrode is relatively small, you can get away with basically ignoring that problem completely.
You can think of it like sort of a random projection of neurons, two electrodes, and there may be in some cases more than one neuron per electrode, but if that number is small enough, those signals can be thought of as, uh, sort of a union of the two.
Mm-hmm.
And for many applications, that's a totally reasonable trade-off to make and can simplify the problem a lot.
And as you sort of scale out channel count, the, uh, relevance of distinguishing individual neurons becomes less important because you have more overall signal and you can start to rely on sort of correlations or covariance structure in the data to help understand when that channel is firing.
What does that, what does that actually represent?
Cuz you know that when that channel's firing in concert with these other 50 channels, that means move left.
But when that same channel's firing with concert with these other 10 channels, that means move right.
Okay.
So you have to do this kind of.
Spike detection on board and you have to do that super efficiently.
So fast and not use too much power cuz you don't wanna be generating too much heat.
So I have to be a super simple signal processing step.
Yeah.
Um, is there some wisdom you can share about what it takes to overcome that challenge?
Yeah.
So we've tried many different versions of basically turning this raw signal into, uh, sort of a feature that you might wanna send off the.
Device.
Yeah.
And I'll say that I don't think we're at the final step of this process.
This is a long journey.
We have something that works clearly today, but there can be many approaches that we find in the future that are much better than what we do right now.
So so some versions of what we do right now, and there's a lot of academic heritage to these ideas.
So I don't wanna, you know, claim that these are original neural link ideas or anything like that.
But, uh, one of these ideas is basically to build a sort of like a convolutional filter, almost, if you will, that slides across the signal and looks for a certain template to be matched.
And that template consists of sort of.
How deep the spike modulates, how much it recovers, and what the duration and window of time is that the whole process takes.
And if you can see in the signal that that template is matched within certain bounds, then you can say, okay, that's a spike.
One reason that approach is super convenient is that you can actually implement that extremely efficiently in hardware, which means that you can run it, uh, in low power across 1,024 channels all at once.
Another approach that we've recently started, uh, exploring, and this can be combined with the spike detection.
Approach is something called spike band power.
And the benefits of that approach are that you may be able to pick up some signal from neurons that are maybe too far away to be detected as a spike, because the farther away you are from an electrode, the weaker that actual spike waveform will look like on that electrode.
So, uh, you might be able to pick up, you know, population level activity of things that are, you know, maybe slightly outside the normal recording radius, what, what neuroscientists sometimes refer to as the hash of, uh, activity, the other stuff that's going on.
Yeah.
Uh, and you can look at sort of across many channels.
How.
How that, uh, sort of background noise is behaving.
You might be able to get more juice out of the signal that way, but it comes at a cost.
That signal is now a floating point representation, which means it's more expensive to send out over a power.
It means you have to find different ways to compress it that are different than what you can apply to binary signals.
So there's a lot of different challenges associated with these different modalities.
So also in terms of communication, you're limited by the amount of data you can send.
Yeah.
So, and also because you're currently using the Bluetooth protocol, you have to batch stuff together.
But you have to also do this, keeping the latency crazy low, like crazy low.
Anything to say about the latency?
Yeah, this is a passion project of mine.
So, uh, I want to build the best mouse in the world.
Yeah.
I don't want to build like the, you know, the Chevrolet spark or whatever of electric cars.
I want to build like the Tesla roadster version of, of a mouse.
And I really do think it's quite possible that within, you know, five to 10 years that most e-sports competitions are dominated by people with paralysis.
This is like.
A very real possibility for a number of reasons.
One is that they'll have access to the best technology to play video games effectively.
The second is they have the time to do so.
So those two factors together are particularly potent for, uh, e-sport competitors.
Unless, uh, people without paralysis are also allowed to implant, right.
Which is, it is another way to interact with a digital, uh, device.
And there's some, there's something to that.
If, if it's a fundamentally different experience.
More efficient experience, even if it's not like some kind of full on high bandwidth communication, if it's just the ability to move the mouse, uh, 10 X faster, like the bits per second, if I can achieve a bit per second, a 10 X, what I can do with the mouse, that's a really interesting possibility of what they can do, especially as you get really good at it, uh, with training.
It's definitely the case that you have a higher ceiling performance, like you, because you don't have to buffer your intention through your arm, through your muscle.
You get just by nature of having a brain implant at all, like 75 millisecond lead time on any action that you're actually trying to take.
And there's some nuance to this.
Like there there's evidence that the motor cortex, you can sort of plan out sequences of actions.
So you may not get that whole benefit all the time, but for a sort of like reaction time style, uh, games where you just want to, someone is over here, snipe them, you know, that kind of thing.
Uh, you actually do have just an inherent advantage because you don't need to go through muscle.
So the question is just how much faster can you make it?
And we're already, you know, faster than, uh, you know, what you're doing.
What you would do if you're going through muscle from a latency point of view, and we're in the early stage of that, I think we can push it sort of our end to end latency right now from brain spike to cursor movement.
It's about 22 milliseconds.
If you think about, uh, the best mice in the world, the best gaming mice, that's about five milliseconds ish of latency, depending on how you measure, depending how fast your screen refreshes.
There's a lot of characteristics that matter there, but yeah.
And the rough time for like a neuron in the brain to actually impact your, uh, command of your hand is about 75 milliseconds.
So if you look at those numbers, you can see that we're already.
Like, you know,
It's a lot faster than what you would get by actually moving your, moving your hand.
And this is something that, you know, if you ask Nolan about it, when he moved the cursor for the first time we asked him about this, it was something I was super curious about.
Like, what does it feel like when you're modulating, you know, a click intention, or when you're trying to just move the cursor to the right, he said it moves before he is like actually intending it to, which is kind of a surreal thing.
And something that, uh, you know, I would love to experience myself one day.
What does that like to have the thing just be so immediate, so fluid that it feels like it's happening before you're.
Uh, actually intending it to move.
Yeah.
I suppose we've gotten used to that latency, that natural latency that happens.
Uh, so is the currently the bottleneck, the communication.
So like the Bluetooth communication, is that what's the actual bottleneck?
I mean, there's always going to be a bottleneck, but what's the current bottleneck?
Yeah.
A couple of things.
So kind of hilariously Bluetooth, uh, low energy protocol has, uh, some restrictions on how fast you can communicate.
So the protocol itself establishes a standard of, you know, the most frequent sort of updates you can send are on the order of 7.5 milliseconds.
And, uh, as we push latency down to the level of sort of individual spikes, impacting control, that level of, of resolution, that kind of protocol is going to become a limiting factor at some scale.
Um, another sort of important nuance to this is that it's not just the, uh, Neuralink itself.
That's part of this equation.
If you start pushing latency sort of below the level of how fast screens refresh, then you have another problem.
Like you need your whole system to be able to, uh, be as reactive as the sort of limits of what the.
Technology can offer, like you need the screen, like 120 Hertz just doesn't, you know, work anymore.
If you're trying to have something respond at something that's, you know, at the level of one millisecond.
That's a really cool challenge.
I also like that for a t-shirt, the, uh, the best mouse in the world.
Tell me on the receiving end.
So the decoding step, now we, we figured out what the spikes are.
We've got them all together.
Now we're sending that over, uh, to the app.
What's the decoding step look like?
Yeah.
So maybe first, what is decoding?
I think there's probably a lot of folks listening that just have.
No.
No clue what, what it means to decode brain activity.
Actually, even if we zoom out beyond that, what is the app?
So there's a, there's an implant that's wirelessly communicating with any digital device that has an app installed.
Yep.
So maybe, can you tell me a high level, what the app is, what the software is outside of the, uh, the brain?
Yeah.
So maybe working backwards from the goal, the goal is to help someone with paralysis in this case, Nolan, be able to navigate his computer independently.
And.
Yeah.
We think the best way to do that is to offer them the same tools that we have to navigate our software, because we don't want to have to rebuild an entire software ecosystem for the brain, at least not yet.
Maybe someday you can imagine there's UXs that are built natively for BCI, but in terms of what's useful for people today, I think we, most people would prefer to be able to just control mouse and keyboard inputs to all the applications that they want to use for their daily jobs for communicating with their friends, et cetera.
And so the job of the application is really to translate this wireless stream of brain data coming off the implant.
Yeah.
And to control the computer.
And we do that by essentially building a mapping from brain activity to sort of the HID inputs to the, the actual hardware.
So HID is just the protocol for communicating like input device events.
So for example, move mouse.
To this position or press this key down.
And so that mapping is fundamentally what the app is responsible for, but there's a lot of nuance of how that mapping works that we spend a lot of time to try to get right.
And we're still in the early stages of a long journey to figure out how to do that optimally.
Uh, so one part of that process.
is decoding. So decoding is this process of taking the statistical patterns of brain data that's
being channeled across this Bluetooth connection to the application and turning it into, for example,
a mouse movement. And that decoding step, you can think of it in a couple different parts. So
similar to any machine learning problem, there's a training step and there's an inference step.
The training step in our case is a very intricate behavioral process where the user has to imagine
doing different actions. So for example, they'll be presented a screen with a cursor on it,
and they'll be asked to push that cursor to the right. Then imagine pushing that cursor to the
left, push it up, push it down. And we can basically build up a pattern or using any sort
of modern ML method of mapping of given this brain data and that imagined behavior, map one to the
other. And then at test time, you take that same pattern matching system, in our case, it's a deep
neural network, and you run it and you take the live stream of brain data coming off their implant,
you decode it by pattern matching to what you saw at calibration time, and you use that for
control of the computer.
Now, a couple like sort of rabbit holes that I think are quite interesting.
One of them has to do with how you build that best template matching system. Because there's a
variety of behavioral challenges and also debugging challenges when you're working with someone who's
paralyzed. Because again, fundamentally, you don't observe what they're trying to do. You can't see
them attempt to move their hand. And so you have to figure out a way to instruct the user to do
something and validate that they're doing it correctly, such that then you can downstream
build with confidence the map.
And so that's one of the things that I think is really important. And I think that's one of the
things that I think is really important. And by doing the action correctly, what I really mean is
at the level of resolution of what neurons are doing. So if in ideal world, you could get a
signal of behavioral intent that is ground truth accurate at the scale of sort of one millisecond
resolution, then with high confidence, I could build a mapping from my neural spikes to that
behavioral intention. But the challenge is, again, that you don't observe what they're actually
doing. And so there's a lot of nuance to how you build user experiences that gives you a lot of
information. And that gives you more than just sort of a course, on average, correct representation
of what the user's intending to do. If you want to build the world's best mouse, you really want it
to be as responsive as possible. You want it to be able to do exactly what the user's intending at
every sort of step along the way, not just on average, be correct when you're trying to move
it from left to right. And building a behavioral sort of calibration game or sort of software
experience that gives you that level of resolution is what we spend a lot of time working.
So the calibration process, the interface has to encourage,
encourage precision, being like, whatever it does, it should be super intuitive that the next
thing the human is going to likely do is exactly that intention that you need, and only that
intention. And you don't have any feedback except that may be speaking to you afterwards, what they
actually did. You can't, oh yeah. So that's fundamentally, that is a really exciting UX
challenge, because that's all on the UX. It's not just,
just about being friendly or nice or usable. It's like user experience is how it works.
It's how it works for the calibration and calibration, at least at this stage of Neuralink
is like fundamental to the operation of the thing and, and not just calibration,
but continued calibration, essentially. Yeah. And maybe you said something that I
think is worth exploring there a little bit. You said it's, you know, primarily a UX challenge.
And I think a large component of it is, but there is also a very interesting
machine.
Yeah.
Challenge here, which is given some, you know, a data set, including some on average,
correct behavior of asking the user to move up or move down, move right, left,
and given a data set of neural spikes, is there a way to infer in some kind of semi-supervised or
entirely unsupervised way, what that high resolution version of their intention is?
And if you think about it, like there probably is because there are enough data points in the data
set, enough constraints on your model, that there should be a way with the right sort of formulation
to like.
Let the model figure out itself, for example, at this millisecond, this is exactly how hard they're
pushing upwards. And at this millisecond, this is how hard they're trying to push upwards.
It's really important to have very clean labels. Yes. So like the problem,
because much harder from the machine learning perspective, the labels are noisy.
That's correct.
And then to get the clean labels, that's a UX challenge.
Correct. Although clean labels, I think maybe it's worth exploring what that exactly means. I think
any given labeling strategy will have some number of assumptions it makes about what the user's
attempting to do.
Those assumptions can be formulated in a loss function, or they can be formulated in terms of
heuristics that you might use to just try to estimate or guesstimate what the user is trying to
do. And what really matters is how accurate those assumptions. For example, you might say, hey,
user, push upwards and follow the speed of this cursor. And your heuristic might be that they're
trying to do exactly what that cursor is trying to do. Another competing heuristic might be they're
actually trying to go slightly faster at the beginning of the movement and slightly slower at
the end. And those competing heuristics may or may not be accurate reflections of what the user is
trying to do. Another version of the task might be, hey, user, imagine moving this cursor a fixed
offset. So rather than follow the cursor, just try to move it exactly 200 pixels to the right. So
here's the cursor, here's the target. Okay, cursor disappears, try to move that now invisible cursor
200 pixels to the right. And the assumption in that case would be that the user can actually
modulate correctly that position offset. But that position offset assumption might be a weaker
assumption. And therefore, potentially, you can make it more accurate than these heuristics that
are trying to guesstimate at each millisecond. So that's another version of the task.
Each millisecond what the user is trying to do. So you can imagine different tasks that make
different assumptions about the nature of the user intention. And those assumptions being correct is
what I would think of as a clean label. For that step, what are we supposed to be
visualizing? There's a cursor. And you want to move that cursor to the right or the left,
up and down, or maybe move them by a certain offset. So that's one way. Is that the best way
to do calibration? So for example, alternative crazy way that probably is playing a role here
is a game like Web Grid. Yeah.
Where you're just getting a very large amount of data, the person playing a game,
where if they are in a state of flow, maybe you can get clean signal as a side effect.
Yep.
Is that or is it is that not an effective way for initial calibration?
Yeah, great question. There's a lot to unpack there. So the first thing I would draw distinction
between is sort of open loop first closed loop. So open loop, what I mean by that is the user is sort
of going from zero to one. They have no model at all. And they're trying to get to the place where
they have some level of control at all. In that setup, you really need to have some task that
gives the user a hint of what you want them to do such that you can build this mapping again from
brain data to output. Then once they have a model, you could imagine them using that model and
actually adapting to it and figuring out the right way to use it themselves. And then retraining on
that data to give you sort of a boost in performance. There's a lot of challenges
associated with both of these techniques. And we can sort of rabbit hole into both of them if you've
interested. But the sort of challenge with the open loop task is that the user themselves doesn't
get proprioceptive feedback about what they're doing. They don't necessarily perceive themselves
or feel the mouse under their hand when they're trying to do an open loop calibration. They're
being asked to perform something. Like imagine if you sort of had your whole right arm numbed
and you stuck it in a box and you couldn't see it. So you had no visual feedback and you had
no proprioceptive feedback about what the position or activity of your arm was.
And now you're asked, okay, given this thing on the
screen that's moving from left to right, match that speed. And you basically can try your best to
invoke whatever that imagined action is in your brain that's moving the cursor from left to right.
But in any situation, you're going to be inaccurate and maybe inconsistent in how you do that
task. And so that's sort of the fundamental challenge of open loop.
The challenge with closed loop is that once the user is given a model and they're able to start
moving the mouse on their own, they're going to very naturally adapt to that model.
And that co-adaptation between the model learning what they're doing and the user learning how to use
the model may not find you the best sort of global minima. It may be that your first model was noisy
in some ways or maybe just had some quirk. There's some part of the data distribution
it didn't cover super well. And the user now figures out because they're a brilliant user
like Nolan, they figure out the right sequence of imagined motions or the right angle they have to
hold their hand at to get it to work. And they'll get it to work great. But then the next day they
come back to their device and maybe they don't remember exactly all the tricks and tricks they're
going to use the previous day. And so there's a complicated sort of feedback cycle here that can
emerge and can make it a very difficult debugging process.
Okay, there's a lot of really fascinating things there.
Yeah, actually, just to stay on the closed loop, I've seen situations, this actually happened
watching psychology grad students. They use a piece of software when they don't know how
to program themselves. They use a piece of software that somebody else wrote and it has a bunch of
bugs. Yeah.
And they figure out like, and they've been using it for years.
Yeah.
They figure out ways to work around. Oh, that just happens. Like nobody,
nobody like considers maybe we should fix this. They just adapt. And that's a really interesting
notion that we just said we're really good at adapting, but you need to still,
that might not be the optimal.
Yeah.
Okay. So how do you solve that problem? Do you have to restart
from scratch every once in a while kind of thing?
Yeah, it's a good question. First and foremost, I would say this is not a solved problem.
Yeah.
And for anyone who's, you know, listening in academia who works on BCIs,
I would also say this is not a problem that's solved by simply scaling channel count.
So this is, you know, maybe that can help and you can get sort of richer covariance structures that
you can use to exploit when trying to come up with good labeling strategies. But if you're
interested in problems that aren't going to be solved inherently by just scaling channel count,
this is one of them. Yeah. So how do you solve it? It's not a solved problem. That's the first
thing I want to make sure it gets across. The second thing is any solution that involves closed
loop is going to become a very difficult debug.
And one of my sort of general heuristics for
choosing what prompts to tackle is that you want to choose the one that's going to be the easiest
to debug. Because if you can do that, even if the ceiling is lower, you're going to be able to move
faster, because you have a tighter iteration loop debugging the problem. And in the open loop
setting, there's not a feedback cycle to debug with the user in the loop. And so there's some
reason to think that that should be an easier debugging problem. The other thing that's worth
understanding is that even in the closed loop setting, there's no special software that's
magic of how to infer what the user is truly attempting to do. In the closed loop setting,
although they're moving the cursor on the screen, they may be attempting something different than
what your model is outputting. So what the model is outputting is not a signal that you
can use to retrain, if you want to be able to improve the model further, you still have this
very complicated guesstimation or unsupervised problem of figuring out what is the true user
intention underlying that signal. And so the open loop problem has the nice property
of being easy to debug. And the second known property is that it has all the same information
content as a closed-loop scenario. Another thing I want to mention and call out is that this problem
doesn't need to be solved in order to give useful control to people. You know, even today with the
solutions we have now and that academia has built up over decades, the level of control that can be
given to a user, you know, today is quite useful. It doesn't need to be solved to get to that level
of control. But again, I want to build the world's best mouse. I want to make it, you know, so good
that it's not even a question that you want it. And to build the world's best mouse, the superhuman
version, you really need to nail that problem. And a couple maybe details of previous studies that
we've done internally that I think are very interesting to understand when thinking about
how to solve this problem. The first is that even when you have ground truth data of what the user
is trying to do, and you can get this with an able-bodied monkey, a monkey that has an Erlang
device implanted and moving a mouse to control a computer, even with that ground truth data set,
it turns out that the
optimal thing to predict to produce high performance BCI is not just the direct control
of the mouse. You can imagine, you know, building a data set of what's going on in the brain and
what is the mouse exactly doing on the table. And it turns out that if you build the mapping
from neural spikes to predict exactly what the mouse is doing, that model will perform worse
than a model that is trained to predict sort of higher level assumptions about what the user
might be trying to do. For example, assuming that the monkey is trying to go in a straight
line to the target. It turns out that making those assumptions is actually more effective
in producing a model than actually predicting the underlying hand movement.
So the intention, not like the physical movement or whatever.
Yeah.
There's obviously a very strong correlation between the two, but the intention is a more
powerful thing to be chasing.
Right.
Well, that's also super interesting. I mean, the intention itself is fascinating because,
yes, with the BCI here, in this case, with digital telepathy, you're acting on the intention,
not the action, which is why there's an experience of like,
feeling like it's happening before you meant for it to happen. That is so cool. And that is why
you could achieve like superhuman performance probably in terms of the control of the mouse.
So for OpenLoop, just to clarify, so whenever the person is tasked to like move the mouse to
the right, you said there's not feedback. So they don't get to get that satisfaction of like
actually getting it to move, right?
So you could imagine giving the user feedback on a screen,
but...
It's difficult because at this point, you don't know what they're attempting to do. So what can
you show them that would basically give them a signal of I'm doing this correctly or not correctly?
So let's take this very specific example. Like maybe your calibration task looks like you're
trying to move the cursor a certain position offset. So your instructions to the user are,
hey, the cursor's here. Now, when the cursor disappears, imagine moving it 200 pixels from
where it was to the right to be over this target. In that kind of scenario, you could imagine coming
up with some sort of consistency metric that you could display to the user of, okay, I know what the
spike train looks like.
On average, when you do this action to the right, maybe I can produce some sort of probabilistic
estimate of how likely is that to be the action you took, given the latest trial or trajectory
that you imagined. And that could give the user some sort of feedback of how consistent are they
across different trials. You could also imagine that if the user is prompted with that kind of
consistency metric, that maybe they just become more behaviorally engaged to begin with,
because the task is kind of boring when you don't have any feedback at all. And so there may be
benefits to the, you know, the user experience of the trial. And so that's something that you could
look at, you know, the user experience of showing something on a screen, even if it's not accurate,
just because it keeps the user motivated to try to increase that number or push it upwards.
So there's a psychology element here.
Yeah, absolutely.
And again, all of that is UX challenge. How much signal drift is there? Hour to hour,
day to day, week to week, month to month? How often do you have to recalibrate
because of the signal drift?
Yeah. So this is a problem we've worked on both with
NHP, non-human primates before our clinical trial, and then also with Noland during the clinical
trial. Maybe the first thing that we're stating is what the goal is here. So the goal is really
to enable the user to have a plug and play experience where, I guess they don't have to
plug anything in, but a play experience where they, you know, can use the device whenever they
want to, however they want to. And that's really what we're aiming for. And so there can be a set
of solutions that get to that state without considering this non-stationarity problem.
So maybe the first solution here that's important is that they can recalibrate,
recalibrate whenever they want. This is something that Noland has the ability to do today. So he can
recalibrate the system, you know, at 2 AM in the middle of the night without his, you know,
caretaker or parents or friends around to help push a button for him. The other important part
of the solution is that when you have a good model calibrated, that you can continue using that
without needing to recalibrate it. So how often he has to do this recalibration today depends really
on his appetite for performance. We observe sort of a degradation through time of how well any
individual model works.
But this can be mitigated behaviorally by the user adapting their control strategy.
It can also be mitigated through a combination of sort of software features that we provide to the
user. For example, we let the user adjust exactly how fast the cursor is moving. We call that the
gain, for example, the gain of how fast the cursor reacts to any given input intention.
They can also adjust the smoothing, how smooth the output of that cursor intention actually is.
They can also adjust the friction, which is how easy is it to stop and hold still.
And all these software tools allow the user a great deal of flexibility and troubleshooting
mechanisms.
To be able to solve this problem for them.
By the way, all of this is done by looking to the right side of the screen, selecting the mixer
and the mixer you have.
It's like DJ mode. DJ mode for your PCI.
I mean, it's a really well done interface. It's really, really well done. And so yeah,
there's that bias that there's a cursor drift that Nolan talked about in a stream.
Although he said that you guys were just playing around with it with him
and they're constantly improving. So that could have been just a snapshot of that.
Particular moment, a particular day. But he said that there was
this cursor drift and this bias that could be removed by him, I guess, looking to the right
side of the screen, the left side of the screen to kind of adjust the bias.
Yeah.
That's one interface action, I guess, to adjust the bias.
Yeah. So this is actually an idea that comes out of academia.
There is some prior work with sort of brain gate clinical trial participants where they
pioneered this idea of bias correction. The way we've done it, I think is, yeah, it's, you know,
very prioritized, very beautiful user experience where the user can essentially
flash the cursor over to the side of the screen and it opens up a window where they can actually
sort of adjust or tune exactly the bias of the cursor. So bias maybe for people who aren't
familiar is just sort of what is the default motion of the cursor if you're imagining nothing.
And it turns out that that's one of the first sort of qualia of the cursor control experience
that's impacted by neural non-stationarity. Qualia of the cursor experience.
I mean, I don't know how else to describe it. Like, you know,
I'm not the I'm not the guy moving thing.
It's very poetic. I love it. The qualia of the cursor experience.
Yeah. I mean, it sounds poetic, but it is deeply true. There is an experience
when it works well, it is a joyful, a really pleasant experience. And when
it doesn't work well, it's a very frustrating experience. That's actually the Bach of UX.
It's like, you have the possibility to frustrate people or the possibility to give them joy.
Yes.
That's awesome.
That's awesome.
Awesome.
It's going to be a close one.
the end of the day it really is truly the case that ux is how the thing works and so it's not
just like what's showing on the screen it's also you know what control surfaces does a decoder
provide the user like we want them to feel like they're in the f1 car not like the you know some
like minivan right you and that really truly is how we think about it um nolan himself is an f1
fan so um we refer to ourself as a pit crew he really is truly the f1 driver and there's different
you know control surfaces that that different kinds of cars and airplanes provide the user
and we take a lot of inspiration from that when designing how the cursor should behave
and what maybe one nuance of this is you know even details like when you move a mouse on a
macbook trackpad the sort of response curve of how that uh input that you give the trackpad
translates to cursor movement is different than how it works with a mouse when you move
on the trackpad there's a different response function a different curve to how much a
movement translates to input to the computer than when you do it physically with a mouse
and that's because somebody sat down a long time ago when they're designing the initial
input systems to
the computer as far as they can and they're designing the initial input systems to any
computer as far as they can and they're designing the initial input systems to any computer
and they thought through exactly how it feels
to use these different systems.
And now we're designing sort of the next generation
of this input system to a computer,
which is entirely done via the brain.
And there's no proprioceptive feedback.
Again, you don't feel the mouse in your hand.
You don't feel the keys under your fingertips.
And you want a control surface
that still makes it easy and intuitive
for the user to understand the state of the system
and how to achieve what they want to achieve.
And ultimately, the end goal is that that UX
is completely, it fades into the background
and it becomes something that's so natural and intuitive
that it's subconscious to the user.
And they just should feel like they have
basically direct control over the cursor.
It just does what they want it to do.
They're not thinking about the implementation
of how to make it do what they want it to do.
It's just doing what they want it to do.
Is there some kind of things along the lines
of like Fitt's law where you should move the mouse
in a certain kind of way that maximizes your chance
to hit the target?
I don't even know what I'm asking,
but I'm hoping the intention of my question
will land on a profound answer.
No.
Is there some kind of understanding
of the laws of UX when it comes
to the context of somebody using their brain
to control it?
Like that's different than actual with a mouse.
I think we're in the early stages
of discovering those laws.
So I wouldn't claim to have solved that problem yet,
but there's definitely some things we've learned
that make it easier for the user to get stuff done.
And it's pretty straightforward when you verbalize it,
but it takes a while to actually get to that point
when you're in the process of debugging this stuff
in the trenches.
One of those things is that
any machine learning system you build
has some number of errors.
And it matters how those errors translate
to the downstream user experience.
For example, if you're developing a search algorithm
in your photos, if you search for your friend Joe
and it pulls up a photo of your friend Josephine,
maybe that's not a big deal
because the cost of an error is not that high.
So I think it's important to understand that.
In a different scenario
where you're trying to detect insurance fraud
or something like this
and you're directly sending someone to court
because of some machine learning model output,
then the errors make a lot more sense to be careful about.
You want to be very thoughtful
about how those errors translate to downstream effects.
The same is true in BCI.
So for example, if you're building a model
that's decoding a velocity output from the brain
versus an output where you're trying
to modulate the left click, for example,
these have sort of different trade-offs
of how precise you need to be
before it becomes useful.
For velocity, it's okay to be on average correct
because the output of the model
is integrated through time.
So if the user's trying to click at position A
and they're currently at position B,
they're trying to navigate over time
to get between those two points.
And as long as the output of the model
is on average correct,
they can sort of steer it through time
with the user control loop in the mix,
they can get to the point they want to get to.
The same is not true of a click.
For a click, you're performing it almost instantly
at the scale of neurons firing.
And so you want to be very sure
that that click is correct
because a false click can be very destructive to the user.
They might accidentally close the tab
that they're trying to do something in
and lose all their progress.
They might accidentally hit some send button
on some text that is only half composed
and reads funny after.
So there's different sort of cost functions
associated with errors in this space.
And part of the UX design is understanding
how to build a solution that is,
when it's wrong, still useful to the end user.
That's so fascinating.
Assigning cost to everything,
every action, when an error occurs.
So every action, if an error occurs,
has a certain cost.
And incorporating that
into how you interpret the intention,
mapping it to the action,
is really important.
I didn't quite, until you said it,
realize there's a cost
to sending the text early.
It's a very expensive cost.
Yeah, it's super annoying.
If you're a cursor,
imagine if your cursor misclicked every once in a while.
That's super obnoxious.
And the worst part of it is,
usually, when the user's trying to click,
they're also holding still
because they're over the target they want to hit
and they're getting ready to click.
Which means that in the data sets that we build,
on average, it's the case that low speeds
or desire to hold still is correlated with
when the user's attempting to click.
Wow, that is really fascinating.
It's also not the case,
people think that, oh, click is a binary signal.
This must be super easy to decode.
Well, yes, it is.
But the bar is so much higher
for it to become a useful thing for the user.
And there's ways,
there's ways to solve this.
I mean, you can sort of take the compound approach of,
well, let's just give the,
like, let's take five seconds to click.
Let's take a huge window of time
so we can be very confident about the answer.
But again, world's best mouse.
The world's best mouse doesn't take a second to click
or 500 milliseconds to click.
It takes five milliseconds to click or less.
And so if you're aiming for that kind of high bar,
then you really want to solve the underlying problem.
So maybe this is a good place to ask about
how to measure performance,
this whole bits per second.
What, can you like explain what you mean by that?
That may be a good place to,
to start is to talk about WebGrid as a game
as a good illustration of the measurement of performance.
Yeah.
Maybe I'll take one zoom out step there,
which is just explaining why we care to measure this at all.
So again, our goal is to provide the user
the ability to control the computer as well as I can
and hopefully better.
And that means that they can do it
at the same speed as what I can do.
It means that they have access
to all the same functionality that I have,
including, you know, all those little details
like command tab, command space,
you know, all this stuff.
Then you'd be able to do it with their brain
and with the same level of reliability
as what I can do with my mouse.
And that's a high bar.
And so we intend to measure
and quantify every aspect of that
to understand how we're progressing towards that goal.
There's many ways to measure BPS, by the way.
This isn't the only way,
but we present the user a grid of targets.
And basically we compute a score,
which is dependent on how fast and accurately they can select
and then how small are the targets.
And the more targets that are on the screen,
the smaller they are,
the more information you present per click.
And so if you think about it
from information theory point of view,
you can communicate across
different information theoretic channels.
And one such channel is a typing
interface you could imagine
that's built out of a grid,
just like a software keyboard on the screen.
And bits per second is a measure
that's computed by taking the log
of the number of targets on the screen.
You can subtract one
if you care to model a keyboard
because you have to subtract one
for the delete key on the keyboard.
But log of the number of targets on the screen
times the number of correct selections
minus incorrect,
divided by some time window,
for example, 60 seconds.
And that's sort of the standard way
to measure a cursor control task in academia.
And all credit in the world
goes to this great professor,
Dr. Chenoy of Stanford,
who came up with that task.
And he's also one of my inspirations
for being in the field.
So all the credit in the world to him
for coming up with a standardized metric
to facilitate this kind of bragging rights
that we have now to say that
Nolan is the best in the world
at this task with his BCI.
It's very important for progress
that you have standardized metrics
that people can compare across
different techniques and approaches.
How well does this do?
So yeah, big kudos to him
and to all the team at Stanford.
Yeah, so for Nolan
and for me playing this task,
there's also different modes
that you can configure this task.
So the Web Grid task
can be presented as
just sort of a left click on the screen,
or you could have, you know,
targets that you just dwell over,
or you could have targets
that you left right click on.
You could have targets
that are left right click,
middle click, scrolling,
clicking and dragging.
You know, you can do all sorts of things
within this general framework.
But the simplest, purest form
is just blue targets
show up on the screen.
Blue means left click.
That's the simplest form of the game.
And the sort of prior records here
in academic work
and at Neuralink internally
with sort of NHPs
have all been
matched or beaten by Nolan
with his Neuralink device.
So sort of prior to Neuralink,
the sort of world record
for a human using the device
is somewhere between 4.2 to 4.6 BPS,
depending on exactly what paper you read
and how you interpret it.
Nolan's current record is 8.5 BPS.
And again, the sort of median
Neuralink performance is 10 BPS.
So you can think of it roughly
as he's 85% the level of control
of a median Neuralinker
using their cursor
to select blue targets on the screen.
And yeah, I think
there's a very interesting journey ahead
to get us to that same level
of 10 BPS performance.
It's not the case that
sort of the tricks that got us
from, you know, 4 to 6 BPS
and then 6 to 8 BPS
are going to be the ones
that get us from 8 to 10.
And in my view,
the core challenge here
is really the labeling problem.
It's how do you understand
at a very, very fine resolution
what the user is attempting to do?
And yeah, I highly encourage
folks in academia
to work on this problem.
What's the journey with Nolan
on that quest of increasing
the BPS on WebGrid?
In March, you said
that he selected
89,285 targets in WebGrid.
Yep.
So he loves this game.
He's really serious
about improving his performance
in this game.
So what is the journey
of trying to figure out
how to improve that performance?
How much can that be done
on the decoding side?
How much can that be done
on the calibration side?
How much can that be done
on the Nolan side
of like figuring out
how to convey his intention
more cleanly?
Yeah, no, this is a great question.
So in my view,
one of the primary reasons
why Nolan's performance is so good
is because of Nolan.
Nolan is extremely focused
and very energetic.
He'll play WebGrid sometimes
for like four hours
in the middle of the night,
like from 2 a.m. to 6 a.m.
He'll be playing WebGrid
just because he wants to push it
to the limits of what he can do.
And, you know, this is not us
like asking him to do that.
I want to be clear.
Like we're not saying,
hey, you should play WebGrid tonight.
We just gave him the game
as part of our research, you know,
and he is able to play independently
and practice.
Whenever he wants
and he really pushes hard to push it.
The technology is the absolute limit.
And he views that as like,
you know, his job really
to make us be the bottleneck.
And boy, has he done that well.
And so that's the first thing
to acknowledge is that, you know,
he is extremely motivated
to make this work.
I've also had the privilege
to meet other, you know,
clinical trial participants
from BrainGate and other trials.
And they very much
share the same attitude of like,
they view this as their life's work
to, you know, advance the technology
as much as they can.
And if that means
selecting targets on the screen
for four hours from 2 a.m.
to 6 a.m.,
then so be it.
And there's something
extremely admirable about that
that's worth calling out.
Okay.
So now, how do you sort of get
from where he started,
which is no cursor control to 8BPS?
So, I mean, when he started,
there's a huge amount of learning
to do on his side and our side
to figure out
what's the most intuitive control for him.
And the most intuitive control for him
is sort of,
you have to find the set intersection
of what do we have the signal to decode?
So we don't pick up, you know,
every single neuron in the motor cortex,
which means we don't have representation
for every part of the brain.
So there may be some signals
that we have better sort of
decode performance on than others.
For example, on his left hand,
we have a lot of difficulty
distinguishing his left ring finger
from his left middle finger.
But on his right hand,
we have a good, you know,
good control and good modulation
detected from the neurons
that we're able to record
for his pinky and his thumb
and his index finger.
So you can imagine
how these different, you know,
subspaces of modulated activity
intersect with what's
the most intuitive for him.
And this has evolved over time.
So once we gave him the ability
to calibrate models on his own,
he was able to,
go and explore
various different ways
to imagine controlling the cursor.
For example,
he can imagine controlling the cursor
by wiggling his wrist side to side
or by moving his entire arm
by having to get one point
into his feet.
You know, he tried like
a whole bunch of stuff
to explore the space
of what is the most natural way
for him to control the cursor
that at the same time
is easy for us to decode.
Just to clarify,
it's through the body mapping procedure
that you're able to figure out
which finger he can move?
Yes.
Yeah, that's one way to do it.
Maybe one nuance of the
when he's doing it,
he can imagine many more things
than we represent
in that visual on the screen.
So we show him sort of abstractly,
here's a cursor.
You figure out
what works the best for you.
And we obviously have hints
about what will work best
from that body mapping procedure of,
you know, we know that
this particular action
we can represent well,
but it's really up to him
to go and explore
and figure out what works the best.
But at which point does
he no longer visualize
the movement of his body
and he's just visualizing
the movement of the cursor?
Yeah.
How quickly does he go from,
how quickly does it
get there?
So this happened on a Tuesday.
I remember this day very clearly
because at some point
during the day,
it looked like he wasn't
doing super well.
It looked like the model
wasn't performing super well
and he was like getting distracted.
But he actually,
it wasn't the case.
Like what actually happened was
he was trying something new
where he was just
controlling the cursor.
So he wasn't imagining
moving his hand anymore.
He was just imagining,
I don't know what it is,
some like abstract intention
to move the cursor on the screen.
And I cannot tell you
what the difference
between those two things are.
I really truly cannot.
He's tried to explain it
to me before.
I cannot, you know,
give a first person account
of what that's like.
But the expletives
that he uttered in that moment
were, you know,
enough to suggest
that it was a very
qualitatively different
experience for him to
just have direct
neural control over a cursor.
I wonder if there's a way
through UX
to encourage a human being
to discover that.
Because he discovered it,
like you said to me,
that he's a pioneer.
So he discovered that
on his own
through all of this,
the process of trying to
try to move the cursor
with different kinds of intentions.
But that is clearly
a really powerful thing
to arrive at,
which is to let go
of trying to control
the fingers and the hand
and control the actual
digital device with your mind.
That's right.
UX is how it works.
And the ideal UX
is one that it's
the user doesn't
have to think about
what they need to do
in order to get it done.
They just,
it just does it.
Yeah.
That is so fascinating.
But I wonder on the,
on the biological side,
how long it takes
for the brain to adapt.
Yeah.
So is it just simply
learning
like high level software
or is there like
a neuroplasticity component
where like the,
the brain is adjusting slowly?
Yeah.
The truth is,
I don't know.
I'm very excited to see
with sort of the second participant
that we implant,
what the,
you know,
what the journey is like for them.
Because we'll have learned
a lot more.
Potentially,
we can help them understand
and explore that direction
more quickly.
This is something I didn't,
you know,
this wasn't me prompting
Nolan to go try this.
He was just exploring
how to use his device
and figure it out himself.
But now that we know
that that's a possibility
that maybe there's a way to,
you know,
for example,
hint the user,
don't try super hard
during calibration.
Just do something
that feels natural
or just directly
control the cursor.
You know,
don't imagine explicit action.
And from there,
we should be able to
hopefully understand
how this is for somebody
who has not experienced
that before.
Maybe that's the default
mode of operation for them.
You don't have to go
through this intermediate
phase of explicit motions.
Or maybe if that naturally
happens for people,
you can just
occasionally encourage them
to allow themselves
to move the cursor.
Right.
Actually,
sometimes just like
with a four minute mile,
just the knowledge
that that's possible.
Pushes you to do it.
Yeah.
Enables you to do it
and then it becomes trivial.
And then it also
makes you wonder,
this is the cool thing
about humans.
Once there's a lot more
human participants,
they will discover
things that are possible.
Yes.
And share their experiences
with each other.
And that because
of them sharing it,
they'll be able to do it.
All of a sudden,
that's unlocked
for everybody.
Yeah.
Because just the knowledge
sometimes is the thing
that enables it to do it.
Yeah.
I mean,
just coming on that too,
like there's,
we've probably tried
like a thousand different ways
to do various
aspects of decoding.
And now we know
like what the right subspace
is to continue exploring
further.
Again,
thanks to Nolan
and the many hours
he's put into this.
And so even just that
help like help
constrain sort of
the beam search
of different approaches
that we could explore
really helps
accelerate for the next person.
You know,
the set of things
that we'll get to try
on day one,
how fast we hope
to get them to useful control,
how fast we can enable
them to use it independently
and to get value
out of the system.
So yeah,
massive hats off
to Nolan
and all the participants
that came before him
to make this technology
a reality.
So how often
are the updates
to the decoder?
Because Nolan mentioned
like,
okay,
there's a new update
that we're working on
and that in the stream
he said he plays
the snake game
because it's like
super hard.
It's a good way
for him to test
like how good
the update is.
So,
and he says like
sometimes the update
is a step backwards.
It's like,
it's a constant
like iteration.
So how often,
like what does
the update entail?
Is it mostly
on the decoder side?
Yeah,
a couple comments.
So one is,
it's probably worth
drawing distinction
between sort of
research sessions
where we're actively
trying different things
to understand like
what the best approach is
versus sort of
independent use
where we wanted to have
the ability to just
go use the device
how anybody would want
to use their MacBook.
And so what he's referring to
is I think usually
in the context
of,
in the research session
where we're trying
many, many different approaches
to even unsupervised approaches
like we talked about earlier
to try to come up
with better ways
to estimate his true intention
and more accurately decode it.
And in those scenarios,
I mean,
we try in any given session,
he'll sometimes work
for like eight hours a day.
And so that can be
hundreds of different models
that we would try
in that day,
like a lot
of different things.
Now,
it's also worth noting
that we update
the application
he uses quite frequently.
I think sometimes
up to like four
or five times a day
we'll update his application
with different features
or bug fixes
or feedback
that he's given us.
So he's been able to,
he's a very articulate person
who is part of the solution.
He's not a complaining person.
He says,
hey,
here's this thing
that I've discovered
is not optimal in my flow.
Here's some ideas
how to fix it.
Let me know
what your thoughts are.
Let's figure out
how to solve it.
And it often happens
that those things
are addressed
within a couple hours
of him giving us his feedback.
That's the kind
of iteration cycle
we'll have.
And so sometimes
at the beginning
of the session
he'll give us feedback
and at the end
of the session
he's giving us feedback
on the next iteration
of that process.
That's fascinating
because one of the things
you mentioned
that there's 271 pages
of notes
taken from the BCI sessions
and this was just in March.
So one of the amazing things
about human beings
that they can provide,
especially ones
who are smart
and excited
and all like positive
and good vibes
like Nolan,
that they can provide feedback,
continuous feedback.
It also requires,
just to brag on the team
a little bit,
I work with a lot
of exceptional people
and it requires the team
being absolutely
laser focused
on the user
and what will be
the best for them.
And it requires
a level of commitment
of, okay,
this is what the user feedback was.
I have all these meetings.
We're going to skip that today
and we're going to do this.
That level of focus
and commitment
is, I would say,
underappreciated
in the world.
And also,
you obviously have
to have the talent
to be able to execute
on these things effectively.
And yeah,
we have that in loads.
Yeah,
and this is such
an interesting space
of UX design
because,
there's so many
unknowns here.
And I can tell
UX is difficult
because of how many
people do it poorly.
It's just not
a trivial thing.
It's also,
UX is not something
that you can
always solve
by just constant
iterating on different things.
Sometimes you really
need to step back
and think globally,
am I even in the right
sort of minima
to be chasing down
for a solution?
There's a lot of problems
in which fast iteration cycle
is the,
the predictor
of how successful
you will be.
As a good example,
like in an RL simulation,
for example,
the more frequently
you get a reward,
the faster you can progress.
It's just an easier
learning problem
the more frequently
you get feedback.
But UX is not that way.
I mean,
users are actually
quite often wrong
about what the right
solution is.
And it requires
a deep understanding
of the technical system
and what's possible
combined with what
the problem is
you're trying to solve.
Not just how the user
expressed it,
but what the true
underlying problem is
to actually get
to the right place.
Yeah,
that's the old,
like,
stories of Steve Jobs,
like,
rolling in there,
like,
yeah,
the user is a good,
is a useful signal,
but it's not
a perfect signal.
And sometimes
you have to remove
the floppy disk drive
or whatever the,
I forgot,
all the crazy stories
of Steve Jobs,
like,
making wild
design decisions.
But there,
some of it
is aesthetic
that
some of it
is about
the love
you put into
the design,
which is very much
a Steve Jobs
Steve Jobs
Steve Jobs
Johnny Ives
type thing.
But when you have
a human being
using their brain
to interact with it,
it also is deeply
about function.
It's not just
aesthetic.
And that,
you have to empathize
with a human being
before you
while not always
listening to them
directly.
Like,
you have to deeply
empathize.
It's fascinating.
It's really,
really fascinating.
And at the same time,
iterate, right?
But not iterate
in small ways.
Sometimes it's a complete
like,
rebuilding the design.
He said that,
Nolan said,
in the early days,
the UX sucked.
Yeah.
But you improved quickly.
What was that journey like?
Yeah, I mean,
I'll give one concrete example.
So,
he really wanted
to be able to read manga.
This is something that he,
I mean,
it sounds like a simple thing,
but it's actually
a really big deal for him.
And he couldn't do it
with this mouse stick.
It just,
it wasn't accessible.
You can't scroll
with a mouse stick
on his iPad
on the website
that he wanted
to be able to use
to read the,
the newest manga.
And so,
Might be a good quick pause
to say the mouse stick
is the thing he's using,
holding a stick
in his mouth
to scroll
on a tablet.
Right, yeah.
It's basically,
you can imagine
it's a stylus
that you hold
between your teeth.
Yeah.
It's basically
a very long stylus.
And it's exhausting,
it hurts,
and it's inefficient.
Yeah.
And maybe it's also
worth calling out,
there are other
alternative assistive technologies,
but that particular situation
Nolan's in,
and this is not uncommon,
and I think it's also
not well understood by folks,
is that,
you know,
he's relatively spastic,
so he'll have muscle spasms
from time to time.
And so,
any assistive technology
that requires him
to be positioned
directly in front of a camera,
for example,
an eye tracker,
or anything that requires him
to put something in his mouth,
just is a no-go,
because he'll either
be shifted out of frame
when he has a spasm,
or if he has something
in his mouth,
it'll stab him in the face,
you know,
if he spasms too hard.
So,
these kind of considerations
are important
when thinking about
what advantages a PCI
has in someone's life.
If it fits ergonomically
into your life
in a way that you can use it
independently
when your caretaker's not there,
or in the chair,
depending on,
you know,
your comfort level
and your desire
to have pressure sores,
you know,
all these factors matter a lot
in how good the solution is
in that user's life.
So,
one of these
very fun examples
is scroll.
So,
again,
Manga is something
he wanted to be able to read,
and
there's many ways
to do scroll with a PCI.
You can imagine,
like,
different gestures,
for example,
the user could do
that would move the page.
But scroll is a very fascinating
control surface
because
it's a huge thing
on the,
on the screen
in front of you.
So,
any sort of jitter
in the model output,
any sort of error
in the model output
causes,
like,
an earthquake
on the screen.
Like,
you really don't want
to have your Manga page
that you're trying to read
be shifted up
and down
a few pixels
just because,
you know,
your scroll decoder
is not completely accurate.
And so,
this was an example
where
we had to figure out
how to formulate
the problem
in a way
that the errors
of the system,
whenever they do occur,
and we'll do our best
to minimize them,
but whenever those errors
do occur,
that it doesn't interrupt
the qualia,
again,
of the experience
that the user is having.
It doesn't interrupt
their flow
of reading their book.
And so,
what we ended up building
is this
really brilliant
feature.
This is a teammate
named Bruce
who worked on this
really brilliant work
called QuickScroll.
And QuickScroll
basically looks at the screen
and it identifies
where on the screen
are scroll bars.
And it does this
by deeply integrating
with macOS
to understand
where are the scroll bars
actively present
on the screen
using the sort of
accessibility tree
that's available
to macOS apps.
And we identified
where those scroll bars
are and provided
a BCI scroll bar.
And the BCI scroll bar
looks similar
to a normal scroll bar,
but it behaves
very differently
in that once you sort of
move over to it,
your cursor sort of
morphs onto it.
It sort of attaches
or latches onto it.
And then once you
push up or down
in the same way
that you'd use
a push to control
the normal cursor,
it actually moves
the screen for you.
So, it's basically
like remapping
the velocity
to a scroll action.
And the reason
that feels so natural
and intuitive
is that when you move
over to attach to it,
it feels like magnetic.
So, you're like
sort of stuck onto it.
And then it's
one continuous action.
You don't have to like
switch your imagined movement.
You sort of snap onto it
and then you're good to go.
You just immediately
can start pulling the page down
or pushing it up.
And even once you
get that right,
there's so many
little nuances
of how the scroll behavior works
to make it natural
and intuitive.
So, one example
is momentum.
Like when you scroll
a page with your fingers
on the screen,
you know,
you actually have
some like flow.
Like it doesn't just stop
right when you lift
your finger up.
The same is true
with BCI scroll.
So, we had to spend
some time to figure out
what are the right nuances
when you don't feel
the screen under
your fingertip anymore.
What is the right
sort of dynamic
or what's the right
amount of page give,
if you will,
when you push it
to make it flow
the right amount
for the user to have
a natural experience
reading their book.
And there's a million,
I mean, there's,
I could tell you like
there's so many
little minutiae
of how exactly
that scroll works
that we spent
probably like a month
getting right
to make that feel
extremely natural
and easy for the user
to get.
I mean, even the scroll
on a smartphone
with your finger
feels extremely
natural and pleasant.
And it probably
takes an extremely
long time
to get that right.
And actually,
the same kind
of visionary
UX design
that we were
talking about.
Don't always listen
to the users,
but also listen
to them
and also have
like visionary
big like
throw everything
out,
think from
first principles,
but also not.
Yeah, yeah.
By the way,
it just makes me think
that scroll bars
on the desktop
probably have
stagnated
and never taken
that,
like because
the snap
same as it's like
snap to grid
snap to scroll bar
action you're talking
about is something
that could
potentially be
extremely useful
in the desktop setting.
Yeah.
Even just for
users to just
improve the experience
because the current
scroll bar experience
and the desktop
is horrible.
Yeah.
It's hard to find,
hard to control.
There's not a momentum.
There's
and the intention
should be clear
when I start moving
towards the scroll bar,
there should be a
snapping to the scroll bar
action.
But of course,
you know,
maybe I'm okay
paying that cost,
but there's
hundreds of millions
of people paying
that cost nonstop.
But anyway,
but in this case,
this is necessary
because there's
an extra cost
paid by Nolan
for the jitteriness.
So you have to switch
between the scrolling
and the reading.
There has to be
a phase shift
between the two.
Like when you're
scrolling,
you're scrolling.
Right, right.
So that is one drawback
of the current
approach.
Maybe one other
just sort of
case study here.
So again,
UX is how it works
and we think about
that holistically
from like the
even the feature detection
level of what we detect
in the brain
to how we design
the decoder,
what we choose to decode
to then how it works
once it's being used
by the user.
So another good example
in that sort of
how it works
once they're actually
using the decoder,
you know,
the output that's
displayed on the screen
is not just what
the decoder says.
It's also a function
of, you know,
what's going on
on the screen.
So we can understand,
for example,
that, you know,
when you're trying
to close a tab,
that very small
stupid little X
that's extremely tiny
which is hard
to get precisely hit
if you're dealing
with sort of a noisy
output of the decoder,
we can understand
that that is a small
little X you might
be trying to hit
and actually make it
a bigger target for you.
Similar to how
when you're typing
on your phone,
if you're, you know,
used to like the
iOS keyboard,
for example,
it actually adapts
the target size
of individual keys
based on an underlying
language model.
So it'll actually
understand if I'm typing,
hey, I'm going to see L,
it'll make the E key
bigger because it knows
Lex is the person
I'm going to go see.
And so that kind of,
you know, predictiveness
can make the experience
much more smooth
even without, you know,
improvements to the
underlying decoder
or feature detection
part of the stack.
So we do that with a feature
called magnetic targets.
We actually index the screen
and we understand,
okay, these are the places
that are, you know,
very small targets
that might be difficult to hit.
Here's the kind of
cursor dynamics
around that location
that might be indicative
of the user trying
to select it.
Let's make it easier.
Let's blow up the size
of it in a way
that makes it easier
for the user to sort of
snap onto that target.
So all these little details,
they matter a lot
in helping the user
be independent
in their data.
So how much of the work
on the decoder
is generalizable
to P2, P3, P4, P5, Pn?
How do you improve
the decoder
in a way that's generalizable?
Yeah, great question.
So the underlying signal
we're trying to decode
is going to look
very different in P2
than in P1.
For example,
channel number 345
is going to mean
something different
in user 1
than it will in user 2
just because that electrode
that corresponds
with channel 345
is going to be
next to a different neuron
in user 1
versus user 2.
But the underlying
approach is the methods,
the user experience
of how do you get
the right sort of
behavioral pattern
from the user
to associate
with that neural signal
we hope will translate
over multiple
generations of users.
And beyond that,
it's very, very possible,
in fact, quite likely
that we've overfit
to sort of Nolan's
user experience
desires and preferences.
And so what I hope
to see is that
when we get
a second, third,
fourth participant
that we find
sort of what the right
wide minimas are
that cover all the cases
that make it more intuitive
for everyone.
And hopefully there's
a cross-pollination
of things where,
oh, we didn't think
about that with this user.
Because, you know,
they can speak.
But with this user
who just can fundamentally
not speak at all,
this user experience
is not optimal.
And that will actually,
those improvements
that we make there
should hopefully translate
then to even people
who can speak
but don't feel
comfortable doing so
because we're in a public
setting like their
doctor's office.
So the actual mechanism
of open-loop labeling
and then closed-loop
labeling
will be the same
and hopefully
can generalize
across the different users
as they're doing
the calibration step.
And the calibration
step is going to
be pretty cool.
I mean,
that in itself,
the interesting thing
about WebGrid,
which is like closed-loop,
it's like fun.
I love it
when there's like,
there used to be
kind of an idea
of human computation,
which is using
actions a human
would want to do anyway
to get a lot of signal from.
And like WebGrid
is that,
like a nice video game
that also serves
as great calibration.
It's so funny.
This is,
I've heard this reaction
so many times.
Before sort of
the first user
was implanted,
we had an internal
perception that
the first user
would not find this fun.
And so we thought
really quite a bit
actually about like,
should we build other games
that like are,
you know,
more interesting for the user
so we can get this kind of data
and help facilitate research
that's, you know,
for long duration
and stuff like this.
It turns out that like
people love this game.
I always loved it,
but I didn't know
that that was
a shared perception.
Yeah.
And just in case
it's not clear,
WebGrid is,
there's a grid of,
let's say,
35 by 35 cells
and one of them
lights up blue
and you have to move
your mouse over that.
And click on it.
And if you miss it
and it's red and...
I played this game
for so many hours.
So many hours.
And what's your record,
you said?
My,
I think I have the highest
at Neuralink right now.
My record's 17 BPS.
17 BPS.
Which is about,
if you imagine that
35 by 35 grid,
you're hitting about
100 trials per minute.
So 100 correct selections
in that one minute window.
So you're averaging about,
you know,
between 500,
600 milliseconds
per selection.
So one of the reasons
that I think
I struggle with that game
is I'm such a keyboard person.
So everything
is done with your keyboard.
If I can avoid
touching the mouse,
it's great.
So how can you
explain your high performance?
I have like a whole ritual
I go through
when I play WebGrid.
So it's actually
like a diet plan
associated with this.
Like it's a whole thing.
So the first thing is...
I have to fast for five days.
I have to go up to the mountains.
Actually,
it kind of,
I mean,
the fasting thing is important.
So this is like,
you know...
It focuses the mind, yeah.
Yeah.
It's true.
So what I do is I,
actually I don't eat
for a little bit beforehand.
And then I'll actually eat
like a ton of peanut butter
right before.
This is a real thing.
This is a real thing, yeah.
And then it has to be
really late at night.
This is, again,
a night owl thing
I think we share.
But it has to be like,
you know,
midnight, 2 a.m.
kind of time window.
And I have a very specific
like physical position
I'll sit in,
which is...
I used to be,
I was homeschooled growing up
and so I did most of my work
like on the floor,
just like in my bedroom
or whatever.
And so I have a very
specific situation...
On the floor.
On the floor
that I sit and play.
And then you have to make sure
like there's not a lot of weight
on your elbow
when you're playing
so that you can move quickly.
And then I turn the gain
of the cursor,
so the speed of the cursor
way, way up.
So it's like small motions
that actually move the cursor.
Are you moving with your wrist
or you're never...
I move with my fingers.
So my wrist is almost
completely still.
I'm just moving my fingers.
Yeah.
You know those,
just on a small tangent,
which I've been meaning
to go down this rabbit hole
of people that set
the world record in Tetris.
Those folks,
they're playing,
there's a way to...
Did you see this?
It seems like all the fingers
are moving.
Yeah.
You could,
you could find a way
to do it
where like it's
using a loophole
like a bug
that you can do
some incredibly fast stuff.
So it's,
it's along that line
but not quite.
But you do realize
there'll be like a few
programmers right now
listening to this
who will fast
and eat peanut butter.
Yeah, please,
please break my record.
I mean,
the reason I did this
literally was just because
I wanted the bar
to be high.
Like I wanted the,
the number that we aim for
should not be like
the median performance.
It should be like,
it should be able to beat
all of us at least.
Like that should be
the minimum bar.
What do you think is possible?
Like 20?
Yeah.
I don't know what the limit,
I mean,
the limits you can calculate
just in terms of
like screen refresh rate
and like cursor
immediately jump
into the next target.
But there's,
I mean,
I'm sure there's limits
before that with
just sort of reaction time
and visual perception
and things like this.
I'd guess it's in the
below 40,
but above 20,
somewhere in there.
It's probably that right
that I never be thinking about.
It also matters like
how difficult the task is.
You can imagine like
some people might be able
to do like 10,000 targets
on the screen
and maybe they can do
better that way.
So there's some like
task optimizations
you could do
to try to,
boost your performance
as well.
What do you think
it takes for Nolan
to be able to do
above 8.5
to keep increasing
that number?
You said like
every increase
in the number
might require different,
yeah,
different improvements
in the system.
Yeah,
I think the nature
of this work is,
the first answer
that's important to say
is I don't know.
This is,
you know,
edge of the research.
So again,
nobody's gotten
to that number before.
So what's next
is going to be,
you know,
a heuristic guess
from my part.
What we've seen
historically is that
different parts
of the stack
become bottlenecks
at different time points.
So,
you know,
when I first joined
Erlink like three years
ago or so,
one of the major problems
was just the latency
of the Bluetooth connection.
It was just like
the radio on the device
wasn't super good.
It was an earlier
revision of the implant
and it just like,
no matter how good
your decoder was,
if your thing is updating
every 30 milliseconds
or 50 milliseconds,
it's just going to be choppy
and no matter
how good you are,
that's going to be
frustrating and lead
to challenges.
So,
you know,
at that point,
it was very clear
that the main challenge
is just get the data
off the device
in a very reliable way
such that you can enable
the next challenge
to be tackled.
And then,
you know,
at some point,
it was,
you know,
actually the modeling challenge
of how do you
just build a good mapping,
like the supervised
learning problem
of you have a bunch of data
and you have a label
you're trying to predict,
just what is the right
like neural decoder architecture
and hyperparameters
to optimize that.
That was the problem
for a bit.
And once you solve that,
it became a different bottleneck.
I think the next bottleneck
after that was actually
just sort of
software stability
and reliability.
You know,
if you have
widely varying
sort of inference latency
in your system
or your,
you know,
your app just lags out
every once in a while,
it decreases your ability
to maintain
and get in a state of flow
and it basically just disrupts
your control experience.
And so,
there's a variety
of different software bugs
and improvements we made
that basically increased
the performance of the system,
made it much more reliable,
much more stable,
and led to a state
where we could reliably
collect data
to build better models with.
So,
that was a bottleneck
for a while.
It's just sort of like
the software stack.
If I were to guess
right now,
there's sort of
two major directions
you could think about
for improving BPS further.
The first major direction
is labeling.
So,
labeling is,
again,
this fundamental challenge
of given
a window of time
where the user is expressing
some behavioral intent,
what are they really
trying to do
at the granularity
of every millisecond?
And that,
again,
is a task design problem,
it's a UX problem,
it's a machine learning problem,
it's a software problem.
Sort of touches
all those different domains.
The second
thing you can think about
to improve BPS further
is either completely
changing the thing
you're decoding
or just extending
the number of things
that you're decoding.
So,
this is sort of
in the direction
of functionality.
Basically,
you can imagine
giving more clicks.
For example,
a left click,
a right click,
a middle click,
different actions
like click and drag,
for example,
and that can improve
the effective bit rate
of your communication
processes.
If you're trying to
allow the user
to express themselves
through any given
communication channel,
you can measure that
with bits per second,
but what actually
matters at the end
of the day
is how effective
are they at navigating
their computer.
And so,
from the perspective
of the downstream tasks
that you care about,
functionality and
extending functionality
is something we're
very interested in
because not only
can it improve
the sort of number
of BPS,
but it can also
improve the downstream
sort of independence
that the user has
and the skill and efficiency
with which they can
operate their computer.
Would the number
of threads increasing
also potentially help?
Yes.
Short answer is yes.
It's a bit nuanced
how that curve
or how that manifests
in the numbers.
So,
what you'll see
is that if you
sort of,
plot a curve
of number of channels
that you're using
for decode
versus either
the offline metric
of how good
you are at decoding
or the online metric
of sort of,
in practice,
how good is the user
at using this device,
you see roughly
a log curve.
So,
as you move
further out
in number of channels,
you get a corresponding
sort of logarithmic
improvement
in control quality
and offline validation metrics.
The important nuance
here is that
each channel
corresponds
with a specific
you know,
represented intention
in the brain.
So, for example,
if you have a channel
254,
it might correspond
with moving to the right.
Channel 256
might mean move to the left.
If you want to
expand the number
of functions
you want to control,
you really want to have
a broader set of channels
that covers a broader
set of imagined movements.
You can think of it like,
kind of like
Mr. Potato Man, actually.
Like, if you had
a bunch of different
imagined movements
you could do,
how would you map
those imagined movements
to input to a computer?
You could imagine,
you know,
handwriting to output
characters on the screen.
You could imagine
just type,
type in with your fingers
and have that output
text on the screen.
You could imagine
different finger modulations
for different clicks.
You could imagine
wiggling your big nose
for opening some menu
or wiggling your,
you know,
your big toe
to have like
command tab occur
or something like this.
So, it's really
the amount of different actions
you can take in the world
depends on how many channels
you have
and the information content
that they carry.
Right, so that's more
about the number of actions.
So, actually,
as you increase
the number of threads,
that's more about
increasing
the number of actions
you're able to
perform.
One other nuance there
that is worth mentioning.
So, again,
our goal is really
to enable a user
with paralysis
to control their computer
as fast as I can.
So, that's BPS
with all the same
functionality I have,
which is what we just
talked about,
but then also
as reliably as I can.
Yeah.
And that last point
is very related
to channel count discussion.
So, as you scale out
the number of channels,
the relative importance
of any particular feature
of your model input
to the output control
of the user diminishes,
which means that
if the sort of
neural non-stationarity effect
is per channel,
or if the,
if the noise is independent
such that more channels
means on average
less output effect,
then your reliability
of your system
will improve.
So, one sort of
core thesis
that at least I have
is that scaling channel count
should improve
the reliability of the system
without any work
on the decoder itself.
Can you linger
on reliability here?
So, first of all,
when you say
non-stationarity
of the signal,
which aspect
are you referring to?
Yeah.
So, maybe let's talk briefly
what the actual
underlying signal looks like.
So, again,
I spoke very briefly
at the beginning
about how
when you imagine
moving to the right
or imagine moving to the left,
neurons might fire
more or less.
And the frequency content
of that signal,
at least in the motor cortex,
is very correlated
with the output intention
or the behavioral task
that the user is doing.
You can imagine, actually,
this is not obvious,
that rate coding,
which is the name
of that phenomenon,
is like the only way
the brain can represent information.
You can imagine
many different ways
in which the brain
could encode intention.
And there's actually evidence
like in bats, for example,
that there's temporal codes,
so timing codes,
of like exactly
when particular neurons fire
is the mechanism
of information representation.
But at least
in the motor cortex,
there's substantial evidence
that it's rate coding
or at least one
like first-order effect
is that it's rate coding.
So then,
if the brain
is representing information
by changing
the sort of frequency
of a neuron firing,
what really matters
is sort of the delta
between sort of
the baseline state
of the neuron
and what it looks like
when it's modulated.
And what we've observed
and what has also been observed
in academic work
is that that baseline rate,
sort of the,
if you're to target the scale,
if you imagine
that analysis,
analogy for like measuring,
you know,
flour or something
when you're baking,
that baseline state
of how much the pot weighs
is actually different
day to day.
And so,
if what you're trying to measure
is how much rice is in the pot,
you're going to get
a different measurement
different days
because you're measuring
with different pots.
So that baseline rate shifting
is really the thing that,
at least from a first-order
description of the problem,
is what's causing
this downstream bias.
There can be other effects,
nonlinear effects
on top of that,
but at least at a very
first-order description
of the problem,
that's what we observe
day to day
is that the baseline firing rate
of any particular
neuron,
or observed
on a particular channel
is changing.
So can you just
adjust to the baseline
to make it relative
to the baseline nonstop?
Yeah,
this is a great question.
So,
with monkeys,
we have found
various ways to do this.
One example way to do this
is you ask them
to do some
behavioral task
like play the game
with a joystick.
You measure what's going on
in the brain.
You compute some mean
of what's going on
across all the input features
and you subtract that
in the input
when you're doing
your BCI session.
Works super well.
For whatever reason,
that doesn't work
super well with Nolan.
I actually don't know
the full reason why,
but I can imagine
several explanations.
One such explanation
could be that
the context effect difference
between some open-loop task
and some closed-loop task
is much more significant
with Nolan
than it is with a monkey.
Maybe in this open-loop task
he's watching
the Lex Freeman podcast
while he's doing the task
or he's whistling
and listening to music
and talking with his friend
and asking his mom
what's for dinner
while he's doing this task.
And so the exact
sort of difference
in context
between those two things
states may be much larger
and thus lead to a bigger
generalization gap
between the features
that you're normalizing
at open-loop time
and what you're trying
to use at closed-loop time.
That's interesting.
Just on that point,
it's kind of incredible
to watch Nolan
be able to do
to multitask
to do multiple tasks
at the same time
to be able to move
the mouse cursor effectively
while talking
and while being nervous
because he's talking
in front of me.
Kicking my ass
in chess too.
Kicking your ass
and talk trash
while doing it.
So all at the same time.
And yes,
if you're trying
to normalize
to the baseline
that might throw
everything off.
Boy, is that interesting.
Maybe one comment
on that too.
For folks that aren't familiar
with assistive technology,
I think there's a common
belief that, you know,
well, why can't you just
use an eye tracker
or something like this
for helping somebody
move a mouse on the screen?
And it's really
a fair question
and one that
I actually was not confident
before from Nolan
that this was going to be
a profoundly transformative
technology for people
like him.
And I'm very confident
now that it will be
but the reasons are subtle.
It really has to do
with ergonomically
how it fits into their life.
Even if you can just
offer the same level
of control
as what they would have
with an eye tracker
or with a mouse stick.
But you don't need
to have that thing
in your face.
You don't need to be
positioned in a certain way.
You don't need your caretaker
to be around
to set it up for you.
You can activate it
when you want,
how you want,
wherever you want.
That level of independence
is so game changing
for people.
It means that they can
text a friend at night
privately without their mom
needing to be in the loop.
It means that they can
like open up,
you know,
and browse the internet
at 2 a.m.
when nobody's around
to set their iPad up for them.
This is like
a profoundly
game changing thing
for folks in that situation.
And this is even before
we start talking about folks
that, you know,
may not be able
to communicate at all
or ask for help
when they want to.
This can be the,
potentially the only link
that they have
to the outside world.
And yeah,
that one doesn't,
I think,
need explanation
of why that's so impactful.
You mentioned
neural decoder.
How much machine learning
is in the decoder?
How much magic?
How much science?
How much art?
How difficult
is it?
How difficult is it
to come up with a decoder
that figures out
what these
sequence of spikes mean?
Yeah,
good question.
There's a couple
different ways
to answer this.
So maybe I'll zoom out
briefly first
and then I'll go down
one of the rabbit holes.
So the zoomed out view
is that building the decoder
is really the process
of building the data set
plus compiling it
into the weights.
And each of those steps
is important.
The direction,
I think,
of further improvement
is primarily going to be
in the data set side
of how do you construct
the optimal labels
for the model.
But there's an entirely
separate challenge
of then how do you
compile the best model?
And so I'll go briefly
down the second one,
down the second rabbit hole.
One of the main challenges
with designing
the optimal model
for BCI
is that offline metrics
don't necessarily
correspond to online metrics.
It's fundamentally
a control problem.
The user is trying
to control something
on the screen.
And the exact
sort of user experience
of how
you output
the intention
impacts their ability
to control.
So, for example,
if you just look
at validation loss
as predicted by your model,
there can be multiple ways
to achieve the same
validation loss.
Not all of them
are equally controllable
by the end user.
And so,
you know,
it might be as simple
as saying,
oh, you could just
add auxiliary loss terms
that, like,
help you capture
the thing that actually matters.
But this is a very
complex, nuanced process.
So how you turn
the labels into the model
is more of a nuanced process
than just, like,
a standard supervised
learning problem.
One very fascinating
anecdote here,
we've tried many different
sort of neural network
architectures
that translate
brain data
to velocity outputs,
for example.
And one example
that stuck in my brain
from a couple years ago now
is we,
at one point,
we were using
just fully connected networks
to decode
the brain activity.
We tried an A-B test
where we were measuring
the relative performance
in online control sessions
of sort of
one deconvolution
over the input signal.
So if you imagine
per channel,
you have a sliding window
that's producing
some convolve feature
for each of those
inputs
that sequences
for every single channel
simultaneously,
you can actually get
better validation metrics,
meaning you're fitting
the data better
and it's generalizing
better in offline data
if you use this
convolutional architecture.
You're reducing parameters,
it's sort of a standard
procedure when you're
dealing with time-series data.
Now it turns out
that when using
that model online,
the controllability
was worse,
was far worse,
even though the
offline metrics were better.
And there can be many ways
to interpret that,
but what that taught me
at least was that,
hey, it's at least
the case right now
that if you were to just
throw a bunch of
compute at this problem,
and you were trying
to sort of
hyperparameter optimize
or let some GPT model
hard code come up
with or invent
many different solutions,
if you were just
optimizing for loss,
it would not be sufficient,
which means that there's
still some inherent
modeling gap here.
There's still some artistry
left to be uncovered here
of how to get your model
to scale with more compute,
and that may be
fundamentally a labeling problem,
but there may be
other components
to this as well.
Is it data constraint
at this time?
Which is what it sounds like.
Like, how do you get
a lot of good labels?
Yeah, I think it's
data quality constrained,
not necessarily
data quantity constrained.
But even like,
even just the quantity,
I mean, because it has
to be trained
on the interactions.
I guess there's not
that many interactions.
Yeah, so it depends
what version of this
you're talking about.
So if you're talking about,
let's say the simplest example
of just 2D velocity,
then I think, yeah,
data quality is the main thing.
If you're talking about
how to build a sort of
multifunction output
that lets you do
all the inputs,
the computer that you
and I can do,
then it's actually
a much more sophisticated
and nuanced modeling challenge
because now you need
to think about
not just when the user
is left-clicking,
but when you're building
the left-click model,
you also need to be thinking
about how to make sure
it doesn't fire
when they're trying
to right-click
or when they're trying
to move the mouse.
So one example
of an interesting bug
from like sort of week one
of BCI with Nolan
was when he moved the mouse,
the click signal
sort of dropped off a cliff
and when he stopped,
the click signal went up.
So again,
there's a contamination
between the two inputs.
Another good example
was at one point
he was trying to do
sort of a left-clicking drag
and the minute
he started moving,
the left-click signal
dropped off a cliff.
So again,
because there's some contamination
between the two signals,
you need to come up
with some way
to either in the data set
or in the model
build robustness
against this kind of,
you can think of it
like overfitting,
but really it's just
that the model
has not seen
this kind of variability before.
So you need to find some way
to help the model with that.
This is super cool
because it feels like
all of this is very solvable,
but it's hard.
Yes,
it is fundamentally
an engineering challenge.
This is important to emphasize
and it's also important
to emphasize that
it may not need
fundamentally new techniques,
which means that
people who work on,
let's say,
unsupervised speech classification
using CTC loss,
for example,
with internal theory,
they could potentially
have very applicable skills
to this.
So what things
are you excited about
in the future development
of the software stack
on Neuralink?
So everything
we've been talking about,
the decoding,
the UX.
I think there's some
I'm excited about,
like something I'm excited about
from the technology
side and some I'm excited
about for understanding
how this technology
is going to be best situated
for entering the world.
So I'll work backwards
on the technology
entering the world
side of things.
I'm really excited
to understand
how this device works
for folks that,
you know,
cannot speak at all,
that have no ability
to sort of bootstrap
themselves into useful
control by voice command,
for example,
and are extremely limited
in their current capabilities.
I think that will be
an incredibly useful
signal for us
to understand,
I mean,
really what is an existential
threat for all startups,
which is product market fit.
Does this device
have the capacity
and potential to transform
people's lives
in the current state?
And if not,
what are the gaps?
And if there are gaps,
how do we solve them
most efficiently?
So that's what I'm very
excited about for the next
year or so of clinical
trial operations.
The technology side,
I'm quite excited
about basically
everything we're doing.
I think it's going
to be awesome.
The most prominent
one I would say
is scaling channel count.
So right now we have
a thousand channel device.
The next version
we'll have between
three and six thousand
channels,
and I would expect
that curve to continue
in the future.
And it's unclear
what set of problems
will just disappear
completely at that scale
and what set of problems
will remain and require
further focus.
And so I'm excited
about the clarity
of gradient that that
gives us in terms
of the user experiences
we choose to focus
our time and resources
on and also in terms
of the even things
as simple as
non-stationarity.
Like, does that problem
just completely go away
at that scale?
Or do we need to come
up with new creative
UX's still even
at that point?
And also when we get
to that time point,
when we start expanding
out dramatically
the set of functions
that you can output
from one brain,
how to deal with
all the nuances
of both the user
experience of not
being able to feel
the different keys
under your fingertips
but still need to be
able to modulate
all of them in synchrony
to achieve the thing
you want.
And again, you don't
have that properly
set to feedback loop,
so how can you make
that intuitive for a user
to control a high
dimensional control
surface without feeling
the thing physically?
I think that's going
to be a super
interesting problem.
I'm also quite excited
to understand,
you know, do these
scaling laws continue?
Like, as you scale
channel count,
how much further out
do you go before
that saturation point
is truly hit?
And it's not obvious
today.
I think we only know
what's in the sort of
interpolation space.
We only know what's
between zero and 1024,
but we don't know
what's beyond that.
And then there's a
whole sort of like
range of interesting
sort of neuroscience
and brain questions,
which is when you
stick more stuff
in the brain
in more places,
you get to learn
much more quickly
about what those
brain regions represent.
And so I'm excited
about that fundamental
neuroscience learning,
which is also important
for figuring out
how to most efficiently
insert electrodes
in the future.
So yeah, I think
all those dimensions
I'm really, really
excited about,
and that doesn't even
get close to touching
the sort of software
stack that we work
on every single day
and what we're
working on right now.
Yeah, it seems
virtually impossible
to me that a thousand
electrodes is where
it saturates.
It feels like this
would be one of those
silly notions in the
future where obviously
you should have
millions of electrodes
and this is where
like the true
breakthroughs happen.
You tweeted,
some thoughts are
most precisely
described as
described in poetry.
Why do you think that is?
I think it's because
the information
bottleneck of language
is pretty steep.
And yet you're able
to reconstruct
in the other person's brain
more effectively
without being literal.
Like if you can express
the sentiment such that
in their brain,
they can reconstruct
the actual true underlying
meaning and beauty
of the thing that you're
trying to get across,
that sort of the
thing that you're
trying to express.
So the generator function
in their brain is more
powerful than what
language can express.
And so the mechanism
of poetry is really
just to feed or
seed that generator
function.
So being literal
sometimes is a sub-optimal
compression for the
thing you're trying to
convey.
That's right.
And it's actually in the
process of the user
going through that
generation that they
understand what you
mean.
Like that's the
beautiful part.
It's also like when you
look at a beautiful
painting, like it's not
the pixels of the
painting that are
beautiful.
It's the thought process
that occurs when you see
that, the experience of
that, that actually is
the thing that matters.
Yeah.
It's resonating with
some deep thing within
you that the artist also
experienced and was able
to convey that through
the pixels.
Right.
And that's actually
going to be relevant for,
for, for full-on
telepathy.
You know, it's like,
if you just read the
poetry literally, that
doesn't say much of
anything interesting.
It requires a human to
interpret it.
So it's the combination
of the human mind and
all the experiences that
human, human being has
within the context of
the collective intelligence
of the human species that
makes that poem make
sense.
And they, they load that
in.
And so in that same
way, the signal that
carries from human to
human, uh, meaning might
not, may seem trivial,
but may actually carry a
lot of power, uh, because
of the complexity of the
human mind and the
receiving end.
Yeah.
That's interesting.
I, poetry still doesn't,
who was it?
I think, uh, Yoshibaku
first of all, she always
said, uh, uh, something
about all the people that
think we've achieved AGI
explain why humans like
music.
Oh yeah.
And, and until, until the
AGI likes music, you haven't
achieved AGI or something.
Like, do you not think
that's like some next
token entropy, surprise
kind of thing going on?
I don't know.
I don't know either.
I, I listen to a lot of
classical music and also
read a lot of poetry.
And, uh, yeah, I do wonder
if like, there is some
element of the next token
surprise factor going on
there.
Yeah, maybe.
Cause I mean, like a lot
of the tricks in both
poetry and music are like,
basically you have some
repeated structure and then
you do like a twist.
Yeah.
Like it's like, okay.
Verse or like clause one,
two, three is one thing.
And then clause four is
like, okay, now we're onto
the next theme.
Yeah.
And it, they kind of play
with exactly when the
surprise happens and the
expectation of the user.
And that's even true.
Like through history, as
musicians evolve music, they
take like some known
structure that people are
familiar with and they just
tweak it a little bit.
Like they tweak it and add
a surprising element.
It's especially true in
like in classical music
heritage, but that's what I'm
wondering.
Like, is it all just
entropy?
Like the, the, so, so
break, so breaking structure
or breaking symmetry is
something that humans seem
to like maybe as simple as
that.
Yeah.
And I mean, great artists
copy, uh, and they also, you
know, knowing which rules to
break is the important
part and fundamentally it
must be about the, the
listener of the piece.
Like which rules is the
right one to break is about
the user or the audience
member perceiving that as
interesting.
Uh, what do you think is
the meaning of human
existence?
There's a TV show I really
like called the West wing.
And in, uh, in the West wing,
there's a character.
He's the president of the
United States.
Who's, uh, having a discussion
about the Bible with one of
their colleagues and, uh,
what the colleague says
something about, you know, the
Bible says X, Y, and Z.
And, uh, the president says,
yeah, but it also says ABC.
And, uh, person says, well, do
you believe the Bible to be
literally true?
And the president says, yes, but
I also think that neither of us
are smart enough to understand
it.
I think to like the analogy here
for the meaning of life is that
largely we don't know the right
question to ask.
And so I'm, I think I'm very
aligned with, uh, sort of the
hitchhikers.
Guide the galaxy version of this
question, which is basically if
we can ask the right questions,
it's much more likely we find
the meaning of human existence.
And so in the short term as a
heuristic in the sort of search
policy space, we should try to
increase the diversity of, uh,
people asking such questions or
generally of consciousness and
conscious beings asking such
questions.
Um, so again, I think I'll take
the, I don't know card here, but
say, I do think there are
meaningful things we can do that
improve the likelihood of
answering that question.
It's interesting how much
value you assign to the task of
asking the right questions.
That's the, that's the main thing
is not the answers is the
questions.
This point, by the way, is driven
home, uh, in a very painful way
when you try to communicate with
someone who cannot speak, because
a lot of the time, the last thing
to go is they have the ability to
somehow, you know, wiggle a lip or
move something that allows them to
say yes or no.
And in that situation, it's very
obvious that what matters is, are you
asking them?
The right question to be able to
say yes or no to.
Wow.
That's powerful.
Well, bliss, thank you for everything
you do and thank you for being you.
And thank you for talking today.
Thank you.
Thanks for listening to this
conversation with bliss Chapman.
And now dear friends, here's Nolan
Arbaugh, the first human being to have
a neural link device implanted in his
brain.
You had a diving accident in 2016 that
left you paralyzed with no feeling from
the shoulders down.
How did that accident change your life?
There's sort of a freak thing that happened.
Uh, imagine you're running into the ocean.
Um, all of this is a lake, but you're
running into the ocean and you get to
about waist high, and then you kind of
like dive in, take the rest of the plunge
under the wave or something.
That's what I did.
Um, and then I just never came back up.
Not sure what happened.
Uh, I did it running.
I was running into the water with a
couple of guys, and so my idea of what
happened is really just that I took like
a stray fist, elbow, knee, foot, something
to the side of my head.
Uh, the left side of my head was sore
for about a month afterwards.
So it must've taken a pretty big knock.
And then, uh, they both came up and I
didn't, and so I was face down in the
water for a while.
I was conscious.
Um.
And then eventually just, you know,
realized I couldn't hold my breath any longer.
And I keep saying, took a big drink.
Um, people, I don't know if they like that.
I say that it seems like I'm making light of it
all, but, um, this is kind of how I am.
And I don't know, like I'm a very relaxed
sort of stress-free person.
I rolled with the punches.
Um, for a lot of this, I kind of took it in stride.
It's like, all right, well, what can I do next?
How can I improve my life even a little bit, um, on a
day-to-day basis at first, just trying to find some way
to heal as much of my body as possible, um, to try
to get healed, to try to get off a ventilator, um,
learn as much as I could.
So I could somehow survive, um, once I left the hospital.
Um.
And then thank God I had like my family around me.
If I didn't have my parents, uh, my siblings, then I would
have never made it this far.
They've done so much for me.
Um, more than like I can ever thank them for honestly.
And a lot of people don't have that.
A lot of people in my situation, their families either aren't capable of
providing for them or honestly just don't want to, and so they get placed somewhere.
And, you know, in some sort of home.
Uh, so thankfully I had my family.
I have a great group of friends, a great group of buddies from college who have all rallied
around me and we're all, um, still incredibly close.
People always say, you know, if you're lucky, you'll end up with one or two friends from
high school that you keep throughout your life.
I have, uh, about 10, 10 or 12 from high school that have all stuck around and we still get
together all of us.
Twice a year.
Um, we call it the spring series and the fall series.
Um, this last one we all did, uh, we dressed up like X-Men.
So I did a professor Xavier and it was freaking awesome.
It was so good.
So yeah, I have such a great support system around me.
And so, you know, being a quadriplegic isn't that bad.
I get weighted on, um, all the time.
People bring me food and drinks and I get to sit around and watch as much tea.
V and movies and anime as I want.
I get to read as much as I want.
Um, I mean, it's, it's great.
It's beautiful to see that you see the silver lining in all of this.
Uh, it was just going back.
Do you remember the moment when you first realized you're paralyzed from the neck down?
Yep.
I was face down in the water.
Um, right when I, whatever, something hit my head.
I, um, tried to get up.
And I realized I couldn't move and it just sort of clicked.
I'm like, all right, I'm paralyzed.
Can't move.
What do I do?
Um, if I can't get up, I can't flip over, can't do anything.
Then I'm going to drown eventually.
Um, and I knew I couldn't hold my breath forever.
So I just held my breath and thought about it for maybe 10, 15 seconds.
Um, I've heard from other people that like look on liquors, I guess the,
two girls that pulled me out of the water were two of my best friends.
They are lifeguards.
Um, and one of them said that, um, it looked like my body was sort of shaking in the water.
Like I was trying to flip over and stuff.
Um, but I knew, I knew immediately.
And I just kind of, I realized that that's like what my situation was from here on out.
Maybe if I got to the hospital, they'd be able to do something.
When I was in the hospital,
like right before surgery, I was trying to calm, uh, one of my friends down.
I had like brought her with me from college to camp and she was just bawling over me.
And I was like, Hey, it's going to be fine.
Like, don't worry.
Um, I was cracking some jokes to try to lighten the mood.
Um, the nurse had called my mom and I was like, don't tell my mom.
Um, she's just going to be stressed out.
Call her after I'm out of surgery.
Cause at least she'll have some answers then like whether I live or not really.
Um, and I didn't want her to be.
I didn't want her to be stressed through the whole thing, but I knew.
And then when I first woke up after surgery, um, I was super drugged up.
Uh, they had me on fentanyl like three ways, which was awesome.
Um, I don't, I don't recommend it, but, um, I saw, I saw some crazy stuff, uh, on that
fentanyl and it was still the best I've ever felt, uh, on drugs, um, medication, sorry,
on medication.
Um, and.
Uh, I remember the first time I saw my mom in the hospital, I was just bawling.
I had like ventilator in, um, like I couldn't talk or anything.
And, uh, I just started crying because it was more like seeing her.
Not that, I mean, the whole situation obviously was pretty rough, but, uh, it
was just like seeing her face for the first time was pretty hard, but, um, yeah,
I just, I never had like a moment of.
You know, man, I'm paralyzed, this sucks.
I don't want to like be around anymore.
It was always just, I hate that I have to do this, but like sitting here and wallowing
isn't going to help.
So immediate acceptance.
Yeah.
Yeah.
Has there been low points along the way?
Yeah.
Yeah, sure.
Um, I mean, there are days when I don't really feel like doing anything.
Not so much anymore.
Like not for the last couple of years, I don't really feel that way.
I've, um, more so just wanted to try to do anything possible to make my life better at
this point.
Um, but at the beginning there were some ups and downs, there were some really hard things
to adjust to, um, first off, just like the first couple of months, the amount of pain
I was in was really, really hard.
I mean, I remember screaming at the top of my lungs in the hospital because I thought
my legs were on fire and obviously I can't feel anything, but it's all nerve pain.
And so that was a really hard night.
I asked them to give me as much pain meds as possible.
They're like, you've had as much as you can have.
So just kind of deal with it, go to a happy place sort of thing.
So that was a pretty low point.
Um, and then every now and again, it's hard, like realizing things that I wanted to do
in my life that I won't be able to do anymore.
Um, you know, I always wanted to be a husband and father.
Yeah.
And I just don't think that I could do it now as a quadriplegic.
Maybe it's possible, but I'm not sure I would ever, um, put, you know, someone I love through
that.
Um, like having to take care of me and stuff, um, not being able to, you know, go out and
play sports.
I was a huge athlete growing up, so that was pretty hard.
Um, just little things too.
When I realized I can't do them anymore, like there's something really special about being
able to hold a book and smell a book, like the feel, uh, the texture, the smell, like
as you turn the pages, like, I just love it and I can't do it anymore.
And it's little things like that.
Um, the two year mark was pretty rough.
Two years is when they say you will, um, get back basically as much as you're ever going
to get back as far as movement and sensation goes.
And so for the first two years, that was the only thing on my mind was like, trust me,
like try as much as I can to move my fingers, my hands, my feet, everything possible to
try to get sensation and movement back.
And then when the two year mark hit, so, um, June 30th, 2018, I was, I was really sad that
that's kind of where I was.
Um, and then just randomly here and there, but I was never like depressed for long periods
of time.
Just, it never seemed worthwhile to me.
What gave you strength?
My faith, my faith in God, uh, was a big one.
My understanding that it was all for a purpose.
And even if that purpose wasn't anything involving Neuralink, even if that purpose was, you know,
there's, there's a story in the Bible about Job.
And I think it's a really, really popular story about how Job, you know, has all of
these.
How terrible things happen to him and he praises God throughout, uh, the whole situation.
I thought, and I think a lot of people think for most of their lives that they are Job,
that they're the ones going through something terrible and they just need to, you know,
praise God through the whole thing and everything will work out.
At some point after my accident, I realized that I might not be Job, that I might be,
you know, one of his children that gets killed or kidnapped or taken from him.
And so it's about terrible things that happened to those around you who you love.
So maybe, you know, in this case, my mom would be Job and she has to get through something
extraordinarily hard.
And I just need to try and make it as best as possible for her because, um, she's the
one that's really going through this massive trial.
Um, and that gave me a lot of strength and obviously my family, um, my family and my
friends, they, they give me all the strength that I need, uh, on a day-to-day basis.
So it makes things a lot easier having that great support system around me.
From everything I've seen of you online, your streams and, uh, the way you are today, I
really admire, let's say your unwavering positive outlook on life.
Has that always been this way?
Yeah.
Yeah.
I've, I mean, I've just always thought.
Yeah.
Yeah.
I could do anything I ever wanted to do.
There was never anything too big, like whatever I set my mind to, I felt like I could do it.
Um, I didn't want to do a lot.
I wanted to like travel around and be sort of like a gypsy and like go work odd jobs.
I had this dream of traveling around Europe and being like, I don't know, a shepherd in
like Wales or Ireland and then going and being a fisherman in Italy.
Uh.
And I was like, I'm going to do all of these things for like a year.
Like it's such like cliche things, but I just thought it would be so much fun to go and
travel and do different things.
And so, um, I've always just seen the best in people around me too.
And I've always tried to be good to people and growing up with my mom too.
She's like the most positive, energetic person in the world.
And we're all just people, people like, uh, I just get along great.
Um, I really enjoy meeting new people.
And so, um, I just wanted to do everything.
Um, this is just kind of just how I've been.
It's just great to see that cynicism didn't take over given everything you've been through.
Yeah.
That's, uh, was that like a deliberate choice you made that you're not going to let this
keep you down?
Yeah, a bit.
Also, like, I just, it's just kind of how I am.
I just, like I said, I roll with the punches.
Yeah.
I roll with the punches with everything.
I always used to tell people, like, I don't stress about things much.
Um, and whenever I'd see people getting stressed, I'd just say, you know, like, it's not hard.
Just don't stress about it.
And like, that's all you need to do.
Uh, and they're like, that's not how that works.
Like it works for me.
I just don't stress and everything will be fine.
Like everything will work out.
Obviously not everything always goes well and it's not like it all works out for the
best all the time.
Yeah.
I don't think stress has had, uh, any place in my life since I was a kid.
What was the experience like of you being selected to be the first human being to have
a neural link device implanted in your brain?
Were you scared?
Excited?
No.
No, it was cool.
Um, like I was, I was never afraid of it.
I had to think through a lot.
Should I, should I do this?
Um, like be the first?
Like be the first person I could wait until number two or three and get a better version
of the neural link.
Like the first one might not work.
Maybe, um, it's actually gonna kind of suck.
Um, it's going to be the worst version ever in a person.
So why would I do the first one?
Like I've already kind of been selected.
I could just tell them, you know, like, okay, find someone else and then I'll do number
two or three.
Like I'm sure they would let me, they're looking for a few people anyways, but ultimately I
was like, I don't know.
There's something about being the first one to do something.
It's pretty cool.
I always thought that if I had the chance that I would like to do something for the
first time, um, this seemed like a pretty good opportunity.
Um, and I was, I was never scared.
I think my like faith had a huge, uh, part in that.
I always felt like God was preparing me for something.
Um, I almost wish it wasn't this.
Because I had many conversations with God about not wanting to do any of this as a quadriplegic.
I told him, you know, I'll go out and talk to people.
I'll go out and travel the world and talk to, you know, stadiums, thousands of people
give my testimony.
I'll do all of it, but like heal me first.
Don't make me do all of this in a chair.
That sucks.
Um, and I guess he won that argument.
I didn't really have much of a choice.
I always felt like there was something.
Yeah.
Going on and to see how I guess easily I made it through the interview process and
how quickly everything happened, um, how the star sort of aligned with all of this, it,
it just told me like, as the surgery was getting closer, it just told me that, you know, it,
it was all meant to happen.
It was all meant to be.
And so I shouldn't be afraid of anything.
That's to come.
And so I wasn't, I kept telling myself like, you know, you say that now, but as soon as
the surgery comes, you're probably going to be freaking out.
Like you're about to have brain surgery and brain surgery is a big deal for a lot of people,
but it's a even bigger deal for me.
Like it's all I have left the amount of times I've been like, thank you God, that you didn't
take my brain and my personality and my ability to think, um, my like love of learning, like
my character, everything.
Like, thank you so much.
Like, as long as you left me that, then I think I can get by.
And I was about to let people go like root around and they're like, Hey, we're going
to go like put some stuff in your brain, like hopefully it works out.
Um, and so it was, it was something that gave me pause, but like I said, how smoothly everything
went, I never expected for a second that anything would go wrong.
Plus the more people I met on the borrows side and on the knurling side, they're just the
most impressive people in the world.
Like I can't speak enough to how much I trust these people with my life and how impressed
I am with all of them and to see the excitement on their faces, to like walk into a room and
roll into a room and see all of these people looking at me.
Like we're just, we're so excited.
Like we've been working so hard on this and it's finally happening.
It's super infectious.
Um, it just makes me want to do it even more and to help them achieve their dreams.
Like I don't know.
It's so, it's so rewarding and I'm so happy for all of them.
Honestly.
What was the, uh, day of surgery like what's, uh, when'd you wake up?
What'd you feel?
Yeah.
Minute by minute.
Yeah.
Were you freaking out?
No, no.
I thought I was going to, but a surgery approach the night before the morning of, I was just
excited.
Like I was like, let's make this happen.
I think I said that.
Uh, something like that to Elon on the phone, uh, beforehand we were like, um, FaceTiming
and I was like, let's rock and roll.
And he's like, let's do it.
Uh, I don't know.
I just, I wasn't scared.
So we woke up, I think we had to be at the hospital at like 5 30 AM.
I think surgery was at like 7 AM.
So we woke up pretty early.
I'm not sure much of us slept that night, um, um, got to the hospital 5 30, went through
like all the pre-ops.
Yeah.
All that stuff.
Everyone was super nice.
Uh, Elon was supposed to be there in the morning, um, but something went wrong with his plane.
So we ended up FaceTiming, uh, that was cool.
Had one of the greatest one-liners of my life after that phone call, um, hung up with him.
There were like 20 people around me and I was like, I just hope he wasn't too starstruck
talking to me.
Nice.
Yeah.
It was good.
Well done.
Yeah.
Yeah.
Did you write that ahead of time?
No, no.
It just came to me.
I was like, this is, this seems right.
You know?
Yeah.
I went into surgery.
Um, I asked if I could pray right beforehand.
So I like prayed over the room.
I asked God if you like be with my mom in case anything happened to me and, uh, just
to like calm her nerves out there, uh, woke up and played a bit of a prank on my mom.
Uh, I don't know if you've heard about it.
Yeah.
I read about it.
Yeah.
Uh, she wasn't, she was not happy.
Uh,
Can you take me through the prank?
Yeah.
This is something.
Do you regret doing that now?
Um, it was something, it was something I, I had talked about ahead of time with my buddy
Bain.
I was like, I would really like to play a prank on my mom.
Um, uh, very specifically my mom, she's very gullible.
Um, I think she had knee surgery once even.
And, um, after she came out of knee surgery, um, uh, she was super groggy.
She was like, I can't feel my legs.
And my dad looked at her.
He was like, you don't have any legs.
Like they, they had, they had to amputate both your legs and we just do very mean things
to her all the time.
Um, I'm so surprised that she still loves us.
Um, but right after surgery, I was really worried that I was going to be too like groggy,
like not all there.
I had had anesthesia once before and it, it messed me up.
Like I could not function, um, for a while afterwards.
And I, um,
I like said a lot of things that I was like, I was really worried that I was going to start,
I don't know, like dropping, dropping some bombs and I wouldn't even know.
I wouldn't remember.
Um, so I was like, I was like, please God, don't let that happen.
And please let me be there enough to do this to my mom.
Um, and so she walked in, uh, after surgery, it was like the first time they had been able
to see me after surgery.
And, um.
And she just looked at me, she said, hi, like, how are you?
How are you doing?
How do you feel?
And I looked at her and this very, I think the anesthesia helped very like groggy sort
of confused look on my face.
It's like, who, who are you?
And she just started looking around the room, like at the surgeons or the doctors, like,
what did you do to my son?
Like, you need to fix this right now.
Tears started streaming.
I saw how much she was freaking out.
I was like, I can't let this go on.
And so I was like, mom, mom, I'm fine.
Like, uh, it's all right.
And, uh, still, she was not happy about it.
She, uh, still says she's going to get me back someday, but I mean, I don't know.
I don't know what that's going to look like.
It's a lifelong battle.
Yeah.
Yeah.
But it was good.
In some sense, there was a demonstration that you still got.
That's, that's all I wanted it to be.
That's all I wanted it to be.
And I knew that doing something super mean to her like that would show her.
Yeah.
To show that you're still there.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
To, to show that you're still there, that you love her.
Yeah, exactly.
Exactly.
It's a dark way to do it, but I love it.
Yeah.
Uh, what was the first time you were able to feel that you can use the Neuralink device
to affect the world around you?
Yeah.
Um, the first little taste I got of it was, uh, actually not too long after surgery.
Um, some of the Neuralink team had brought in, um, like a little iPad, uh, a little tablet
screen.
And they had put up eight different channels that were recording some of my neuron spikes.
And they put it in front of me.
They're like, this is like real time, your brain firing.
I was like, that's super cool.
My first thought was, I mean, if they're firing now, let's see if I can affect them in some way.
So I started trying to wiggle my fingers.
And I just started scanning through the channels.
And one of the things I was doing was moving my index finger up and down.
And I just saw this yellow spike on top row, third box over or something.
I saw this yellow spike every time I did it.
And I was like, oh, that's cool.
And everyone around me was just like, what are you seeing?
I was like, look, look at this one.
Look at this top row, third box over, this yellow spike.
That's me right there, there, there.
And everyone was freaking out.
They started clapping.
I was like, that's super unnecessary.
This is what's supposed to happen, right?
So you're imagining yourself moving each individual finger one at a time.
Yeah.
And then seeing that you can notice something.
And then when you did the index finger, you're like, oh.
Yeah, I was wiggling kind of all of my fingers to see if anything would happen.
There was a lot of other things going on.
But that big yellow spike was the one that stood out to me.
I'm sure that if I would have stared at it long enough, I could have mapped out.
Maybe a hundred different things.
But the big yellow spike was the one that I noticed.
Maybe you could speak to what it's like to sort of wiggle your fingers.
To imagine that the mental, the cognitive effort required to sort of wiggle your index finger, for example.
How easy is that to do?
Pretty easy for me.
It's something that at the very beginning, after my accident, they told me to try and move my body as much as possible.
Even if.
You know, you can't just keep trying because that's going to create new like neural pathways or pathways in my spinal cord to like reconnect these things.
To hopefully regain some movement someday.
That's fascinating.
Yeah, I know.
It's bizarre, but.
That's part of the recovery process is to keep trying to move your body.
Yep.
And the nervous system does its thing.
It starts reconnecting.
It'll start reconnecting for some people.
Some people.
It never works.
Some people, they'll do it.
Like for me, I got some bicep control back and that's about it.
I can, if I try enough, I can wiggle some of my fingers, not like on command.
It's more like if I try to move, say, my right pinky and I just keep trying to move it after a few seconds, it'll wiggle.
So I know there's stuff there.
Like I know like that happens with, you know, a few different of my fingers.
And stuff.
Um, but yeah, that's, that's what they tell you to do.
Um, one of the people at the time when I was in the hospital came in and told me for one guy who had recovered, um, most of his control, what he thought about every day was actually walking like the act of walking, um, just over and over again.
So I tried that for years.
I try just imagining walking, which is.
It's hard.
It's hard to.
Imagine like all of the steps that go into, well, taking a step, like all of the things that have to move, like all of the activations, uh, that have to happen along your leg in order for one step to occur.
But you're not just imagining you're like doing it, right?
I'm trying.
Yeah.
So it's like, it's imagining over again what I had to do to take a step.
Cause it's not something any of us think about.
We just, you want to walk.
And you take a step.
Um, you don't think about all of the different things that are going on in your body.
So I had to recreate that in my head as much as I could.
And then I practice it over and over and over.
So it's not like a third person perspective as a first person perspective.
You're like, it's not like you're imagining yourself walking.
You're like literally doing this, everything, all the same stuff as if you're walking.
Yeah.
Which, which was hard.
It was hard at the beginning.
Like frustrating hard?
Yeah.
Or like actually cognitively hard?
Like which way?
Uh, it was both.
Um, there's a, there's a scene in one of the Kill Bill movies actually, uh, oddly enough
where she is like paralyzed.
I don't know from like a drug that was in her system.
And then she like find some way to get into the back of a truck or something.
And she stares at her toe and she says, move, like move your big toe.
And, uh, after, you know, she's like, I don't know.
For, you know, a few seconds on screen, she does it.
And she did that with every one of her like body parts until she can move again.
I did that for years, just stared at my body and said, move your index finger, move your
big toe.
Um, sometimes vocalizing it like out loud, sometimes just thinking it.
I tried every different way to do this, to try to get some movement back.
And it's hard because it, it actually is like taxing.
like physically taxing on my body, which is something I would have never expected because
it's not like I'm moving, but it feels like there's a buildup of, I don't know, the only
way I can describe it is there are like signals that aren't getting through from my brain down
because there's that gap in my spinal cord. So brain down and then from my hand back up to the
brain. And so it feels like those signals get stuck in whatever body part that I'm trying to
move and they just build up and build up and build up until they burst. And then once they burst,
I get like this really weird sensation of everything sort of like dissipating back out
to level and then I do it again. It's also just like a fatigue thing, like a muscle fatigue,
but without actually moving your muscles. It's very, very bizarre.
And then, you know, if you try to stare at a body part or think about a body part and move
for two, three, four, sometimes eight hours, it's very taxing on your mind. It takes a lot of focus.
It was a lot easier at the beginning because I wasn't able to like control a TV in my room or
anything. I wasn't able to control any of my environment. So for the first few years,
a lot of my body parts were like, I don't know, I don't know, I don't know. I don't know. I don't
know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't
know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't
I was doing was staring at walls. And so, um, obviously I did a lot of thinking and I tried
to move a lot just over and over and over again. Do you never give up sort of hope there?
No training hard, essentially.
Yep. And I still do it. I do it like subconsciously. And I think that, uh,
that helped a lot with things with Neuralink. Honestly, it's something that I talked about
the other day at the,
all hands that i did at nerling's austin facility welcome to austin by the way yeah hey thanks man
i i went to school hey thanks thanks man the the gigafactory was super cool i went to school at
texas a&m so i've been around before um so you should be saying welcome to me yeah welcome to
texas yeah i get you um but yeah i was talking about how a lot of what they've had me do
especially at the beginning um well i still do it now um is body mapping so like there will be a
visualization of a hand or an arm on the screen and i have to do that motion and that's how they
sort of train um the algorithm to like understand what i'm trying to do and so it made things very
uh seamless um for me i think that's really really cool so it's it's amazing to know because i i've
learned a lot about the body mapping procedure yeah like with uh with the interface and everything
like that it's cool to know that you've been a century like
training to be like world class at that task yeah yeah i i don't know if other quadriplegics
like other paralyzed people give up i hope they don't um i hope they keep trying because
i've heard other paralyzed people say like don't ever stop they tell you two years but um
you you just never know you're the human body's capable of amazing things so um
i've heard other people say don't give up uh like i think one girl had um spoken to me through
some family members and said that she had been paralyzed you know for 18 years and she'd been
trying to like wiggle her index finger for all that time and she finally got a bat like 18 years
later so like i know that it's possible and i'll never give up doing it i just i do it when i'm
lying down like watching tv i'll find myself doing it kind of just almost like on its own it's just
something i've gotten so used to doing that i don't know i i don't think i'll ever stop that's
really awesome to hear because i think it's one of those things that can really pay off in the long
term because like that is training you're not visibly seeing the results of that training at
the moment but like there's a like olympic level nervous system getting yeah getting ready for
something honestly was like something that i think neuralink gave me that um i can't i can't thank
them enough for like i can't show my
appreciation for it enough was being able to visually see that what i'm doing is actually
having some effect um it's a huge part of the reason why like i know now that i'm going to
keep doing it forever because before neuralink i was doing it every day and i was just assuming
that things were happening like it's not like i knew i wasn't getting back any
mobility or um sensation or anything so i could have been running up against a brick wall for all
i knew and with neuralink i get to see like all the signals happening real time and i get to see
that you know what i'm doing can actually be mapped you know when we started doing like click
calibrations and stuff when i go to click my index finger for a left click that it actually
recognizes that like it it changed how i think
about what's possible with like retraining my body to move and so yeah i'll i'll never give up now
and also just the signal that there's still a powerhouse of a brain there that's like
exactly uh and as the technology develops that brain is i mean that's the most important thing
about the human body is the brain and it can do a lot of the control so what did it feel like when
you first could wiggle the index finger and saw the environment respond like that little yeah
everybody just being way too dramatic according to you yeah it was very cool i mean it was cool but
it i keep telling this to people it made sense to me like it made sense that you know like there
are signals still happening in my brain and that as long as you had something near it that could
measure those that could record those then you should be able to like visualize it in some way
like see it happen and so that was not very surprising to me i was just like oh cool like
we we found one like we found something that works um it was cool to see that their technology
worked um and that everything that they'd worked so hard for was like going to pay off um but i
hadn't like moved a cursor or anything at that point i had like interacted with a computer or
anything at that point um so it it it just made sense it was cool like like i i didn't really
know much about bci at that point either so i didn't know like what sort of step this was going
actually making um like i didn't know if this was like a huge deal or if this was just like
okay this is you know it's cool that we got this far but we're actually hoping for something like
much better down the road it's like okay i just thought that they knew that it turned on so i was
like cool like this is this is cool what did you like read up on the specs of the hardware you get
installed like the number of threads yeah yeah i knew all that but it's all like it's all greek to
threads 64 threads 16 electrodes 1024 channels okay like that that that math checks out
sounds right yeah when was the first time you were able to move a mouse cursor i know it must
have been within the first maybe week a week or two weeks that i was able to like first move the
cursor and again like it kind of made sense to me like it it didn't seem like that big of a deal
like it
it was like okay well how do i explain this when everyone around you starts clapping for something
that you've done it's it's easy to say okay like i did something cool like that was that was
impressive in some way um what exactly that meant what it was hadn't really like set in for me um
so again i knew that
me trying to move a body part um and then that being mapped um in some sort of like
machine learning algorithm to be able to um identify like my brain signals and then take
that and give me cursor control that all kind of made sense to me i don't know like all the
ins and outs of it but i was like there are still signals in my brain firing they just can't get
through because there's like a gap in my spinal cord and so i was like okay well i'm going to
just do it so they just they can't get all the way down and back up but they're still there so
when i move the cursor for the first time i was like that's cool but i expected that that should
happen like it it made sense to me um when i moved the cursor for the first time um with just
my mind without like physically trying to move so i guess i can get into that just a little bit
like the difference between attempted movement and imagined movement yeah that's a fascinating
difference yeah people wanted it yeah i think that's what it's all about like i think it's a
that's a fascinating difference yeah i think it's a fascinating difference yeah i think it's a
the other yeah yeah yeah so like attempted movement is me physically trying to attempt to move say my
hand i try to attempt to move my hand to the right to the left forward and back um and that's all
attempted attempt to you know like lift my finger up and down attempt to kick or something um i'm
physically trying to do all of those things even if you can't see it like i'm this would be like
me attempting to like shrug my shoulders or something that's all attempted movement um
that all that's what i was doing for the first couple of weeks when they were going to give me
cursor control when i was doing body mapping it was attempt to do this attempt to do that when um
near was telling me um to like imagine doing it it like kind of made sense to me but it's not
something that people practice like if you started school um as a child and they said okay
write your name with this pencil and so you do that like okay now imagine writing your name with
that pencil kids would think uh like i guess like that kind of makes sense and they would do it um
but that's not something we're taught it's all like how to do things physically we think about
like thought experiments
and things but that's not like that's not like a physical action of doing things it's more like
what you would do in certain situations so imagine movement it never really connected with me like i
guess you could maybe describe it as like a professional athlete like swinging a baseball
bat or swinging like a golf club like imagine what you're supposed to do but then you go right
to that and physically do it like you then you get a bat in your hand and then you do what you've
been imagining and so i don't have a physical action to do it but i'm like okay i'm going to
have that like connection so telling me to imagine something versus attempting it it just there wasn't
a lot that i could do there um mentally i just kind of had to accept what was going on and try
um but the attempted moving thing it all made sense to me like if i try to move then there's
a signal being sent in my brain and as long as they can pick that up then they should be able
to map it to what i'm trying to do and so when i first moved the cursor like that
was it was just like yes this should happen like i'm i'm not surprised by that but can you clarify
is there supposed to be a difference between imagine movement and attempted movement yeah
just that in imagine movement you're not attempting to move at all so it's you're like
visualize visualizing and then theoretically is that supposed to be a different part of the brain
that lights up in those two different situations yeah not necessarily i think all these signals
can still be represented in motor cortex but the difference i think has to do with the
naturalness of imagining something worse got it attempting and sort of the fatigue of that over
time and by the way on the mic is bliss uh so like this is just different ways to prompt you to kind
of get to the thing that you're around yeah yeah attempted movement does sound like the right thing
yeah try yeah i mean it makes sense to me because imagine for me i'll be i would start visualizing
like in my mind visualizing attempted i would actually start trying to like yeah there's a
i mean i you know i did like combat sports my whole life like wrestling when i'm imagining a move
see i'm like moving my muscle exactly like there's a there is a bit of an activation almost
versus like visualizing yourself like a picture doing it yeah it's something that i feel like
naturally anyone would do if you try to tell someone to imagine doing something they might
close their eyes and then start physically doing it um but it's just didn't click yeah it's it's
it's hard it was very hard at the beginning but attempted worked attempted worked it worked just
like it should work like work like a charm um i remember there was like one tuesday we were
messing around and i think i forget what swear word you used but there's a swear word that came
out of your mouth when you figured out you could just do the direct cursor control yeah that's it
it blew my mind like no pun intended blew my mind when i first
um
moved the cursor just with my thoughts and not attempting to move it's something that i found
um like over the couple of weeks like building up to that um that as i get better cursor controls
like the model uh gets better um then it gets easier for me to like um like i don't have to
attempt as much to move it
and part of that is something that i'd even talked with them about um when i was watching
the signals of my brain one day i was watching when i like attempted to move to the right and
i watched the screen as like i saw the spikes like i was seeing the spike the signal was being sent
before i was actually attempting to move um i imagine just because you know when you go to
say move your hand or any body part that signal is going to be sent to your brain and you're going to
get sent before you're actually moving has to make it all the way down and back up before you
actually do any sort of movement so there's a delay there and i noticed that there was something
going on in my brain before i was actually attempting to move that um my brain was
like anticipating what i wanted to do and that all started sort of um i don't know like
percolating in my brain like it just it was just sort of there
like always in the back like that's so weird that it could do that it kind of makes sense but
i wonder what that means um as far as like using the neural link and um you know and then as i was
playing around with the attempted movement and playing around with the cursor and i saw that
like as the cursor control got better that it was anticipating my movements um and what i wanted it
to do like cursor movements what i wanted to do and i saw that it was anticipating my movements
a bit better and a bit better and then one day i just randomly as i was playing web grid i um
like looked at a target before i had started like attempting to move i was just trying to like
get over like train um my eyes to start looking ahead like okay this is the target i'm on but if
i look over here to this target i know i can like maybe be a bit quicker getting there and i looked
over and the cursor just shot over it it was like oh my god i'm like oh my god i'm like oh my god
wild like i had to take a step back like i was like this should not be happening all day i was
just smiling i was so giddy i was like guys do you know that this works like i can just think it and
it happens which like they'd all been saying this entire time like i can't believe like you're doing
all this with your mind i'm like yeah but is it really with my mind like i'm attempting to move
and it's just picking that up so it doesn't feel like it's with my mind but when i moved it for
the first time like that it was oh man it like it was like i was like oh my god i'm like oh my god
it made me think that this technology that what i'm doing is actually way way more impressive than
i ever thought it was way cooler than i ever thought and it just opened up a whole new world
of possibilities of like what could possibly happen with this technology and what i might
be able to be capable of with it because you had felt for the first time like this was digital
telepathy like you're controlling a digital device with your mind yeah
i mean this is that's a real moment of discovery that's really cool like you've discovered
something i've seen like scientists talk about like a big aha moment you know like nobel prize
winning they'll have this like holy crap yeah like that's what that's what it felt like like
i didn't feel like like i felt like i had discovered something but for me maybe not
necessarily for like the world at large or like this field at large it just felt like an aha
moment in my life and i'm like oh my god i'm like oh my god i'm like oh my god i'm like oh my god
for me like oh this works like obviously it works um and so that's what i do like all the time now
uh i kind of intermix um the attempted movement and uh imagine movement i do it all like together
because i've found that there is some interplay with it that maximizes efficiency with the cursor
so it's not all like one or the other it's not all just i only use attempted or i only
use like imagined movements it's more i use them um in parallel and uh i can do one or the other i
can just completely think about um whatever i'm doing but um i don't know i i like to play around
with it i also like to just experiment with these things like every now and again i'll get this idea
in my head like hmm i wonder if this works and i'll just start doing it and then afterwards i'll
tell them by the way i wasn't doing that like you guys wanted me to um i was i i thought about it
something and i wanted to try it and so i did it seems like it works so maybe we should like
explore that a little bit so i think that discovery is not just for you at least from
my perspective that's a discovery for everyone else who ever uses a neural link that this is
possible like i don't think that's an obvious thing that this is even possible it's like uh
i was saying to bliss earlier uh it's like the four minute mile people thought it was impossible
to run a mile in four minutes and once the first person did it then everyone just started
doing it so like just to show that it's possible that paves the way to like anyone can now do it
that's the thing that's actually possible you don't need to do the attempted movement you just
go direct that's crazy that is great it is crazy uh for people who don't know can you explain how
the link app works you have an amazing stream on the topic your first stream i think on x
uh describing the app uh can you just describe how it works yeah so it's just an app that's
a neural link created um to help me interact with a computer so on the link app uh there are a few
different settings and different modes and things i can do on it so there's like the body mapping
if we kind of touched on um there's a calibration um calibration is how i actually get cursor
control so calibrating what's going on in my brain to uh
translate that into cursor control so it will pop out um models what what they use i think is
like time so it would be you know five minutes and calibration will give me um so good of a model
and then if i'm in it for 10 minutes and 15 minutes uh the models will progressively get
better and um so you know the longer i'm in it generally the um better the models will get
that's really cool because you often refer to the models
yeah the model is the thing that's constructed once you go through the calibration stuff yeah
and then you also talked about something sometimes you'll play like a really difficult game like
snake just to see how good the model is yeah yeah so snake is kind of like my litmus test for models
if i can control snake decently well then i know i have a pretty good model so yeah the link app has
all of those it has webgrid in it now um it's also how i like connect to the computer just in
general um so they've given me a lot of information about how to use the link app and how to use the
link app so i can you know say like connect or implant disconnect and um as long as i have
that charger handy then i can connect to it so the charger is also how i connect to the link
app to connect the computer i have to have um the implant charger uh over my head when i want
to connect to have it wake up because the implants in hibernation mode uh like always when i'm not
using it um i think there's a setting to like wake it up and then i can connect to the link app and
um so yeah i'll like connect to the link app and then go through all sorts of things uh calibration
for the day maybe body mapping i have like i made them give me like a little homework tab
um because i am very forgetful and i forget to do things a lot um so i have like a lot of data
collection things that i can do and then i can connect to the link app and then i can go through
uh that they want me to do is the body mapping part of the data collection or is that also part
of the yeah it is it's something that they want me to do um daily which i've been slacking on
because i've been doing so much media and traveling so much so i've been i've been super
famous yeah i've i've been a terrible um first candidate for how much i've uh been slacking on
my homework um but yeah it's just something that they want me to do every day to you know track um
how uh
well the neural link is performing over time and have something to give i imagine to give to the
fda to you know create all sorts of fancy charts and stuff and show like hey this is what the
neural link this is how it's performing you know day one versus day 90 versus day 180 and things
like that what's the calibration step like is it is it like move left move right it's uh a bubble
game so there will be like yellow bubbles that pop up on the screen at first it is open loop so
this is something that i still don't fully understand the open loop and closed loop thing
i mean blitz talked for a long time about the difference between the two from the on the
technical side okay so it'd be great to hear your okay so your side of the story open loop is
basically um i have no control over the cursor um the cursor will be moving on its own across
the screen and i am following by intention um the cursor to different bubbles and then my um the
algorithm is training off of what like the signals it's getting are as i'm doing this there are a
couple different ways that they've done it they call it center out target so there will be a bubble
in the middle and then eight bubbles around that and the cursor will go from uh the middle uh to
one side so say middle to left back to middle to up to middle like upright and they'll do that all
the way around uh the circle and i will follow that cursor um the whole time and then it will
go off of my intentions what it is expecting my intentions to be um throughout the whole process
can you actually speak to when you say follow yes you don't mean with your eyes you mean with
your intentions yeah so uh generally for calibration i'm doing attempted movements
uh because i think it works better i think the better models as i progress through calibration
um make it easier um to use imagine movements
so calibrated on attempted movement will create a model that makes it really effective for you to
then use the force yes i've tried um doing calibration with imagined movement and it just
doesn't work as well um for some reason so that was the center out targets there's also one where
you know a random target will pop up on the screen and it's the same i just like move i follow along
the cursor is to that target all across the screen um i've tried those with imagined movement
and for some reason the models just don't um they don't give as high level as quality when we get
into closed loop um i haven't played around with it a ton so maybe like the different ways that
we're doing calibration now might make it a bit better but what i've found is there will be a
point in
calibration where i can use uh imagine movement before that point it doesn't really work so if i
do calibration for 45 minutes the first 15 minutes i can't use imagine movement it just like doesn't
work for some reason um and after a certain point uh i i can just sort of feel it i can tell
it moves different uh that's the best way i can
describe it like it's almost as if it is anticipating what i am going to do again before
i go to do it um and so using attempted movement for 15 minutes at some point i can kind of tell
when i like move my eyes to the next target that the cursor is starting to like pick up
like it's starting to understand it's learning like what i'm going to do so first of all it's
really cool that i mean you are a true pioneer in all of this you're like exploring all of this and
exploring how to do every aspect of this most effectively and there's just uh i imagine so many
lessons learned from this so thank you for being a pioneer in all these kinds of different like
super technical ways and it's also cool to hear that there's like a different like feeling
to the experience when it's calibrated in different ways like just because i imagine your
brain is doing something different and that's why there's a different feeling to it and then trying
to understand the words and the measurements to those feelings would be also interesting but at
the end of the day you can also measure that your actual performance on whether it's snake or web
grid you can see like what actually works well and you're saying for the open loop calibration
the attempted movement works best for now yep yep so the this is the open loop you don't get
the feedback that's something that you did something yeah is that frustrating or no no it makes sense to me like
uh we've done it with a cursor and without a cursor in open loop so sometimes it's just um
say for like the center out the um you'll start calibration with a bubble
lighting up and i push towards that bubble and then when that bubble you know when it's pushed
towards that bubble for say three seconds the bubble will pop and then i come back to the middle
um so i'm doing it all just by my intentions like that's what it's learning anyway so it makes sense
as long as i follow what they want me to do you know like follow the yellow brick road that it'll
all work out um you're full of great references uh is this the bubble game fun like yeah they always
feel so bad making me do calibration like oh we're about to do you know a 40 minute calibration
i'm like all right do you guys want to do two of them um like i'm always asking to like
whatever they need i'm more than happy to do and it's not it's not bad like i get to lie there and
um or sit in my chair and like do these things with some great people i get to have great
conversations i can give them feedback um i can talk about all sorts of things uh i could throw
something on on my tv in the background and kind of like split my attention between them um like
it's not bad at all i don't know score that you get like can you do better on the bubble game no
i would love that um i i i would love yeah writing down uh suggestions from no that's uh
make it more fun gamified yeah that's one thing that i really really enjoy about web grid is
because i'm so competitive um like the higher the bps the higher the score i know the better i'm
doing and so if i i think i've asked at one point one of the guys like if he could give me some sort
of like a score i would love that um i would love that um i i i would love that um i i would love
numerical feedback for calibration like i would like to know what they're looking at like oh
you know it is um we see like this number while you're doing calibration and that means at least
on our end that we think calibration is going well um and i would love that because i would
like to know if what i'm doing is going well or not but then they've also told me like yeah
not necessarily like one-to-one it doesn't actually mean that calibration is going well
in some ways um so it's not like a hundred percent and they don't want to like skew
what i'm experiencing or want me to change things based on that if that number isn't always
accurate to like how the model will turn out or how like the end result that's at least what i got
from it uh one thing i do i have asked them and something that i really enjoy um striving for is
towards the end of calibration there is like a time between targets um and so i like to keep
like at the end uh that number as low as possible so at the beginning it can be you know
four or five six seconds between the numbers and then at the end of calibration it can be
between me popping bubbles but towards the end i like to keep it below like 1.5 or if i could get
it to like one second between like bubbles because in my mind that translates um really nicely to
something like web grid where i know if i can hit a target uh one every second that i'm doing real
real well there you go that's the way to get a score on the calibrations like the speed how
quickly can you get from bubble to bubble yeah uh so there's the open loop and then it goes to
can already start giving you a sense because you're getting feedback of like how good the
model is yeah so closed loop is when i um first get cursor control and how they've uh described
it to me someone who does not understand this stuff i am the dumbest person in the room every
time i'm with any of the humility yeah um is that i am closing the loop so i am actually now
um the one that is like finishing the loop of whatever this loop is i don't even know what the
they've never told me they just say there is a loop and at one point it's open and i can't control
and then i get control and it's closed so i'm finishing the loop so how long the calibration
usually takes you said like 10-15 minutes well yeah they're they're trying to get that number
down pretty low um that's what we've been working on a lot recently is getting that down as low as
possible so that way you know if this is something that people need to do on a daily basis or if some
other day basis or once a week they don't want people to be sitting in calibration for long
periods of time i think they wanted to get it down seven minutes or below um at least where we're at
right now it'd be nice if they you never had to do calibration um so we'll get there at some point
i'm sure the more we learn about the brain and um like i think that's you know the dream um
i think right now for me to get like really really good models um i'm in calibration 40 or 45
minutes um and i don't mind like i said they always feel really bad but if it's going to get
me a model that can like break these records on webgrid i'll stay in it for flipping two hours
let's talk business so webgrid um i saw a presentation that where bliss said by march
you selected 89 000 targets in webgrid can you explain this game well what is webgrid
and what does it take to be a world-class performer in webgrid as you continue to break
work
world records yeah um
it's like a gold medalist like wow yeah you know i'd like to thank i'd like to thank everyone who's
helped me get here my coaches my parents for driving me to practice every day at five in the
morning um like thank god um and just overall my dedication to my craft the interviews with
athletes are always like that exactly it's like that template yeah so so um so webgrid
webgrid
is a grid cells it's it's literally just a grid they can make it as big or small as you can make
a grid a single box on that grid will light up and you go and click it and it is a way for them to
benchmark how good a bci is so it's you know pretty straightforward you just click targets
only one blue cell appears and you're supposed to move the mouse to there and click on it
so i like playing on like
bigger grids because it the bigger the grid the like more bps it's bits per second um that you get
every time you click one so i'll say i'll play on like a 35 by 35 um grid and then one of those
little squares a cell and call it target whatever will light up and you move the cursor there and
you click it and then you do that um forever and you've been able to achieve at first eight bits
per second and
And you recently broke that.
Yeah, I'm at 8.5 right now.
I would have beaten that literally the day before I came to Austin.
But I had like a, I don't know, like a five second lag right at the end.
And I just had to wait until the latency calmed down.
And then I kept clicking.
But I was at like 8.01 and then five seconds of lag.
And then the next like three targets I clicked all stayed at 8.01.
So if I would have been able to click during that time of lag,
I probably would have hit, I don't know, I might have hit nine.
So I'm there.
I'm like, I'm really close.
And then this whole Austin trip has really gotten in the way of my WebGrid playing ability.
It's frustrating.
Yeah.
So that's all you're thinking about right now?
Yeah, I know.
I just want, I want to do better.
At nine.
I want to do better.
I want to hit nine.
I think, well, I know nine is very, very achievable.
I'm right there.
Um, I think 10.
I could hit maybe in the next month.
Like I could do it probably in the next few weeks if I really push.
I think you and Ilana are basically the same person.
Because last time I did a podcast with him,
he came in extremely frustrated that he can't beat Uber Lilith as a droid.
That was like a year ago, I think.
I forget.
Like solo.
Yeah.
And I could just tell there's some percentage of his brain the entire time was thinking like,
I wish I was right now attempting.
I think he did it that night.
He did it that night.
Yeah.
He stayed up and did.
He did it that night.
Yeah.
It's just crazy to me.
I mean, it's in a, in a, in a fundamental way, it's really inspiring and what you're
doing is inspiring in that way because I mean, it's not just about the game.
Everything you're doing there has impact by striving to do well on web grid.
You're helping everybody figure out how to create the system all along, like the decoding,
the software, the hardware, the calibration, all of it, how to make all of that work so
you can do everything else really well.
Yeah.
It's just really fun.
Well, that's also, that's part of the thing is making it fun.
Yeah.
It's addicting.
I'm I've joked about, um, like what they actually did when they went in and put this thing in
my brain, they must've flipped a switch to make me, uh, more susceptible to these kinds
of games to make me addicted to like web grid or something.
Yeah.
Do you know bliss's high score?
Yeah.
He said like 14 or something.
17.
Oh boy.
17.1 or something.
17.1.
Yeah.
He told me he like does it on the floor with peanut butter and he like fasts it's, it's,
it's weird.
It sounds like cheating.
It sounds like performance enhancing.
Uh,
No, it was like the first time Nolan, uh, played this game, he asked, well, you know, how good
are we at this game?
And I think you told me right then, you're gonna, you're gonna try to beat me.
I'm gonna get there someday.
Yeah.
I think I fully believe you.
I think I can.
I'm excited for that.
Yeah.
So I've been playing first off with the dwell cursor, which really hampers my web grid playing
ability.
Basically I have to wait 0.3 seconds for every click.
Oh, so you can't do the clicks.
You have to, you have to, so you click by dwelling.
You said 0.3,
0.3 seconds, which, which sucks.
It really slows down how much I'm able to like how high I'm able to get.
I still hit like 50, I think I hit like 50 something trials, net trials per minute in
that.
Um, which was pretty good.
Um, cause I'm able to like, um,
Um, there's one of the settings is also like how slow you need to be moving in order to
initiate a click to start a click.
So I can tell sort of when I'm on that, um, threshold to start initiating a click just
a bit early.
So I'm not fully stopped over the target.
When I go to click, I'm doing it like on my way to the targets a little, um, to try to
time it just right.
Wow.
So you're slowing down.
Yeah.
Just, just a hair right before the targets.
This is like a lead performance.
Okay.
But that's still, it's, it sucks that there's a ceiling of the 0.3.
Well, there, I can get down to 0.2 and 0.1 0.1.
Yeah.
And I've played with that a little bit too.
Um, I have to adjust a ton of different parameters in order to play with 0.1 and I don't have
control over all of that on my end yet.
It also changes like how the models are trained.
Like if I train a model, like in web grid, like a bootstrap on a model, which basically
is them.
Uh, training models as I'm playing web grid, um, based off of like the web grid data that
I'm still like, if I play web grid for 10 minutes, they can train off that data specifically,
um, in order to get me a better model.
Um, if I do that with 0.3 versus 0.1, the models come out different.
Um, the way that they, um, interact is it's just much, much different.
So I have to be really careful.
I found that doing it with 0.3 is actually better in some ways, unless I can do it with
0.1 and change all of the different models.
If I change all of the different parameters, then that's more ideal because obviously
0.3 is faster than 0.1.
So, uh, I could, I could get there.
I can get there.
Can you click using your brain?
For right now, it's the hover clicking with the dwell cursor.
Um, we, before all the thread retraction stuff happened, we were calibrating clicks, left
click, right click.
That was, um, my previous ceiling, um, before I broke the record again with the dwell cursor
was.
I think on a 35 by 35 grid with left and right click and you get more, um, BPS, more bits
per second using multiple clicks.
Cause it's more difficult.
Oh, because what is it?
The blue you get, you're supposed to do either a left click or like right click.
Yes.
It's a different color.
Yeah.
Blue targets for left.
Click orange targets for right.
Click is what they had done.
So, uh, my previous record of 7.5 was with the blue and the orange targets.
Yeah.
Um, I think if I went back to that now, um, doing the click calibration, I would be able
to, and being able to like initiate clicks on my own, I think I would break that 10 ceiling
like in a couple of days, max.
Yeah.
You would start making bliss nervous about his 17.
Why do you think we haven't given him the, exactly.
Uh, so what, what did it feel like with the retractions that there is a, some of the threads
are attracted.
It sucked.
It was really, really hard.
The day they told me was the day of my big neural link tour at their Fremont facility.
They told me like right before we went over there, it was really hard to hear my initial
reaction was all right, go in, fix it, like go and take it out and fix it.
The first surgery was so easy.
Like, like I went to sleep a couple hours later, I woke up and here we are.
Um, I didn't feel any pain.
Didn't take like any, um, um, pain.
Pills or anything.
So I just knew that if they wanted to, they could go in and put in a new one, like next
day, if that's what it took, because I just wanted, I wanted it to be better and I wanted
not to lose the capability.
I had so much fun, um, playing with it for a few weeks for a month I had, I get it opened
up so many doors for me and it opened up so many more possibilities that I didn't want
to lose it.
After a month, I thought it would have been a cruel twist of fate if I had gotten to see
the view from like the top of this mountain and then have it all come crashing down after
a month.
And I knew like say the top of the mountain, but like I, how I saw it was, I was just now
starting to climb the mountain and I was like, there was so much more than I knew was possible.
And so to have all of that be taken away, it was really, really hard.
Um.
But then on the drive over to the facility, I don't know, like five minute drive, whatever
it is.
Um, I talked with my parents about it.
I prayed about it.
I was just like, you know, I'm not going to let this ruin my day.
I'm not going to let this, um, ruin this amazing like tour that they have set up for me.
Like I want to go show everyone how much I appreciate all the work they're doing.
I want to go like meet all of the people who have made this possible.
And I want to go have one of the best days of my life.
And I did, and it was amazing.
And it absolutely was one of the best days I've, uh, ever been privileged to experience.
And then for a few days, uh, I was pretty down in the dumps, but, uh, for like the first
few days afterwards, I was just like, I didn't know if it was ever going to work again.
And then I just, I made the decision that it.
Even if I lost the ability to use the neural link, even if I lost, um, even if I like lost
out on everything to come, um, if I could keep giving them data in any way, then I would
do that.
If I needed to just do, um, like some of the data collection every day or body mapping
every day for a year, then I would do it.
Um, because I know that everything I'm doing helps everyone to come after me and that's
all I wanted.
Right.
So the reason that I did this was to help people.
And I knew that anything I could do to help, I would continue to do, even if I never got
to use the cursor again, then, you know, I was just happy to be a part of it.
And everything that I'd done was just a perk.
It was something that I got to experience and I know how amazing it's going to be for
everyone to come after me.
So might as well just keep trucking along, you know,
Well, that said you were able to get, to work your way up, to get the performance back so
this is like going from Rocky one to Rocky two.
So when did you first realize that this is possible and what gave you sort of the strength
and motivation, the determination to do it, to increase back up and beat your previous
record?
Uh, yeah, it was within a couple of weeks, like
Again, this feels like I'm interviewing an athlete.
This is great.
I like to thank my parents.
The road back was long and hard, from many difficulties, there were dark days.
Um, uh, it was, it was a couple of weeks, uh, I think, and then there was just a turning
point.
I think they had switched how, um, they were measuring, um, the neuron spikes in my brain,
like the bliss helped me out.
Uh, yeah, the way in which we were measuring, uh, the behavior of individual neurons.
Yeah.
So we're switching from a sort of individual spike detection to something called spike
band power, which, uh, if you watch the previous segments with either me or DJ, you probably
have some confidence.
So when they did that, it was kind of like, uh, you know, light over the head, like light
bulb moment, like, oh, this works.
And um, this seems like, like we can run with this.
And I saw the, um, uptick in performance immediately.
Like I could feel it when they switched over, I was like, this is better.
Like this is good.
Like everything up till this point for the last few weeks, last, like whatever, three
or four weeks.
Cause it was before they even told me like everything before this sucked.
Like, let's keep doing what we're doing now.
And at that point it was not like, oh, I know I'm still only at like, say in web grid terms,
like four or five BPS compared to my 7.5 before.
But I know that if we keep doing this, then like I can, I can get back there.
And then they gave me the dwell cursor and the dwell cursor sucked at first.
It's not obviously not what I want, but it gave me a path forward to be able to connect.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
I know.
I know.
Like I said, I'm not, I'm not so sure about that.
I'm not sure if I'm, I'm not so sure if I'm using it the correct way.
I'm not sure if I'm using it the right way.
I'm not so sure if I'm using it the right way.
I'm just not sure.
I don't know.
Like I said, I'm just kind of a person.
I roll with the punches anyway.
So what was the process?
What was the feedback loop on the thing out how to do the spec detection in a way that
would actually work well for Nolan?
Yeah, it's a great question.
So maybe just describe first how the actual update worked is basically an update to your
implant.
So we just did an over the air software update to his implants and what you'd update your
Tesla or your iPhone.
And that firmware change enabled us to record averages of populations of neurons nearby
an individual electrode.
So we have less resolution about which individual neuron is doing what, but we have a broader
picture of what's going on nearby an electrode overall.
And that feedback, I mean, basically, as Nolan described, it was immediate when we flipped
that switch.
I think the first day we did that, you hit three or four VPS right out of the box.
And that was a light bulb moment for, okay, this is the right path to go down.
And from there, there's a lot of feedback around, like, how to make this useful for
independent use.
So what we care about ultimately is that you can use it independently to do whatever you
want.
And to get to that point, it required us to re-engineer the UX, as you talked about with
the dwell cursor, to make it something that you can use independently without us needing
to be involved all the time.
And yeah, this is obviously the start of this journey still, hopefully we get back to the
places where you're doing multiple clicks and using that to control much more fluidly
everything and much more naturally the applications that you're trying to interface with.
And most importantly...
Yeah.
Get that web grid number up.
Yep.
Yeah.
So how's the, on the hover click, do you accidentally click stuff sometimes?
Yeah.
Like what's, how hard is it to avoid accidentally clicking?
I have to continuously keep it moving basically.
So like I said, there's a threshold where it will initiate a click.
So if I ever drop below that, it'll start.
And I have 0.3 seconds to move it before it clicks anything.
Okay.
And if I don't want it to ever get there.
I just keep it moving at a certain speed and just constantly doing circles on screen, moving it back and forth to keep it from clicking stuff.
I actually noticed a couple weeks back that when I was not using the implant, I was just moving my hand back and forth or in circles.
I was trying to keep the cursor from clicking, and I was just doing it while I was trying to go to sleep.
And I was like, okay, this is a problem.
To avoid the clicking.
I guess, does that create problems when you're gaming, accidentally click a thing?
Yeah, it happens in chess.
I've lost a number of games because I'll accidentally click something.
I think the first time I ever beat you was because of an accidental click.
Yeah, a misclick.
It's a nice excuse, right?
Yeah, it is.
Anytime you lose, you could just say, that was accidental.
Yeah.
You said the app improved a lot from version 1 when you first started using it.
It was very different.
It was very different.
So can you just talk about the trial and error that you went through with the team, like 200 plus pages of notes?
What's that process like of going back and forth and working together to improve the thing?
It's a lot of me just using it day in and day out and saying, hey, can you guys do this for me?
Give me this.
I want to be able to do that.
I need this.
I think...
A lot of it just doesn't occur to them, maybe, until someone is actually using the app, using the implant.
It's just something that they just never would have thought of.
Or it's very specific to even me, maybe what I want.
It's something I'm a little worried about with the next people that come is maybe they will want things much different than how I've set it up or what the advice I've given the team.
And they're going to look at some of the things they've added for me.
I'm like, that's a dumb idea.
Why would he ask for that?
And so I'm really looking forward to get the next people on because I guarantee that they're going to think of things that I've never thought of.
They're going to think of improvements.
I'm like, wow, that's a really good idea.
I wish I would have thought of that.
And then they're also going to give me some pushback about like, yeah, what you are asking them to do here, that's a bad idea.
Let's do it this way.
And I'm more than happy to have that happen.
But it's just a lot of like, you know, different interactions with different games or applications, the Internet, just with the computer in general.
There's tons of bugs that end up popping up left, right, center.
So it's just me trying to use it as much as possible and showing them what works and what doesn't work and what I would like to be better.
And then they take that feedback.
And they usually create amazing things for me.
They solve these problems in ways I would have never imagined.
They're so good at everything they do.
And so I'm just really thankful that I'm able to give them feedback and they can make something of it because a lot of my feedback is like really dumb.
It's just like, I want this.
Please do something about it.
And we'll come back super well thought out.
And it's way better than anything I could have ever thought of or implemented myself.
So they're just.
It's great.
They're really, really cool.
As the BCI community grows, would you like to hang out with the other folks with Neuralink?
Like what relationship, if any, would you want to have with them?
Because you said like they might have a different set of like ideas of how to use the thing.
Yeah.
Would you be intimidated by their WebGrid performance?
No, no.
I hope.
Compete.
I hope day one they like wipe the floor with me.
I hope they beat it.
And they crush it, double it if they can, just because on one hand, it's only going to push me to be better because I'm super competitive.
I want other people to push me.
I think that is important for anyone trying to achieve greatness is they need other people around them who are going to push them to be better.
And I even made a joke about it on X once, like once the next people get chosen, like cue buddy cop music.
Like I'm just excited to have.
Other people to do this with and to like share experiences with.
I'm more than happy to interact with them as much as they want.
More than happy to give them advice.
I don't know what kind of advice I could give them, but if they have questions, I'm more than happy.
What advice would you have for the next participant in the clinical trial?
That they should have fun with this because it is a lot of fun and that I hope they work really, really hard because it's not just for us.
It's for everyone.
It's for everyone that comes after us and, you know, come to me if they need anything and to go to Neuralink if they need anything.
Man, Neuralink moves mountains like they do absolutely anything for me that they can.
And it's an amazing support system to have.
It puts my mind at ease for like so many things that I have had like questions about or so many things I want to do.
And they're always there.
And that's really, really nice.
And so I just I would tell them not to be afraid to go to Neuralink with any questions that they have, any concerns, anything that, you know, they're looking to do with this and any help that Neuralink is capable of providing.
I know they will.
And I don't know.
I don't know.
Just work your ass off because it's really important that we try to give our all to this.
So have fun and work hard.
Yeah.
Yeah.
There we go.
Maybe that's what I'll just start saying to people.
Have fun.
Work hard.
Now you're a real pro athlete.
Just keep it short.
Maybe it's good to talk about what you've been able to do now that you have a Neuralink implant, like the freedom you gain from this way of interacting with the outside world.
Like you play video games all night and you do that by yourself.
Yeah.
And that's a kind of freedom.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
To that freedom that you gain.
Yeah.
It's what all, I don't know, people in my position want.
They just want more independence.
The more load that I can take away from people around me, the better.
If I'm able to interact with the world without using my family, without going through any of my friends, like needing them to help me with things, the better.
If I'm able to sit up on my computer all night and not need someone.
If I'm able to sit up on my computer all night and not need someone to sit me up, say like on my iPad, like in a position where I can use it and then have to have them wait up for me all night until I'm ready to be done using it like that.
It takes a load off of all of us and it's really like all I can ask for.
It's something that, you know, I could never thank Neuralink enough for.
I know my family feels the same way.
You know, just being able to have.
I have the freedom to do things on my own at any hour of the day or night.
It means the world to me and I don't know.
When you're up at 2 a.m. playing WebGrid by yourself, I just imagine like it's darkness and there's just a light glowing and you're just focused.
What's going through your mind?
Or you're like in a state of flow where it's like the mind is empty.
Like those like Zen masters.
Yeah.
Generally, it is me playing music of some sort.
I have a massive playlist.
And so I'm just like rocking out to music.
And then it's also just like a race against time because I'm constantly constantly looking at how much battery percentage I've left on my implant.
Like, all right, I have 30 percent, which equates to, you know, X amount of time, which means I have to break this record in the next, you know, hour and a half or else.
It's not happening tonight.
And so it's it's a little stressful when that happens, when it's like when it's above 50 percent.
I'm like, OK, like I got time.
It starts getting down to 30 and then 20.
It's like, all right, 10 percent.
A little pop up is going to pop up right here and it's going to really screw my WebGrid flow.
It's going to tell me that, you know, like there's a like a low battery, low battery pop up comes up and it's really going to screw me over.
So if I have to, if I'm going to break this record, I have to do it in the next.
Like 30 seconds or else that pop up is going to get in the way, like cover my WebGrid.
And then after that, I go click on it, go back into WebGrid.
And I'm like, all right, that means I have, you know, 10 minutes left before this thing's dead.
That's what's going on in my head.
Generally that and whatever song is playing.
And I just I just want I want to break those records so bad.
Like, it's all I want when I'm playing WebGrid.
It has become less of like, oh, this is just a leisurely activity.
Like, I just enjoy.
I'm doing this because it just feels so nice and it puts me at ease.
It is now once I'm in WebGrid, you better break this record or you're going to waste like five hours of your life right now.
And I don't know.
It's just fun.
It's fun, man.
Have you ever tried WebGrid with like two targets and three targets?
Can you get higher BPS with that?
Can you do that?
You mean like different color targets or you mean multiple targets that change the thing?
Yeah.
So BPS is a log of number of targets times correct minus incorrect.
Divided by time.
And so you can think of like different clicks as basically doubling the number of active targets.
Got it.
So, you know, you basically higher BPS, the more options there are, the more difficult the task.
And there's also like Zen mode you've played in before, which is infinite.
Yeah, it covers it covers the whole screen with a grid and I don't know what.
Yeah.
And so you can go like that's insane.
Yeah.
He doesn't like it because it didn't show BPS.
So like, you know, oh, yeah, I have them.
I had them put in.
I had them put in a giant BPS in the background.
So now it's like the opposite of Zen mode.
It's like it's like super hard mode, like just metal mode of it.
Just like a giant number in the back count.
We should name that metal mode is a much better name.
So you also play Civilization six.
I love Civ six.
Yeah.
Usually go with Korea.
I do.
Yeah.
So the great part about Korea is they focus on like science tech victories, which was not planned.
Yeah.
Like I've been playing Korea for years and then all of the knurling stuff happened.
So it kind of aligned.
But what I've noticed with tech victories is if you can just rush tech rush science, then you can do anything.
Like at one point in the game, you will be so far ahead of everyone technologically that you will have like musket men, infantry men playing sometimes.
Yeah.
And people will still be fighting with like bows and arrows.
And so if you want to win a domination victory, you just get to a certain point with the science and then go and wipe out the rest of the world.
Or you can just take science all the way and win that way.
And you're going to be so far ahead of everyone because you're producing so much science that it's not even close.
I've accidentally won in different ways just by focusing on science.
Accidentally won by focusing on science.
I was playing only science, obviously, like just science all the way, just tech.
And I was trying to get like every tech in the tech tree and stuff.
And then I accidentally won through a diplomatic victory.
And I was so mad.
I was so mad.
Because it just like ends the game one turn.
It was like, oh, you won.
You're so diplomatic.
I'm like, I don't want to do this.
I should have declared war on more people or something.
It was terrible.
But you don't need like giants.
You don't need civilizations with tech, especially with Korea.
You can keep it pretty small.
So I generally just get to a certain military unit and put them all around my border to keep everyone out.
And then I will just build up.
So very isolationist.
Nice.
Just work on the science and the tech.
That's it.
You're making it sound so fun.
It's so much fun.
And I also saw Civilization VII trailer.
Oh, man.
I'm so pumped.
And that's probably coming out.
Come on, Civ VII.
Hit me up.
All alpha, beta tests, whatever.
That'd be so cool.
When is it coming out?
2025.
Yeah, yeah.
Next year, yeah.
What other stuff would you like to see improved about the Neuralink app and just the entire experience?
I would like to, like I said, get back to the click on demand, like the regular clicks.
That would be great.
I would like to be able to connect to more devices.
Right now, it's just the computer.
I'd like to be able to use it on my phone or use it on different consoles, different platforms.
I'd like to be able to control as much stuff as possible, honestly, like an Optimus robot would be pretty cool.
That would be sick if I could control an Optimus robot, the link app itself, it seems like we are getting pretty dialed in to what it might look like down the road.
It seems like we've gotten through a lot of what I've done.
Yeah.
What I want from it, at least.
The only other thing I would say is more control over all the parameters that I can tweak with my cursor and stuff.
There's a lot of things that go into how the cursor moves in certain ways.
And I have, I don't know, like three or four of those parameters.
Like gain and friction and all that.
Gain, friction, yeah.
And there's maybe double the amount of those with just like velocity.
And then with the actual dwell cursor.
So I would like all of it.
I want as much control over my environment as possible.
So you want like advanced mode, you know, like in like there's menus, usually there's basic mode.
And you're like one of those folks, like the power user advanced.
Yeah, yeah.
Got it.
That's what I want.
I want as much control over this as possible.
So yeah, that's really all I can ask for.
Just give me everything.
Give me everything.
Has speech been useful?
Like just being able to talk also in addition to everything else?
Yeah.
You mean like while I'm using it?
While you're using it, like speech to text?
Oh, yeah.
Or do you type?
Or like, because there's also a keyboard.
Yeah, yeah.
So there's a virtual keyboard.
That's another thing I would like to work more on is finding some way to type or text in a different way.
Right now it is like a dictation, basically, and a virtual keyboard that I can use with the cursor.
But we've played around with...
Like fingerspelling, like sign language fingerspelling.
And that seems really promising.
So I have this thought in my head that it's going to be a very similar learning curve that I had with the cursor,
where I went from attempted movement to imagined movement at one point.
I have a feeling, this is just my intuition, that at some point I'm going to be doing fingerspelling
and I won't need to actually attempt to fingerspell anymore.
That I'll just be able to think the letter that I want and it'll pop up.
That would be epic.
Yeah.
That's challenging.
That's hard.
That's a lot of work for you to kind of take that leap.
But that would be awesome.
And then going from letters to words is another step.
You would go from...
Right now it's fingerspelling of just the sign language alphabet.
But if it's able to pick that up, then it should be able to pick up the whole sign language language.
And so then if I could do something along those lines,
or just the sign language spelled word,
if I can spell it at a reasonable speed and it can pick that up,
then I would just be able to think that through and it would do the same thing.
I don't see why not.
After what I saw with the cursor control, I don't see why it wouldn't work.
But we'd have to play around with it more.
What was the process in terms of training yourself to go from attempted movement to imagined movement?
How long did that take?
So how long would this kind of process take?
Well, it was a couple of weeks before it just like happened upon me.
But now that I know that that was possible, I think I could make it happen with other things.
I think it would be much, much simpler.
Would you get an upgraded implant device?
Sure.
Absolutely.
Whenever they'll let me.
So you don't have any concerns for you with the surgery experience?
All of it was like no regrets?
No.
So everything's been good so far?
Yep.
Do you just keep getting upgrades?
Yeah.
I mean, why not?
I've seen how much it's impacted my life already.
And I know that everything from here on out is just going to get better and better.
So I would love to.
I would love to get the upgrade.
What future capabilities are you excited about sort of beyond this kind of telepathy?
Is vision interesting?
So for folks who, for example, who are blind, so you're like enabling people to see or for speech.
Yeah, there's a lot that's very, very cool about this.
I mean, we're talking about the brain.
So there's like, this is just motor cortex stuff.
There's so much more that can be done.
The vision one is fascinating to me.
I think that is going to be very, very cool to give someone the ability to see for the first time in their life would just be, I mean, it, it might be more amazing than even helping someone like me.
Like that just sounds incredible.
The speech thing is really interesting.
Being able to have some sort of like real time.
Translation and, um, cut away that language barrier would be really cool.
Um, any sort of like actual impairments, um, that it could solve, like with speech would be very, very cool.
And then also there are a lot of different disabilities that all originate in the brain and you would be able to hopefully be able to solve a lot of those.
Um, I know there's already stuff to help people with seizures, um, that can be implanted in the brain.
This would.
Do I imagine the same thing?
And so you could do something like that.
I know that, you know, even someone like Joe Rogan has talked about, uh, the possibilities with being able to, um, stimulate the brain in different ways.
Um, I'm not sure.
I'm not sure what, you know, like how ethical a lot of that would be.
That's beyond me, honestly.
But I know that there's a lot that can be done when we're talking about the brain.
And being able to go in and physically make changes to help people or to improve their lives.
So I'm really looking forward to everything that comes from this and I don't think it's all that far off.
Um, I think a lot of this can be implemented within my lifetime.
Um, assuming that I live a long life, what you're referring to is things like people suffering from depression or things of that nature, potentially getting help.
Yeah.
Flip a switch like that.
Make someone happy.
Um, I know, I think Joe has talked about it more in terms of like, you want to experience like what a drug trip feels like.
Like you want to experience what you like to be on.
Of course.
Oh yeah.
Mushrooms or something like that.
DMT.
Like you can just flip that switch in the brain.
Uh, my buddy Bane has talked about being able to like wipe parts of your memory and re-experience things that like for the first time, like your favorite movie or your favorite book, like just wipe that out real quick.
And then re-fall in love.
And then re-experience stuff with Harry Potter or something.
Um, I told him, I was like, I don't know how I feel about like people being able to just wipe parts of your memory.
Um, that seems a little sketchy to me.
He's like, they're already doing it.
So.
Sounds legit.
Uh, I would love memory replay.
Just like actually like high resolution replay of old memories.
Yeah.
I saw an episode of black mirror about that once.
I don't think I want it.
Yeah.
So black mirror always kind of considers the worst case, which is important.
Yeah.
I don't consider the best case or the average case enough.
I don't know what it is about us humans.
We want to think about the worst possible thing.
Yeah.
We love drama.
Yeah.
It's like, how's this new technology going to kill everybody?
We just love that.
Hopefully people don't think about that too much with me.
It'll ruin a lot of my plans.
Yeah.
Yeah.
I assume you're going to have to take over the world.
I mean, you're, I love your Twitter.
I've been hearing voices in my head since getting the neural link, but I feel like people would take it the wrong way.
Plus the voices in my head told me not to.
Yeah.
Yeah.
Yeah.
Please never stop.
So you were talking about optimists.
Is that something you would love to be able to do to control the robotic arm or the entirety of optimists?
Oh yeah, for sure.
For sure.
Absolutely.
You think there's something like fundamentally different about just being able to physically interact with the world?
Yeah. Oh, a hundred percent.
This, I know another thing with like being able to like give people the ability to like feel sensation and stuff too, by going in with the brain and having the neural link maybe do that.
That could be something that could be translated through, transferred through the optimist as well.
Like there's all sorts of really cool interplay between that.
And then also, like you said, just physically interacting.
99% of the things that I can't do myself, obviously I need a caretaker for, someone to physically do things for me.
If an optimist robot could do that, like I could live an incredibly independent life and not be such a burden on those around me.
It would change the way people like me live, at least until whatever this gets cured.
So yeah.
Definitely.
Yeah.
Awesome.
Thank you guys.
It's a pleasure.
Yeah.
Yeah.
But being able to interact with the world physically like that would just be amazing.
And they're not just for having to be a caretaker or something, but something like I talked about, just being able to read a book.
Imagine an optimist robot just being able to hold a book open in front of me, get that smell again.
I might not be able to feel it at that point, or maybe I could, again, with the sensation and stuff.
But there's something different about reading a physical book than staring at a screen or listening to an audio book.
I actually don't like audio books.
I've listened to a ton of them at this point, but I don't really like them.
I would much rather read a physical copy.
So one of the things you would love to be able to experience is opening the book, bringing it up to you, and to feel the touch of the paper.
Yeah.
Oh, man.
The touch, the smell.
I mean, it's just something about the words.
The words on the page.
They've replicated that page color on the Kindle and stuff.
Yeah.
It's just not the same.
Yeah.
So just something as simple as that.
So one of the things you miss is touch?
I do.
Yeah.
A lot of things that I interact with in the world, like clothes or literally any physical thing that I interact with in the world, a lot of times what people around me will do is they'll just come rub it on my face.
They'll lay something on me so I can feel it.
They'll lay something on me so I can feel the weight they will rub, you know, a shirt on me so I can feel fabric like there's something very profound about touch and it is it's something that I miss a lot and something I would love to do again, but we'll see what would be the first thing you do with a with a hand that can touch your mama hug after that, right?
Yeah, yeah, I know.
That's it's one thing that I've that I've asked.
Like God for basically every day since my accident was just being able to like one day move even if it was only like my hand so that way like I could squeeze my mom's hand or something just to like show her that you know, like how much I care and how much I love her and everything something along those lines being able to just interact with the people around me handshake give someone a hug.
I don't know anything like that being able to help me eat.
Like I'd probably get really fat which would be a terrible terrible thing also be bliss and chess on a physical chessboard.
Yeah, yeah, I mean there are just so many upsides, you know, any any way to find some way to feel like I'm bringing bliss down to my level.
Yeah, yeah, he's just such an amazing guy and everything about him is just so above and beyond that.
Yeah.
I don't know what I can do to take him down a notch.
Yeah.
Yeah, humble him a bit.
He needs it.
Yeah.
Okay, as he's sitting next to me.
Did you ever make sense of why God puts good people through such hardship?
Oh, man.
I think it's all about understanding how much we need God and I don't think that.
There's any light without the dark I think that if all of us were happy all the time there would be, you know, no reason to turn to God ever I feel like there would be no concept of, you know, good or bad and I think that as much of like the darkness and the evil that's in the world it makes us all appreciate the good and the things we have.
So much more and I think, you know, like when I had my accident the first one of the first things I said to one of my best friends was in this was within like the first month or two after my accident I said, you know, everything about this accident has just made me understand and believe that like God is real and that there really is a God basically in that like my interactions with him have all been, you know, real and worthwhile and he said if anything seeing me go through this accident.
Yeah.
Believes that there isn't a God and it's a very different reaction, but I believe that it is it is a way for God to test us to build our character to send us through trials and tribulations to make sure that we understand how precious, you know, he is and the things that he's given us in the time that he's given us and then hopefully grow from all of that.
I think that's a huge part.
Of being here is to not just, you know, have an easy life and do everything that's easy but to step out of our comfort zones and really challenge ourselves because I think that's how we grow what gives you hope about this whole thing we have going on human civilization, man, I think people are my biggest inspiration even just being at Neuralink.
For a few months, looking people in the eyes and hearing their motivations for why they're doing this. It's, it's so inspiring. And I know that they could be other places at cushier jobs, working somewhere else, doing X, Y or Z that doesn't really mean that much. But instead, they're here, and they want to better humanity and they want to better just the people around them, the people that are around them.
They want to make better lives for their own family members who might have disabilities or they look at someone like me and they say, you know, I can do something about that. So I'm going to, and it's always been what I've connected with most in the world are people. I'm, I've always been a people person and I love learning about people. And I love learning like how people developed and where they came from. And to see like how much people are willing to do for someone like me when they don't have to. And they're going out there.
Out of their way to make my life better. It gives me a lot of hope for just humanity in general, how much, how much we care and how much we're capable of when we all kind of get together and try to make a difference. And I know there's a lot of bad out there in the world, but there always has been and there always will be. And I think that that is, it shows human resiliency and it shows what we're able, what we're able to endure.
And how much, how much we just want to be there and help each other and how much satisfaction we get from that. Because I think that's one of the reasons that we're here is just to help each other. And I don't know that, that always gives me hope is just realizing that there are people out there who still care and who want to help.
And thank you for being one such human being and continuing to be a great human being through.
Thank you for everything you've been through and being an inspiration to many people, to myself for many reasons, including your epic, unbelievably great performance on WebGrid. I will be training all night tonight to try to catch up.
You can do it.
And I believe in you that you can, once you come back, so sorry to interrupt with the Austin trip. Once you come back, eventually beat bliss.
Yeah, yeah, for sure. Absolutely.
I'm rooting for you. The whole world is rooting for you. Thank you for everything you've done, man.
Thanks. Thanks, man.
Thanks for listening to this conversation with Nolan Arbaugh. And before that, with Elon Musk, DJ Saw, Matthew McDougal, and Bliss Chapman. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Aldous Huxley in The Doors of Perception.
We live together. We act on and react to one another. But always, and in all circumstances, we are by ourselves.
The martyrs go hand in hand into the arena. They are crucified alone. Embraced, the lovers desperately try to fuse their insulated ecstasies into a single self-transcendence in vain.
But it's very nature. Every embodied spirit is doomed to suffer and enjoy its solitude. Sensations, feelings, insights, fancies, all these are private and accept through symbols and a second hand.
We can pull information about experiences, but never the experiences themselves. From family to nation, every human group is a society of island universes.
Thank you for listening, and hope to see you next time.
